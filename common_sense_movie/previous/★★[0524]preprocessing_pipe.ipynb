{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonicaKim89/Review_analysis_text_mining/blob/main/%5B0524%5Dpreprocessing_pipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etfLZBpozHHS"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses\n",
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8sJzTyTXy7Bt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "from hanspell import spell_checker\n",
        "import re\n",
        "import joblib\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_vect = TfidfVectorizer()\n",
        "\n",
        "\n",
        "### sent\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from transformers import *\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "# import sentencepiece as spm\n",
        "\n",
        "# import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH67KVM_zGIV",
        "outputId": "1c257868-50f5-44b7-bbd6-5d6f9d0031c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cwS4nA39NTP",
        "outputId": "2e39a5b3-d12f-41a3-f553-cd15eb4013fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/Derma/PIPE\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/Derma/PIPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj86DxbQ4bWk"
      },
      "source": [
        "### **DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDCJTF-U4a-a",
        "outputId": "c5587dfb-f99a-4a73-fb63-30050d1a2d68"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_excel('..\\\\classification\\\\data\\\\[0523]class_df_v1.xlsx')\n",
        "data_org = pd.read_excel(\"C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Derma\\\\important_data\\\\[0328]derma_final.xlsx\")\n",
        "# loaded_rf =  joblib.load('data/0524_RF_model_88.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbyZsEPC0kKt"
      },
      "source": [
        "### **BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ws-L_iCv0oYR"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = u'‚ñÅ'\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A KoBERT sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A KoBERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sXU20uB-_WS",
        "outputId": "33e28ee2-99cd-49e5-de43-f6de3e768039"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/transformers/7e55d7972628e6fc1babc614b5dd8bb43ab4f9d8541adc9fb1851112a7a7c5cc.4d2f4af7c2ca9df5b147978a95d38840e84801a378eee25756b008638e0bdc7f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/efee434f5f4c5c89b5a7d8d5f30bbb0496f1540349fcfa21729cec5b96cfd2d1.719459e20bc981bc2093e859b02c3a3e51bab724d6b58927b23b512a3981229f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d1c07e179f5e00959a3c8e4a150eaa4907dfe26544e4a71f2b0163982a476523.767d1b760a83978bae6c324157fad57ee513af333a7cea6986e852579f6f0dd1\n",
            "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"monologg/kobert\",\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gf_f8II52Aea"
      },
      "outputs": [],
      "source": [
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "    \n",
        "    SEQ_LEN = 64 #SEQ_LEN : Î≤ÑÌä∏Ïóê Îì§Ïñ¥Í∞à Ïù∏ÌíãÏùò Í∏∏Ïù¥\n",
        "    \n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        # token : Î¨∏Ïû•ÏùÑ ÌÜ†ÌÅ∞ÌôîÌï®\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], truncation=True, padding='max_length', max_length=SEQ_LEN)\n",
        "       \n",
        "        # ÎßàÏä§ÌÅ¨Îäî ÌÜ†ÌÅ∞ÌôîÌïú Î¨∏Ïû•ÏóêÏÑú Ìå®Îî©Ïù¥ ÏïÑÎãå Î∂ÄÎ∂ÑÏùÄ 1, Ìå®Îî©Ïù∏ Î∂ÄÎ∂ÑÏùÄ 0ÏúºÎ°ú ÌÜµÏùº\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        \n",
        "        # Î¨∏Ïû•Ïùò Ï†ÑÌõÑÍ¥ÄÍ≥ÑÎ•º Íµ¨Î∂ÑÌï¥Ï£ºÎäî ÏÑ∏Í∑∏Î®ºÌä∏Îäî Î¨∏Ïû•Ïù¥ 1Í∞úÎ∞ñÏóê ÏóÜÏúºÎØÄÎ°ú Î™®Îëê 0\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        # Î≤ÑÌä∏ Ïù∏ÌíãÏúºÎ°ú Îì§Ïñ¥Í∞ÄÎäî token, mask, segmentÎ•º tokens, segmentsÏóê Í∞ÅÍ∞Å Ï†ÄÏû•\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        \n",
        "        # Ï†ïÎãµ(Í∏çÏ†ï : 1 Î∂ÄÏ†ï 0)ÏùÑ targets Î≥ÄÏàòÏóê Ï†ÄÏû•Ìï¥ Ï§å\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\n",
        "\n",
        "    # tokens, masks, segments, Ï†ïÎãµ Î≥ÄÏàò targetsÎ•º numpy arrayÎ°ú ÏßÄÏ†ï    \n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    return [tokens, masks, segments], targets\n",
        "\n",
        "# ÏúÑÏóê Ï†ïÏùòÌïú convert_data Ìï®ÏàòÎ•º Î∂àÎü¨Ïò§Îäî Ìï®ÏàòÎ•º Ï†ïÏùò\n",
        "def load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y\n",
        "\n",
        "    \n",
        "#------------------Ïã§Ï†ú ÌÖåÏä§Ìä∏ Ìï†Îïå Î∞îÍøÄ Í≤É--------------------------------\n",
        "SEQ_LEN = 8\n",
        "BATCH_SIZE = 32\n",
        "# Í∏çÎ∂ÄÏ†ï Î¨∏Ïû•ÏùÑ Ìè¨Ìï®ÌïòÍ≥† ÏûàÎäî ÏπºÎüº\n",
        "DATA_COLUMN = \"sliced_reviews\"\n",
        "# Í∏çÏ†ïÏù∏ÏßÄ Î∂ÄÏ†ïÏù∏ÏßÄÎ•º (1=Í∏çÏ†ï,0=Î∂ÄÏ†ï) Ìè¨Ìï®ÌïòÍ≥† ÏûàÎäî ÏπºÎüº\n",
        "LABEL_COLUMN = \"label\"\n",
        "\n",
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN].tolist()[i], max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        segments.append(segment)\n",
        "        masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "# ÏúÑÏóê Ï†ïÏùòÌïú convert_data Ìï®ÏàòÎ•º Î∂àÎü¨Ïò§Îäî Ìï®ÏàòÎ•º Ï†ïÏùò\n",
        "def predict_load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "    return data_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bwg0tf3m33EG"
      },
      "outputs": [],
      "source": [
        "def sentence_convert_data(data):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    token = tokenizer.encode(data, max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "    \n",
        "    num_zeros = token.count(0) \n",
        "    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \n",
        "    segment = [0]*SEQ_LEN\n",
        "\n",
        "    tokens.append(token)\n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "4s7J1Vvb3nDO"
      },
      "outputs": [],
      "source": [
        "def derma_evaluation_predict(sentence):\n",
        "    sent_class = []\n",
        "    sent_score = []\n",
        "    score_class = []\n",
        "\n",
        "    data_x = sentence_convert_data(sentence)\n",
        "    predict = sentiment_model.predict(data_x)\n",
        "    predict_value = np.ravel(predict)\n",
        "    predict_answer = np.round(predict_value,0).item()\n",
        "    \n",
        "    if predict_answer == 0:\n",
        "        sent_class.append('Î∂ÄÏ†ï')\n",
        "\n",
        "        score = round(float(1-predict_value),2)\n",
        "        sent_score.append(score)\n",
        "\n",
        "    elif predict_answer == 1:\n",
        "        sent_class.append('Í∏çÏ†ï')\n",
        "        \n",
        "        score = round(float(predict_value),2)\n",
        "        sent_score.append(score)\n",
        "        \n",
        "    return sent_class, sent_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKfCaFydHEN_"
      },
      "source": [
        "### **SENTIMENTAL MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rGcQlzQ1FEQ",
        "outputId": "75f32b4b-e6d9-4881-feb0-d21938dab293"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/monologg/kobert/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9525d6f96682baa1f21538ea58d36263fe16a46345dd9637e3e28a4df2f9380f.ebe6e13ff204bebbffd4764cda3d5a97dc690a9c4110bde6d909ddc3ed5c4585\n",
            "Loading PyTorch weights from /root/.cache/huggingface/transformers/9525d6f96682baa1f21538ea58d36263fe16a46345dd9637e3e28a4df2f9380f.ebe6e13ff204bebbffd4764cda3d5a97dc690a9c4110bde6d909ddc3ed5c4585\n",
            "PyTorch checkpoint contains 92,186,880 parameters\n",
            "Loaded 92,186,880 parameters in the TF 2.0 model.\n",
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/optimizers/rectified_adam.py:120: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
        "# ÌÜ†ÌÅ∞ Ïù∏Ìíã, ÎßàÏä§ÌÅ¨ Ïù∏Ìíã, ÏÑ∏Í∑∏Î®ºÌä∏ Ïù∏Ìíã Ï†ïÏùò\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "# Ïù∏ÌíãÏù¥ [ÌÜ†ÌÅ∞, ÎßàÏä§ÌÅ¨, ÏÑ∏Í∑∏Î®ºÌä∏]Ïù∏ Î™®Îç∏ Ï†ïÏùò\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
        "\n",
        "\n",
        "bert_outputs = bert_outputs[1]\n",
        "# Rectified Adam ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÇ¨Ïö©\n",
        "\n",
        "\n",
        "# Ï¥ù batch size * 4 epoch = 2344 * 4\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*2, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "\n",
        "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
        "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
        "sentiment_model.load_weights(\"/content/drive/MyDrive/Projects/Derma/Sentimental Analysis/sentimental models/weight[0523]sent_derma_v1.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNjns2BX9-jt"
      },
      "source": [
        "### **SENTENCE PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text): \n",
        "    \"\"\" ÌïúÍ∏Ä, ÏòÅÎ¨∏, Ïà´ÏûêÎßå ÎÇ®Í∏∞Í≥† Ï†úÍ±∞ÌïúÎã§. \n",
        "    :param text: \n",
        "    :return: \n",
        "    \"\"\" \n",
        "    text = text.replace(\".\", \" \").strip() \n",
        "    text = text.replace(\"¬∑\", \" \").strip() \n",
        "    pattern = '[^ „Ñ±-„Ö£Í∞Ä-Ìû£|0-9|]+' \n",
        "    text = re.sub(pattern=pattern, repl='', string=text) \n",
        "    return text \n",
        "\n",
        "def stemming (text):\n",
        "    morphs_list = []\n",
        "    one_words = []\n",
        "    result = []\n",
        "\n",
        "    pos = okt.pos(text, join = False)\n",
        "    # print(pos)\n",
        "    try:\n",
        "        for j in pos:\n",
        "            if j.split('/')[1] == 'Noun':\n",
        "                j = j.split('/')[0]\n",
        "                morphs_list.append(j)\n",
        "                        \n",
        "            elif j.split('/')[1] =='Adjective':\n",
        "                k = okt.morphs(j,  stem= True)\n",
        "                k = k[0]\n",
        "                morphs_list.append(k)\n",
        "            elif j.split('/')[1] =='Verb':\n",
        "                v = okt.morphs(j,  stem= True)\n",
        "                v = v[0]\n",
        "                morphs_list.append(v)\n",
        "\n",
        "            elif j.split('/')[1] =='Adverb':\n",
        "                ad = okt.morphs(j,  stem= True)\n",
        "                v = v[0]\n",
        "                morphs_list.append(ad)\n",
        "\n",
        "        for i in morphs_list:\n",
        "            if len(i) != 1:\n",
        "                result.append(i)\n",
        "        \n",
        "\n",
        "        # for i in one_words:\n",
        "        #     if i not in stopwords_kor:\n",
        "        #         result.append(i)\n",
        "    except:\n",
        "        result.append(text)\n",
        "        pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def cleaned_sentence(x):\n",
        "    cleaned_list = []\n",
        "    str_x = str(x)\n",
        "    pos = okt.pos(str_x, join = True)\n",
        "    sent_ = str(pos)\n",
        "    adj = sent_.split('/Adjective')\n",
        "    for i in adj:\n",
        "        v = i.split('/Verb') \n",
        "        for k in v:\n",
        "            str_k = str(k)\n",
        "            cln_k = clean_text(k)\n",
        "            cln_k = cln_k.replace(' ', '')\n",
        "            space = spell_checker.check(cln_k)\n",
        "            text = space.checked\n",
        "            cleaned_list.append(text)\n",
        "\n",
        "    return cleaned_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuR6ZtWRB78c",
        "outputId": "15fc514a-0df2-470b-c838-c0b3b75bf61d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "####\n",
        "train_data = train_data.astype(str)\n",
        "X_train = train_data['document']\n",
        "tf_vect.fit(X_train)\n",
        "    ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YWjMErRo-JjZ"
      },
      "outputs": [],
      "source": [
        "def class_sent(x):\n",
        "\n",
        "    cleaned_list = []\n",
        "    sent_class = []\n",
        "    sent_score = []\n",
        "    score_dim = []\n",
        "\n",
        "\n",
        "    str_x = str(x)\n",
        "    pos = okt.pos(str_x, join = True)\n",
        "    sent_ = str(pos)\n",
        "    adj = sent_.split('/Adjective')\n",
        "    for i in adj:\n",
        "        v = i.split('/Verb') \n",
        "        for k in v:\n",
        "            str_k = str(k)\n",
        "            cln_k = clean_text(k)\n",
        "            cln_k = cln_k.replace(' ', '')\n",
        "            space = spell_checker.check(cln_k)\n",
        "            text = space.checked\n",
        "            if len(text)<=4:\n",
        "                pass\n",
        "            else:\n",
        "                cleaned_list.append(text)\n",
        "            df_ = pd.DataFrame({'sliced_reviews':cleaned_list})\n",
        "            X_test_tfidf_vect = tf_vect.transform(df_['sliced_reviews'])\n",
        "            answer = loaded_rf.predict(X_test_tfidf_vect)\n",
        "\n",
        "    #         df_['predict_class'] = answer\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"1\",\"Ïã†Î¢∞ÏÑ±\")\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"2\",\"Î∞òÏùëÏÑ±\")\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"3\",\"ÌôïÏã†ÏÑ±\")\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"4\",\"Í≥µÍ∞êÏÑ±\")\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"5\",\"Ïú†ÌòïÏÑ±\")\n",
        "    # df_['predict_class'] = df_['predict_class'].replace(\"6\",\"ÏùºÎ∞òÎ¨∏Ïû•\")\n",
        "    #         # print(f\"ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ TextÏùò CountVectorizer Shape: {X_test_tfidf_vect.shape}\")\n",
        "\n",
        "    # ###### TFIDF\n",
        "    # score_df = pd.DataFrame(df_['predict_class'].value_counts())\n",
        "\n",
        "    #### SENTIMET ANALYSIS#####\n",
        "    # pos_neg_list = []\n",
        "    # sent_score_list =[]\n",
        "\n",
        "    # pos_neg_list = []\n",
        "    # sent_score_list =[]\n",
        "    # # sent_class = []\n",
        "\n",
        "    # for i in tqdm(df['sliced_reviews'].tolist()):\n",
        "    #     pos_neg, sent_score = derma_evaluation_predict(i)\n",
        "    #     pos_neg_list.append(pos_neg)\n",
        "    #     sent_score_list.append(sent_score)\n",
        "    #     # sent_class.append(sent_class)\n",
        "    # df_['pos_neg'] = pos_neg_list\n",
        "    # df_['sent_score'] = sent_score_list\n",
        "    \n",
        "\n",
        "    return df_, score_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSc1E5lH4O-9"
      },
      "source": [
        "## **CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "####\n",
        "train_data = train_data.astype(str)\n",
        "X_train = train_data['document']\n",
        "tf_vect.fit(X_train)\n",
        "loaded_rf =  joblib.load('..\\\\classification\\\\workspace\\\\[0525]886_rf.pkl')\n",
        "    ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-sjYyIJ4WNr",
        "outputId": "92899e8e-4f4b-4745-ee70-9637f85430fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "####\n",
        "train_data = train_data.astype(str)\n",
        "X_train = train_data['document']\n",
        "tf_vect.fit(X_train)\n",
        "    ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wKEeV-Gq-T30"
      },
      "outputs": [],
      "source": [
        "reviews_list = data_org[data_org['h']=='Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê'].reviews.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_test_tfidf_vect' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47468/629238046.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloaded_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'X_test_tfidf_vect' is not defined"
          ]
        }
      ],
      "source": [
        "loaded_rf.predict(X_test_tfidf_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jDj79iPD2IN",
        "outputId": "bf949250-50c8-4cdc-cd25-d4eca6995b24"
      },
      "outputs": [],
      "source": [
        "df, score_df = class_sent(reviews_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "uQGeCvPPD2FE",
        "outputId": "cce7030d-45dc-44db-f4b8-3111fba72c64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0a12a9bd-26a3-4cdc-b52e-f788020e783b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sliced_reviews</th>\n",
              "      <th>predict_class</th>\n",
              "      <th>pos_neg</th>\n",
              "      <th>sent_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Ïù¥Ïú†Ïóê ÎåÄÌï¥ÏÑú ÏÑ§Î™ÖÏùÑ Ïûò</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.92]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Ìï¥Ï£ºÏÖ®Ïñ¥Ïöî</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.52]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ÏßÄÏù∏Îì§ÏóêÍ≤å Ï∂îÏ≤úÎ∞õÏïÑÏÑú</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.81]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ÏùòÏÇ¨ÏÑ†ÏÉùÎãòÍ≥º ÏßÑÎ£å ÌõÑÏóê ÏÉÅÎã¥Ïã§Î°ú ÏòÆÍ≤®Í∞ÄÏÑú</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.79]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ÏπòÎ£å ÌîÑÎ°úÍ∑∏Îû®ÏùÑ Í≥†Î•¥Îäî</td>\n",
              "      <td>Ïã†Î¢∞ÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.98]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ÏàúÏÑúÎ°ú ÏßÑÌñâÎêòÏóàÏñ¥Ïöî</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.94]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Î®ºÏ†Ä ÌîºÏßÄ Ï°∞Ï†àÌïòÎäî</td>\n",
              "      <td>Î∞òÏùëÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.94]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ÏïÑÏø†ÏïÑ ÌïÑ ÏúÑÏ£ºÎ°ú Í¥ÄÎ¶¨ÌñàÏäµÎãàÎã§</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.57]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Î¨∏Ïã†Ï†úÍ±∞ Î¨∏Ïã†Ìïú Í≥≥Ïùº Î∂ÄÎ∂ÑÎßå ÏßÄÏö∞Í≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.74]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ïó¨Îü¨ Íµ∞Îç∞ ÏïåÏïÑÎ≥¥Í≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.91]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>ÏõåÎÇô Í∞ÄÍ≤©Ïù¥ Ï≤úÏ∞®ÎßåÎ≥ÑÏù∏ ÏπòÎ£åÎùº ÎßêÎèÑ Ïïà ÎêòÍ≤å ÎπÑÏã∏Í≤å</td>\n",
              "      <td>Ïã†Î¢∞ÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.98]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Í≥≥ ÎßéÏùÄÎç∞</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Ìï©Î¶¨Ï†ÅÏù∏ Í∞ÄÍ≤©Ïóê ÏõêÌïòÎäî</td>\n",
              "      <td>Ïã†Î¢∞ÏÑ±</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.96]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Î∂ÄÎ∂ÑÎßå ÏßÄÏõåÏ£ºÏÑ∏Ïöî</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.99]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Î†àÏù¥Ï†ÄÏπòÎ£åÌñàÏäµÎãàÎã§</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.94]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ÏõêÏû•ÎãòÏù¥ ÏÑ§Î™ÖÎèÑ ÏûòÌï¥Ï£ºÏãúÍ≥†</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.98]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Î≥ëÏõêÎèÑ ÏóÑÏ≤≠ ÌÅ¨Í≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>ÍπÄÌï¥ÏóêÏÑú Ïú†Î™ÖÌïú</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.9]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Í≥≥ÏùÄ Ïù¥Ïú†Í∞Ä ÏûàÎÑ§Ïöî</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "      <td>[Î∂ÄÏ†ï]</td>\n",
              "      <td>[0.64]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ÏßÅÏõêÎì§ÎèÑ Ï†ÑÎ∂Ä ÏπúÏ†àÌï¥ÏÑú</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "      <td>[Í∏çÏ†ï]</td>\n",
              "      <td>[0.91]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a12a9bd-26a3-4cdc-b52e-f788020e783b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a12a9bd-26a3-4cdc-b52e-f788020e783b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a12a9bd-26a3-4cdc-b52e-f788020e783b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  sliced_reviews predict_class pos_neg sent_score\n",
              "20                 Ïù¥Ïú†Ïóê ÎåÄÌï¥ÏÑú ÏÑ§Î™ÖÏùÑ Ïûò           Í≥µÍ∞êÏÑ±    [Î∂ÄÏ†ï]     [0.92]\n",
              "21                         Ìï¥Ï£ºÏÖ®Ïñ¥Ïöî           Í≥µÍ∞êÏÑ±    [Í∏çÏ†ï]     [0.52]\n",
              "22                   ÏßÄÏù∏Îì§ÏóêÍ≤å Ï∂îÏ≤úÎ∞õÏïÑÏÑú           ÌôïÏã†ÏÑ±    [Î∂ÄÏ†ï]     [0.81]\n",
              "23        ÏùòÏÇ¨ÏÑ†ÏÉùÎãòÍ≥º ÏßÑÎ£å ÌõÑÏóê ÏÉÅÎã¥Ïã§Î°ú ÏòÆÍ≤®Í∞ÄÏÑú           Í≥µÍ∞êÏÑ±    [Î∂ÄÏ†ï]     [0.79]\n",
              "24                  ÏπòÎ£å ÌîÑÎ°úÍ∑∏Îû®ÏùÑ Í≥†Î•¥Îäî           Ïã†Î¢∞ÏÑ±    [Î∂ÄÏ†ï]     [0.98]\n",
              "25                    ÏàúÏÑúÎ°ú ÏßÑÌñâÎêòÏóàÏñ¥Ïöî           ÌôïÏã†ÏÑ±    [Í∏çÏ†ï]     [0.94]\n",
              "26                    Î®ºÏ†Ä ÌîºÏßÄ Ï°∞Ï†àÌïòÎäî           Î∞òÏùëÏÑ±    [Î∂ÄÏ†ï]     [0.94]\n",
              "27              ÏïÑÏø†ÏïÑ ÌïÑ ÏúÑÏ£ºÎ°ú Í¥ÄÎ¶¨ÌñàÏäµÎãàÎã§          ÏùºÎ∞òÎ¨∏Ïû•    [Î∂ÄÏ†ï]     [0.57]\n",
              "28           Î¨∏Ïã†Ï†úÍ±∞ Î¨∏Ïã†Ìïú Í≥≥Ïùº Î∂ÄÎ∂ÑÎßå ÏßÄÏö∞Í≥†          ÏùºÎ∞òÎ¨∏Ïû•    [Í∏çÏ†ï]     [0.74]\n",
              "29                    Ïó¨Îü¨ Íµ∞Îç∞ ÏïåÏïÑÎ≥¥Í≥†          ÏùºÎ∞òÎ¨∏Ïû•    [Í∏çÏ†ï]     [0.91]\n",
              "30  ÏõåÎÇô Í∞ÄÍ≤©Ïù¥ Ï≤úÏ∞®ÎßåÎ≥ÑÏù∏ ÏπòÎ£åÎùº ÎßêÎèÑ Ïïà ÎêòÍ≤å ÎπÑÏã∏Í≤å           Ïã†Î¢∞ÏÑ±    [Î∂ÄÏ†ï]     [0.98]\n",
              "31                         Í≥≥ ÎßéÏùÄÎç∞           ÌôïÏã†ÏÑ±    [Í∏çÏ†ï]      [0.8]\n",
              "32                  Ìï©Î¶¨Ï†ÅÏù∏ Í∞ÄÍ≤©Ïóê ÏõêÌïòÎäî           Ïã†Î¢∞ÏÑ±    [Í∏çÏ†ï]     [0.96]\n",
              "33                     Î∂ÄÎ∂ÑÎßå ÏßÄÏõåÏ£ºÏÑ∏Ïöî          ÏùºÎ∞òÎ¨∏Ïû•    [Î∂ÄÏ†ï]     [0.99]\n",
              "34                     Î†àÏù¥Ï†ÄÏπòÎ£åÌñàÏäµÎãàÎã§           ÌôïÏã†ÏÑ±    [Î∂ÄÏ†ï]     [0.94]\n",
              "35                ÏõêÏû•ÎãòÏù¥ ÏÑ§Î™ÖÎèÑ ÏûòÌï¥Ï£ºÏãúÍ≥†           ÌôïÏã†ÏÑ±    [Î∂ÄÏ†ï]     [0.98]\n",
              "36                     Î≥ëÏõêÎèÑ ÏóÑÏ≤≠ ÌÅ¨Í≥†          ÏùºÎ∞òÎ¨∏Ïû•    [Í∏çÏ†ï]      [0.6]\n",
              "37                      ÍπÄÌï¥ÏóêÏÑú Ïú†Î™ÖÌïú          ÏùºÎ∞òÎ¨∏Ïû•    [Í∏çÏ†ï]      [0.9]\n",
              "38                    Í≥≥ÏùÄ Ïù¥Ïú†Í∞Ä ÏûàÎÑ§Ïöî          ÏùºÎ∞òÎ¨∏Ïû•    [Î∂ÄÏ†ï]     [0.64]\n",
              "39                  ÏßÅÏõêÎì§ÎèÑ Ï†ÑÎ∂Ä ÏπúÏ†àÌï¥ÏÑú           ÌôïÏã†ÏÑ±    [Í∏çÏ†ï]     [0.91]"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[20:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zu2P0YSGEBtJ",
        "outputId": "abd5af73-3d31-4e26-d62a-e41aa2c5be7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ab5ff93-00e9-4d38-85f7-422991ea6dd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ÏùºÎ∞òÎ¨∏Ïû•</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ÌôïÏã†ÏÑ±</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Í≥µÍ∞êÏÑ±</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ïã†Î¢∞ÏÑ±</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Î∞òÏùëÏÑ±</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ab5ff93-00e9-4d38-85f7-422991ea6dd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ab5ff93-00e9-4d38-85f7-422991ea6dd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ab5ff93-00e9-4d38-85f7-422991ea6dd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      predict_class\n",
              "ÏùºÎ∞òÎ¨∏Ïû•             34\n",
              "ÌôïÏã†ÏÑ±              24\n",
              "Í≥µÍ∞êÏÑ±               7\n",
              "Ïã†Î¢∞ÏÑ±               7\n",
              "Î∞òÏùëÏÑ±               1"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWyqV7IIEBlA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HqaXWgVEBi_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjRNIkZMEBgp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK8hvO1pEBee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75lnltnCEBcc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHKCJKw94BHO"
      },
      "source": [
        "### **Analyzing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VI_vhzTa1E-9"
      },
      "outputs": [],
      "source": [
        "answer_list = []\n",
        "\n",
        "for i in hos_1['sliced_reviews'].tolist():\n",
        "    if len(i)>=60:\n",
        "        answer_list.append('Ìï¥Í≤∞ÏïàÎê®')\n",
        "    elif len(i)<=60:\n",
        "        answer = derma_evaluation_predict(i)\n",
        "        answer_list.append(answer) \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YOQ9KiYF1E8T"
      },
      "outputs": [],
      "source": [
        "preds=sentiment_model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrDwjpb20oSD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbiM5iKH0oP1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMChMus70oNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46TQAByf0oKX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fXbrHPW0oIV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RZFti87My7Bw"
      },
      "outputs": [],
      "source": [
        "def clean_text(text): \n",
        "    \"\"\" ÌïúÍ∏Ä, ÏòÅÎ¨∏, Ïà´ÏûêÎßå ÎÇ®Í∏∞Í≥† Ï†úÍ±∞ÌïúÎã§. \n",
        "    :param text: \n",
        "    :return: \n",
        "    \"\"\" \n",
        "    text = text.replace(\".\", \" \").strip() \n",
        "    text = text.replace(\"¬∑\", \" \").strip() \n",
        "    pattern = '[^ „Ñ±-„Ö£Í∞Ä-Ìû£|0-9|]+' \n",
        "    text = re.sub(pattern=pattern, repl='', string=text) \n",
        "    return text \n",
        "\n",
        "def stemming (text):\n",
        "    morphs_list = []\n",
        "    one_words = []\n",
        "    result = []\n",
        "\n",
        "    pos = okt.pos(text, join = False)\n",
        "    # print(pos)\n",
        "    try:\n",
        "        for j in pos:\n",
        "            if j.split('/')[1] == 'Noun':\n",
        "                j = j.split('/')[0]\n",
        "                morphs_list.append(j)\n",
        "                        \n",
        "            elif j.split('/')[1] =='Adjective':\n",
        "                k = okt.morphs(j,  stem= True)\n",
        "                k = k[0]\n",
        "                morphs_list.append(k)\n",
        "            elif j.split('/')[1] =='Verb':\n",
        "                v = okt.morphs(j,  stem= True)\n",
        "                v = v[0]\n",
        "                morphs_list.append(v)\n",
        "\n",
        "            elif j.split('/')[1] =='Adverb':\n",
        "                ad = okt.morphs(j,  stem= True)\n",
        "                v = v[0]\n",
        "                morphs_list.append(ad)\n",
        "\n",
        "        for i in morphs_list:\n",
        "            if len(i) != 1:\n",
        "                result.append(i)\n",
        "        \n",
        "\n",
        "        # for i in one_words:\n",
        "        #     if i not in stopwords_kor:\n",
        "        #         result.append(i)\n",
        "    except:\n",
        "        result.append(text)\n",
        "        pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def cleaned_sentence(x):\n",
        "    cleaned_list = []\n",
        "    str_x = str(x)\n",
        "    pos = okt.pos(str_x, join = True)\n",
        "    sent_ = str(pos)\n",
        "    adj = sent_.split('/Adjective')\n",
        "    for i in adj:\n",
        "        v = i.split('/Verb') \n",
        "        for k in v:\n",
        "            str_k = str(k)\n",
        "            cln_k = clean_text(k)\n",
        "            cln_k = cln_k.replace(' ', '')\n",
        "            space = spell_checker.check(cln_k)\n",
        "            text = space.checked\n",
        "            cleaned_list.append(text)\n",
        "\n",
        "    return cleaned_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VcTr2-Q-y7Bx",
        "outputId": "076acc02-fe32-4b15-c2f3-f731946ad740"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Projects/Derma/PIPE/workspace'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "/pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BfPVG6iz7mA",
        "outputId": "814510bb-9bd3-4c23-9c40-b9d3eacb81e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/Derma/PIPE/workspace\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/Derma/PIPE/workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ufinj8aey7By"
      },
      "outputs": [],
      "source": [
        "data_org = pd.read_excel('../data/[0328]derma_final.xlsx', index_col=0)\n",
        "train_data = pd.read_excel(\"../data/[0523]class_df_v1.xlsx\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "QBNDLvovy7By",
        "outputId": "45e74838-ac23-49a3-f965-0a4efd574258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39216, 15)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>h</th>\n",
              "      <th>adr</th>\n",
              "      <th>d</th>\n",
              "      <th>f</th>\n",
              "      <th>reviews</th>\n",
              "      <th>stars</th>\n",
              "      <th>treatments</th>\n",
              "      <th>money</th>\n",
              "      <th>ÎπÑÍ≥†</th>\n",
              "      <th>do</th>\n",
              "      <th>si</th>\n",
              "      <th>ro</th>\n",
              "      <th>adr_else</th>\n",
              "      <th>stemm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê</td>\n",
              "      <td>Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)</td>\n",
              "      <td>ÏóÜÏùå</td>\n",
              "      <td>ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            3Ïõî 15Ïùº, 2022ÎÖÑ Í≤åÏãú          ...</td>\n",
              "      <td>ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ùÏúºÎ°ú ÎÇ¥ÏõêÌïú Î≥ëÏõêÏù∏Îç∞ ÏßÑÎ£å ÎÅùÎÇòÍ≥† ÎëêÌîº ÌòÑÎØ∏Í≤ΩÏÇ¨ÏßÑÏùÑ Î¨¥Î£åÎ°ú Ï∞çÏñ¥ÏÑú ÏÉÅÎã¥...</td>\n",
              "      <td>9.3</td>\n",
              "      <td>ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ù</td>\n",
              "      <td>4900</td>\n",
              "      <td>Î¶¨Î∑∞ÏóÜÏùå</td>\n",
              "      <td>Í≤ΩÎÇ®</td>\n",
              "      <td>ÍπÄÌï¥Ïãú</td>\n",
              "      <td>ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú</td>\n",
              "      <td>57</td>\n",
              "      <td>['ÎëêÌîº', 'Í∞ÄÎ†§ÏõÄÏ¶ù', 'ÏõêÌïú', 'Î≥ëÏõê', 'ÏßÑÎ£å', 'ÎÅùÎÇòÎã§', 'ÎëêÌîº', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê</td>\n",
              "      <td>Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)</td>\n",
              "      <td>ÏóÜÏùå</td>\n",
              "      <td>ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            12Ïõî 20Ïùº, 2021ÎÖÑ Í≤åÏãú         ...</td>\n",
              "      <td>ÎåÄÏÉÅÌè¨ÏßÑÏúºÎ°ú ÏßÑÎ£åÎ∞õÏïòÏñ¥Ïöî. 2Ï£º Ïù¥ÏÉÅ ÏπòÎ£åÎ∞õÍ≥† ÏïΩ Î®πÍ≥† Ï£ºÏÇ¨ ÎßûÏúºÎãàÍπå ÏßÑÌÜµÏù¥ Í∞ÄÎùºÏïâ...</td>\n",
              "      <td>10</td>\n",
              "      <td>ÎåÄÏÉÅÌè¨ÏßÑ</td>\n",
              "      <td>4200</td>\n",
              "      <td>Î¶¨Î∑∞ÏóÜÏùå</td>\n",
              "      <td>Í≤ΩÎÇ®</td>\n",
              "      <td>ÍπÄÌï¥Ïãú</td>\n",
              "      <td>ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú</td>\n",
              "      <td>57</td>\n",
              "      <td>['ÎåÄÏÉÅÌè¨ÏßÑ', 'ÏßÑÎ£å', 'Î∞õÎã§', 'ÏπòÎ£åÎ∞õÎã§', 'Î®πÎã§', 'Ï£ºÏÇ¨', 'ÎßûÎã§',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê</td>\n",
              "      <td>Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)</td>\n",
              "      <td>ÏóÜÏùå</td>\n",
              "      <td>ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            8Ïõî 11Ïùº, 2021ÎÖÑ Í≤åÏãú          ...</td>\n",
              "      <td>Ïó¨ÎìúÎ¶Ñ Í≥†ÎØºÏù¥ ÏûàÏñ¥ÏÑú Î∞©Î¨∏ÌñàÏäµÎãàÎã§. ÌîºÎ∂ÄÏ†ÑÎ¨∏ÏùòÎùºÏÑú Ï¶ùÏÉÅÏù¥ ÎÇòÌÉÄÎÇú Ïù¥Ïú†Ïóê ÎåÄÌï¥ÏÑú ÏÑ§Î™Ö...</td>\n",
              "      <td>10</td>\n",
              "      <td>Í¥ÄÎ¶¨ ÏïàÎê®</td>\n",
              "      <td>4000</td>\n",
              "      <td>Î¶¨Î∑∞ÏóÜÏùå</td>\n",
              "      <td>Í≤ΩÎÇ®</td>\n",
              "      <td>ÍπÄÌï¥Ïãú</td>\n",
              "      <td>ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú</td>\n",
              "      <td>57</td>\n",
              "      <td>['Ïó¨ÎìúÎ¶Ñ', 'Í≥†ÎØº', 'Î∞©Î¨∏', 'ÌîºÎ∂Ä', 'Ï†ÑÎ¨∏Ïùò', 'Ï¶ùÏÉÅ', 'ÎÇòÌÉÄÎÇòÎã§',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0          h                   adr   d  \\\n",
              "0          0  Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê  Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)  ÏóÜÏùå   \n",
              "1          1  Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê  Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)  ÏóÜÏùå   \n",
              "2          2  Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê  Í≤ΩÎÇ® ÍπÄÌï¥Ïãú ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú 57 (ÎÇ¥Îèô)  ÏóÜÏùå   \n",
              "\n",
              "                                                   f  \\\n",
              "0  ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            3Ïõî 15Ïùº, 2022ÎÖÑ Í≤åÏãú          ...   \n",
              "1  ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            12Ïõî 20Ïùº, 2021ÎÖÑ Í≤åÏãú         ...   \n",
              "2  ÏóÜÏùåÏòÅÏàòÏ¶ù Ïù∏Ï¶ù            8Ïõî 11Ïùº, 2021ÎÖÑ Í≤åÏãú          ...   \n",
              "\n",
              "                                             reviews stars treatments  \\\n",
              "0  ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ùÏúºÎ°ú ÎÇ¥ÏõêÌïú Î≥ëÏõêÏù∏Îç∞ ÏßÑÎ£å ÎÅùÎÇòÍ≥† ÎëêÌîº ÌòÑÎØ∏Í≤ΩÏÇ¨ÏßÑÏùÑ Î¨¥Î£åÎ°ú Ï∞çÏñ¥ÏÑú ÏÉÅÎã¥...   9.3    ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ù   \n",
              "1  ÎåÄÏÉÅÌè¨ÏßÑÏúºÎ°ú ÏßÑÎ£åÎ∞õÏïòÏñ¥Ïöî. 2Ï£º Ïù¥ÏÉÅ ÏπòÎ£åÎ∞õÍ≥† ÏïΩ Î®πÍ≥† Ï£ºÏÇ¨ ÎßûÏúºÎãàÍπå ÏßÑÌÜµÏù¥ Í∞ÄÎùºÏïâ...    10       ÎåÄÏÉÅÌè¨ÏßÑ   \n",
              "2  Ïó¨ÎìúÎ¶Ñ Í≥†ÎØºÏù¥ ÏûàÏñ¥ÏÑú Î∞©Î¨∏ÌñàÏäµÎãàÎã§. ÌîºÎ∂ÄÏ†ÑÎ¨∏ÏùòÎùºÏÑú Ï¶ùÏÉÅÏù¥ ÎÇòÌÉÄÎÇú Ïù¥Ïú†Ïóê ÎåÄÌï¥ÏÑú ÏÑ§Î™Ö...    10     Í¥ÄÎ¶¨ ÏïàÎê®    \n",
              "\n",
              "     money    ÎπÑÍ≥†  do   si     ro adr_else  \\\n",
              "0    4900   Î¶¨Î∑∞ÏóÜÏùå  Í≤ΩÎÇ®  ÍπÄÌï¥Ïãú  ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú       57   \n",
              "1    4200   Î¶¨Î∑∞ÏóÜÏùå  Í≤ΩÎÇ®  ÍπÄÌï¥Ïãú  ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú       57   \n",
              "2  4000     Î¶¨Î∑∞ÏóÜÏùå  Í≤ΩÎÇ®  ÍπÄÌï¥Ïãú  ÎÇ¥Ïô∏Ï§ëÏïôÎ°ú       57   \n",
              "\n",
              "                                               stemm  \n",
              "0  ['ÎëêÌîº', 'Í∞ÄÎ†§ÏõÄÏ¶ù', 'ÏõêÌïú', 'Î≥ëÏõê', 'ÏßÑÎ£å', 'ÎÅùÎÇòÎã§', 'ÎëêÌîº', ...  \n",
              "1  ['ÎåÄÏÉÅÌè¨ÏßÑ', 'ÏßÑÎ£å', 'Î∞õÎã§', 'ÏπòÎ£åÎ∞õÎã§', 'Î®πÎã§', 'Ï£ºÏÇ¨', 'ÎßûÎã§',...  \n",
              "2  ['Ïó¨ÎìúÎ¶Ñ', 'Í≥†ÎØº', 'Î∞©Î¨∏', 'ÌîºÎ∂Ä', 'Ï†ÑÎ¨∏Ïùò', 'Ï¶ùÏÉÅ', 'ÎÇòÌÉÄÎÇòÎã§',...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data_org.copy()\n",
        "print(data.shape)\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "59Y577hUy7Bz"
      },
      "outputs": [],
      "source": [
        "reviews = data[data['h']=='Í≥†Ïö¥ÎÇòÎùºÌîºÎ∂ÄÍ≥ºÏùòÏõê'].reviews.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGAt9P-o23__"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MbcPjVJy7B0",
        "outputId": "dd25af02-3b40-4576-8267-be9926e8a43e"
      },
      "outputs": [],
      "source": [
        "####\n",
        "train_data = train_data.astype(str)\n",
        "X_train = train_data['document']\n",
        "tf_vect.fit(X_train)\n",
        "loaded_rf =  joblib.load('..\\\\classification\\\\workspace\\\\0524_RF_model_88.pkl')\n",
        "    ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "25_t0qA5y7B0"
      },
      "outputs": [],
      "source": [
        "def cleaned_sentence(x):\n",
        "\n",
        "    cleaned_list = []\n",
        "    str_x = str(x)\n",
        "    pos = okt.pos(str_x, join = True)\n",
        "    sent_ = str(pos)\n",
        "    adj = sent_.split('/Adjective')\n",
        "    for i in adj:\n",
        "        v = i.split('/Verb') \n",
        "        for k in v:\n",
        "            str_k = str(k)\n",
        "            cln_k = clean_text(k)\n",
        "            cln_k = cln_k.replace(' ', '')\n",
        "            space = spell_checker.check(cln_k)\n",
        "            text = space.checked\n",
        "            if len(text)<=4:\n",
        "                pass\n",
        "            else:\n",
        "                cleaned_list.append(text)\n",
        "            df_ = pd.DataFrame({'sliced_reviews':cleaned_list})\n",
        "            X_test_tfidf_vect = tf_vect.transform(df_['sliced_reviews'])\n",
        "            answer = loaded_rf.predict(X_test_tfidf_vect)\n",
        "\n",
        "            df_['predict_class'] = answer\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"1\",\"Ïã†Î¢∞ÏÑ±\")\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"2\",\"Î∞òÏùëÏÑ±\")\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"3\",\"ÌôïÏã†ÏÑ±\")\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"4\",\"Í≥µÍ∞êÏÑ±\")\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"5\",\"Ïú†ÌòïÏÑ±\")\n",
        "    df_['predict_class'] = df_['predict_class'].replace(\"6\",\"ÏùºÎ∞òÎ¨∏Ïû•\")\n",
        "            # print(f\"ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ TextÏùò CountVectorizer Shape: {X_test_tfidf_vect.shape}\")\n",
        "\n",
        "    ###### TFIDF\n",
        "    score_df = pd.DataFrame(df_['predict_class'].value_counts())\n",
        "            \n",
        "\n",
        "    return df_, score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "DfYjn7Ghy7B1",
        "outputId": "79b2833f-3374-473a-e583-0c1b4e93d8d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sliced_reviews</th>\n",
              "      <th>predict_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ùÏúºÎ°ú ÎÇ¥ÏõêÌïú</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Î≥ëÏõêÏù∏Îç∞ ÏßÑÎ£å ÎÅùÎÇòÍ≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ÎëêÌîº ÌòÑÎØ∏Í≤ΩÏÇ¨ÏßÑÏùÑ Î¨¥Î£åÎ°ú Ï∞çÏñ¥ÏÑú</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ÏÉÅÎã¥Ìï¥Ï£ºÏÖ®Ïñ¥Ïöî</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ï†ú ÎëêÌîºÏóê ÎßûÎäî</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ÏÉ¥Ìë∏ Í∂åÌïòÏÖîÏÑú</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ÌïòÎÇò ÏÇ¨Í∞ÄÏßÄÍ≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ÏÉ¥Ìë∏ Î∞©Î≤ïÎèÑ ÏûêÏÑ∏Ìûà</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ÏïåÎ†§Ï£ºÏãúÍ≥†</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ÏπúÏ†àÌïòÏÖ®Ïñ¥Ïöî</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ÎåÄÏÉÅÌè¨ÏßÑÏúºÎ°ú ÏßÑÎ£åÎ∞õÏïòÏñ¥Ïöî</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2Ï£º Ïù¥ÏÉÅ ÏπòÎ£åÎ∞õÍ≥†</td>\n",
              "      <td>Ïã†Î¢∞ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ï£ºÏÇ¨ ÎßûÏúºÎãàÍπå</td>\n",
              "      <td>Ïã†Î¢∞ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ÏßÑÌÜµÏù¥ Í∞ÄÎùºÏïâÏïòÏäµÎãàÎã§</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ÎåÄÏÉÅÌè¨ÏßÑ Î¨¥ÏÑ≠ÎÑ§Ïöî</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ÌÜµÏ¶ùÏù¥ Í∞ÄÎùºÏïâÏïÑÎèÑ</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ÌõÑÏú†Ï¶ùÏù¥ ÎÇ®ÏïÑÏÑú Í∑∏ Î∂ÄÏúÑÍ∞Ä Í≥ÑÏÜç ÏïÑÌîÑÎÑ§Ïöî</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ÏòàÎ∞©Ï†ëÏ¢Ö Íº≠ Ìï¥Ïïº</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Ìï¥Ïöî Ïó¨ÎìúÎ¶Ñ Í≥†ÎØºÏù¥ ÏûàÏñ¥ÏÑú</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Î∞©Î¨∏ÌñàÏäµÎãàÎã§</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sliced_reviews predict_class\n",
              "0            ÎëêÌîº Í∞ÄÎ†§ÏõÄÏ¶ùÏúºÎ°ú ÎÇ¥ÏõêÌïú          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "1              Î≥ëÏõêÏù∏Îç∞ ÏßÑÎ£å ÎÅùÎÇòÍ≥†          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "2        ÎëêÌîº ÌòÑÎØ∏Í≤ΩÏÇ¨ÏßÑÏùÑ Î¨¥Î£åÎ°ú Ï∞çÏñ¥ÏÑú          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "3                  ÏÉÅÎã¥Ìï¥Ï£ºÏÖ®Ïñ¥Ïöî           ÌôïÏã†ÏÑ±\n",
              "4                 Ï†ú ÎëêÌîºÏóê ÎßûÎäî          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "5                  ÏÉ¥Ìë∏ Í∂åÌïòÏÖîÏÑú           ÌôïÏã†ÏÑ±\n",
              "6                  ÌïòÎÇò ÏÇ¨Í∞ÄÏßÄÍ≥†          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "7               ÏÉ¥Ìë∏ Î∞©Î≤ïÎèÑ ÏûêÏÑ∏Ìûà          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "8                    ÏïåÎ†§Ï£ºÏãúÍ≥†           ÌôïÏã†ÏÑ±\n",
              "9                   ÏπúÏ†àÌïòÏÖ®Ïñ¥Ïöî           Í≥µÍ∞êÏÑ±\n",
              "10           ÎåÄÏÉÅÌè¨ÏßÑÏúºÎ°ú ÏßÑÎ£åÎ∞õÏïòÏñ¥Ïöî          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "11              2Ï£º Ïù¥ÏÉÅ ÏπòÎ£åÎ∞õÍ≥†           Ïã†Î¢∞ÏÑ±\n",
              "12                 Ï£ºÏÇ¨ ÎßûÏúºÎãàÍπå           Ïã†Î¢∞ÏÑ±\n",
              "13             ÏßÑÌÜµÏù¥ Í∞ÄÎùºÏïâÏïòÏäµÎãàÎã§          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "14               ÎåÄÏÉÅÌè¨ÏßÑ Î¨¥ÏÑ≠ÎÑ§Ïöî           ÌôïÏã†ÏÑ±\n",
              "15               ÌÜµÏ¶ùÏù¥ Í∞ÄÎùºÏïâÏïÑÎèÑ          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "16  ÌõÑÏú†Ï¶ùÏù¥ ÎÇ®ÏïÑÏÑú Í∑∏ Î∂ÄÏúÑÍ∞Ä Í≥ÑÏÜç ÏïÑÌîÑÎÑ§Ïöî          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "17               ÏòàÎ∞©Ï†ëÏ¢Ö Íº≠ Ìï¥Ïïº          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "18          Ìï¥Ïöî Ïó¨ÎìúÎ¶Ñ Í≥†ÎØºÏù¥ ÏûàÏñ¥ÏÑú          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "19                  Î∞©Î¨∏ÌñàÏäµÎãàÎã§           ÌôïÏã†ÏÑ±"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hos_1, score_df = cleaned_sentence(reviews)\n",
        "hos_1.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dJvRfIRxy7B1",
        "outputId": "de310fe4-d953-49b3-9563-a78f178bcfc8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3939f436-5d2a-47b9-a0f6-238a005a7337\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ÏùºÎ∞òÎ¨∏Ïû•</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ÌôïÏã†ÏÑ±</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Í≥µÍ∞êÏÑ±</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ïã†Î¢∞ÏÑ±</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Î∞òÏùëÏÑ±</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3939f436-5d2a-47b9-a0f6-238a005a7337')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3939f436-5d2a-47b9-a0f6-238a005a7337 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3939f436-5d2a-47b9-a0f6-238a005a7337');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      predict_class\n",
              "ÏùºÎ∞òÎ¨∏Ïû•             34\n",
              "ÌôïÏã†ÏÑ±              24\n",
              "Í≥µÍ∞êÏÑ±               7\n",
              "Ïã†Î¢∞ÏÑ±               7\n",
              "Î∞òÏùëÏÑ±               1"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "work_list=[]\n",
        "alist=[]                          # ÎΩëÏùÄ aÎ•º ÎÑ£Ïñ¥ Ï§ëÎ≥µ Î∞©ÏßÄÌï¥Ï£ºÎäî Î¶¨Ïä§Ìä∏         \n",
        "for i in range(300):\n",
        "  a = random.randint(1,38949)\n",
        "  alist.append(a)      \n",
        "  while a in alist :              # aÍ∞Ä Ïù¥ÎØ∏ ÎΩëÏùÄ Î¶¨Ïä§Ìä∏Ïóê ÏûàÏùÑ ÎïåÍπåÏßÄ Îã§Ïãú ÎΩëÏûê\n",
        "    a = random.randint(1,38949)\n",
        "    work_list.append(data_org['reviews'].tolist()[a])\n",
        "\n",
        "len(work_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "df, score_df = cleaned_sentence(work_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_excel('0525_derma_3.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN12GIlJy7B2"
      },
      "outputs": [],
      "source": [
        "test, score_df = cleaned_sentence('Î†àÏù¥Ï†ÄÌÜ†Îãù ÏπúÏ†àÌïòÍ≥† Îã§Î•∏ Í±∞ Í∂åÏú† Ïïà ÌïòÍ≥† ÌïÑÏöîÌïú Í≤ÉÎßå ÎßêÌï¥Ï£ºÏÖîÏÑú Ï¢ãÍ≥† ÏßÅÏõêÎ∂ÑÎì§ Îã§ ÏπúÏ†àÌïòÏÑ∏Ïöî. ÏãúÏÑ§ÎèÑ Ï¢ãÍ≥† ÌïòÏßÄÎßå ÏòàÏïΩÌï¥ÎèÑ Ï¢Ä ÎåÄÍ∏∞Í∞Ä ÏûàÏïÑÏöî ÎãπÏùºÏòàÏïΩÎèÑ ÎêòÍ≥† Ï¢ãÎÑ§Ïöî!! ÏπúÏ†àÌï¥ÏÑú ÎÑàÎ¨¥ Ï¢ãÏäµÎãàÎã§. Ìö®Í≥ºÎäî ÏïÑÏßÅ Ïùº Ï£ºÏ∞®Îùº Î™®Î•¥Í≤†Ïñ¥Ïöî.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7u_atw9y7B2",
        "outputId": "19d0057b-adbe-4d11-f3f2-84e8f3721a22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sliced_reviews</th>\n",
              "      <th>predict_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Î†àÏù¥Ï†ÄÌÜ†Îãù ÏπúÏ†àÌïòÍ≥†</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Îã§Î•∏ Í±∞ Í∂åÏú† Ïïà ÌïòÍ≥†</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Í≤ÉÎßå ÎßêÌï¥Ï£ºÏÖîÏÑú</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ÏßÅÏõêÎ∂ÑÎì§ Îã§ ÏπúÏ†àÌïòÏÑ∏Ïöî</td>\n",
              "      <td>ÌôïÏã†ÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ÏãúÏÑ§ÎèÑ Ï¢ãÍ≥†</td>\n",
              "      <td>Ïú†ÌòïÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ÌïòÏßÄÎßå ÏòàÏïΩÌï¥ÎèÑ</td>\n",
              "      <td>Í≥µÍ∞êÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ï¢Ä ÎåÄÍ∏∞Í∞Ä ÏûàÏïÑÏöî</td>\n",
              "      <td>Î∞òÏùëÏÑ±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ÎãπÏùºÏòàÏïΩÎèÑ ÎêòÍ≥†</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ÎÑàÎ¨¥ Ï¢ãÏäµÎãàÎã§</td>\n",
              "      <td>ÏùºÎ∞òÎ¨∏Ïû•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ìö®Í≥ºÎäî ÏïÑÏßÅ Ïùº Ï£ºÏ∞®Îùº Î™®Î•¥Í≤†Ïñ¥Ïöî</td>\n",
              "      <td>Ïú†ÌòïÏÑ±</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sliced_reviews predict_class\n",
              "0          Î†àÏù¥Ï†ÄÌÜ†Îãù ÏπúÏ†àÌïòÍ≥†           Í≥µÍ∞êÏÑ±\n",
              "1        Îã§Î•∏ Í±∞ Í∂åÏú† Ïïà ÌïòÍ≥†           Í≥µÍ∞êÏÑ±\n",
              "2            Í≤ÉÎßå ÎßêÌï¥Ï£ºÏÖîÏÑú           ÌôïÏã†ÏÑ±\n",
              "3        ÏßÅÏõêÎ∂ÑÎì§ Îã§ ÏπúÏ†àÌïòÏÑ∏Ïöî           ÌôïÏã†ÏÑ±\n",
              "4              ÏãúÏÑ§ÎèÑ Ï¢ãÍ≥†           Ïú†ÌòïÏÑ±\n",
              "5            ÌïòÏßÄÎßå ÏòàÏïΩÌï¥ÎèÑ           Í≥µÍ∞êÏÑ±\n",
              "6           Ï¢Ä ÎåÄÍ∏∞Í∞Ä ÏûàÏïÑÏöî           Î∞òÏùëÏÑ±\n",
              "7            ÎãπÏùºÏòàÏïΩÎèÑ ÎêòÍ≥†          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "8             ÎÑàÎ¨¥ Ï¢ãÏäµÎãàÎã§          ÏùºÎ∞òÎ¨∏Ïû•\n",
              "9  Ìö®Í≥ºÎäî ÏïÑÏßÅ Ïùº Ï£ºÏ∞®Îùº Î™®Î•¥Í≤†Ïñ¥Ïöî           Ïú†ÌòïÏÑ±"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwvNuu40y7B2",
        "outputId": "3855bb11-df98-48a0-d084-c300e3626190"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Í≥µÍ∞êÏÑ±</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ÌôïÏã†ÏÑ±</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ïú†ÌòïÏÑ±</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ÏùºÎ∞òÎ¨∏Ïû•</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Î∞òÏùëÏÑ±</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      predict_class\n",
              "Í≥µÍ∞êÏÑ±               3\n",
              "ÌôïÏã†ÏÑ±               2\n",
              "Ïú†ÌòïÏÑ±               2\n",
              "ÏùºÎ∞òÎ¨∏Ïû•              2\n",
              "Î∞òÏùëÏÑ±               1"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk9M220Iy7B3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ZNjns2BX9-jt"
      ],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "[0524]preprocessing_pipe.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b131aa79fbb012ccd5fe9686ca8fc5b84b44b90404dbf3b7f41759e12b8001b3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('NLP')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
