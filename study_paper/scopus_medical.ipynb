{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import selenium.common.exceptions as sex\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "path = '/Users/mac626/chromedriver'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.implicitly_wait(3)\n",
    "\n",
    "url = 'https://www.scopus.com/results/results.uri?cc=10&sort=plf-f&src=s&nlo=&nlr=&nls=&sid=c6816bc7750a52c2298547700b553bb7&sot=b&sdt=cl&cluster=scopubyr%2c%222022%22%2ct%2c%222021%22%2ct%2c%222020%22%2ct%2c%222019%22%2ct%2c%222018%22%2ct%2c%222017%22%2ct%2c%222016%22%2ct%2c%222015%22%2ct%2bscopubstage%2c%22final%22%2ct%2bscosubtype%2c%22ar%22%2ct%2c%22re%22%2ct%2bscolang%2c%22English%22%2ct%2bscosrctype%2c%22j%22%2ct&sl=25&s=TITLE-ABS-KEY%28medical+AI%29&ss=plf-f&ps=r-f&editSaveSearch=&origin=resultslist&zone=resultslist'\n",
    "\n",
    "driver.get(url)\n",
    "WebDriverWait(driver, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.support.wait.WebDriverWait (session=\"90306aca81cf910295b2248224912bde\")>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#취소\n",
    "# driver.find_element_by_xpath('//*[@id=\"_pendo-close-guide_\"]').click()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TITLE-ABS-KEY ( medical  AND ai )  AND  ( LIMIT-TO ( PUBYEAR ,  2022 )  OR  LIMIT-TO ( PUBYEAR ,  2021 )  OR  LIMIT-TO ( PUBYEAR ,  2020 )  OR  LIMIT-TO ( PUBYEAR ,  2019 )  OR  LIMIT-TO ( PUBYEAR ,  2018 )  OR  LIMIT-TO ( PUBYEAR ,  2017 )  OR  LIMIT-TO ( PUBYEAR ,  2016 )  OR  LIMIT-TO ( PUBYEAR ,  2015 ) )  AND  ( LIMIT-TO ( PUBSTAGE ,  \"final\" ) )  AND  ( LIMIT-TO ( DOCTYPE ,  \"ar\" )  OR  LIMIT-TO ( DOCTYPE ,  \"re\" ) )  AND  ( LIMIT-TO ( LANGUAGE ,  \"English\" ) )  AND  ( LIMIT-TO ( SRCTYPE ,  \"j\" ) ) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#citation_high\n",
    "driver.find_element_by_xpath('//*[@id=\"navLoad-button\"]/span[1]').click()\n",
    "WebDriverWait(driver, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.support.wait.WebDriverWait (session=\"90306aca81cf910295b2248224912bde\")>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"ui-id-3\"]').click()\n",
    "WebDriverWait(driver, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.support.wait.WebDriverWait (session=\"90306aca81cf910295b2248224912bde\")>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#반복해야할 수 있음\n",
    "driver.find_element_by_xpath('//*[@id=\"resultsPerPage-button\"]/span[2]').click()\n",
    "WebDriverWait(driver, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.support.wait.WebDriverWait (session=\"90306aca81cf910295b2248224912bde\")>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"resultsPerPage-menu\"]/li[4]').click()\n",
    "WebDriverWait(driver, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.support.wait.WebDriverWait (session=\"90306aca81cf910295b2248224912bde\")>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "page = driver.page_source\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "print(len(soup))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Titles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "titles = soup.find_all('a', attrs={'class':'ddmDocTitle'})\n",
    "title = []\n",
    "\n",
    "for i in titles:\n",
    "    title.append(i.get_text())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(len(title))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "authors = soup.find_all('span', attrs={'class':'ddmAuthorList'})\n",
    "author =[]\n",
    "\n",
    "for i in authors:\n",
    "    author.append(i.get_text())\n",
    "\n",
    "print(len(author))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "years = soup.find_all('span', attrs={'class':'ddmPubYr'})\n",
    "year =[]\n",
    "\n",
    "for i in years:\n",
    "    year.append(i.get_text())\n",
    "\n",
    "print(len(year))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "journals = soup.find_all('a', attrs={'class':'ddmDocSource'})\n",
    "journal =[]\n",
    "\n",
    "for i in journals:\n",
    "    journal.append(i.get_text())\n",
    "\n",
    "print(len(journal))\n",
    "print(journal[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n",
      "Cell\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "pages = soup.find_all('div', attrs={'class':'additionalContent'})\n",
    "page =[]\n",
    "\n",
    "for i in pages:\n",
    "    page.append(i.get_text())\n",
    "\n",
    "print(len(page))\n",
    "print(page[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n",
      "172(5),\n",
      "pp.\n",
      "1122-1131.e9\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import pandas as pd\n",
    "\n",
    "medical_AI_1 = pd.DataFrame({'Title':title, 'Author':author, 'Year':year})\n",
    "medical_AI_1.to_csv('medical_AI_1.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ABSTRACT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText1\"]/a/span[1]').click()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "try:\n",
    "    for i in range(1,201):\n",
    "        # driver.implicitly_wait(1)\n",
    "        driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText{}\"]/a/span[1]'.format(i)).click()\n",
    "    # driver.implicitly_wait(4)\n",
    "        WebDriverWait(driver, 10)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Failed\", i)\n",
    "    pass\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Failed 28\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "try:\n",
    "    for i in range(29,201):\n",
    "        # driver.implicitly_wait(1)\n",
    "        driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText{}\"]/a/span[1]'.format(i)).click()\n",
    "    # driver.implicitly_wait(4)\n",
    "        WebDriverWait(driver, 10)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Failed\", i)\n",
    "    pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "page = driver.page_source\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "print(len(soup))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "abstract_list = []\n",
    "for i in range(1, 28):\n",
    "    abstract_list.append('//*[@id=\"previewAbstract{}\"]/span'.format(i))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "for j in range(29, 201):\n",
    "    abstract_list.append('//*[@id=\"previewAbstract{}\"]/span'.format(j))\n",
    "    \n",
    "print(abstract_list[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "//*[@id=\"previewAbstract200\"]/span\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "abstract = []\n",
    "for num, j in enumerate(abstract_list):\n",
    "    contents = driver.find_elements_by_xpath(j)\n",
    "    for i in contents:\n",
    "        abstract.apped(i.text) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "import pandas as pd\n",
    "medical_AI_1 = pd.read_csv('medical_AI_1.csv', index_col=0)\n",
    "medical_AI_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identifying Medical Diagnoses and Treatable Di...</td>\n",
       "      <td>\\nKermany, D.S., Goldbaum, M., Cai, W., (...),...</td>\n",
       "      <td>2018</td>\n",
       "      <td>The implementation of clinical-decision suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computational radiomics system to decode the r...</td>\n",
       "      <td>\\nVan Griethuysen, J.J.M., Fedorov, A., Parmar...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Radiomics aims to quantify phenotypic characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guidelines for the early management of patient...</td>\n",
       "      <td>\\nPowers, W.J., Rabinstein, A.A., Ackerson, T....</td>\n",
       "      <td>2019</td>\n",
       "      <td>Background and Purpose-The purpose of these gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial intelligence in radiology</td>\n",
       "      <td>\\nHosny, A., Parmar, C., Quackenbush, J., Schw...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Artificial intelligence (AI) algorithms, parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brain Intelligence: Go beyond Artificial Intel...</td>\n",
       "      <td>\\nLu, H., Li, Y., Chen, M., Kim, H., Serikawa,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Artificial intelligence (AI) is an important t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Cardiovascular events in patients with mild au...</td>\n",
       "      <td>\\nMorelli, V., Palmieri, S., Lania, A., (...),...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Background: The independent role of mild auton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Update on therapeutic approaches and emerging ...</td>\n",
       "      <td>\\nOmolo, C.A., Soni, N., Fasiku, V.O., Mackraj...</td>\n",
       "      <td>2020</td>\n",
       "      <td>The global pandemic of coronavirus disease 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Artificial Intelligence in Dentistry: Chances ...</td>\n",
       "      <td>\\nSchwendicke, F., Samek, W., Krois, J.\\n</td>\n",
       "      <td>2020</td>\n",
       "      <td>The term “artificial intelligence” (AI) refers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Explainable deep learning models in medical im...</td>\n",
       "      <td>\\nSingh, A., Sengupta, S., Lakshminarayanan, V.\\n</td>\n",
       "      <td>2020</td>\n",
       "      <td>Deep learning methods have been very effective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Machine learning and big data: Implications fo...</td>\n",
       "      <td>\\nTai, A.M.Y., Albuquerque, A., Carmona, N.E.,...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Introduction: Machine learning capability hold...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Identifying Medical Diagnoses and Treatable Di...   \n",
       "1    Computational radiomics system to decode the r...   \n",
       "2    Guidelines for the early management of patient...   \n",
       "3                 Artificial intelligence in radiology   \n",
       "4    Brain Intelligence: Go beyond Artificial Intel...   \n",
       "..                                                 ...   \n",
       "195  Cardiovascular events in patients with mild au...   \n",
       "196  Update on therapeutic approaches and emerging ...   \n",
       "197  Artificial Intelligence in Dentistry: Chances ...   \n",
       "198  Explainable deep learning models in medical im...   \n",
       "199  Machine learning and big data: Implications fo...   \n",
       "\n",
       "                                                Author  Year  \\\n",
       "0    \\nKermany, D.S., Goldbaum, M., Cai, W., (...),...  2018   \n",
       "1    \\nVan Griethuysen, J.J.M., Fedorov, A., Parmar...  2017   \n",
       "2    \\nPowers, W.J., Rabinstein, A.A., Ackerson, T....  2019   \n",
       "3    \\nHosny, A., Parmar, C., Quackenbush, J., Schw...  2018   \n",
       "4    \\nLu, H., Li, Y., Chen, M., Kim, H., Serikawa,...  2018   \n",
       "..                                                 ...   ...   \n",
       "195  \\nMorelli, V., Palmieri, S., Lania, A., (...),...  2017   \n",
       "196  \\nOmolo, C.A., Soni, N., Fasiku, V.O., Mackraj...  2020   \n",
       "197          \\nSchwendicke, F., Samek, W., Krois, J.\\n  2020   \n",
       "198  \\nSingh, A., Sengupta, S., Lakshminarayanan, V.\\n  2020   \n",
       "199  \\nTai, A.M.Y., Albuquerque, A., Carmona, N.E.,...  2019   \n",
       "\n",
       "                                              Abstract  \n",
       "0    The implementation of clinical-decision suppor...  \n",
       "1    Radiomics aims to quantify phenotypic characte...  \n",
       "2    Background and Purpose-The purpose of these gu...  \n",
       "3    Artificial intelligence (AI) algorithms, parti...  \n",
       "4    Artificial intelligence (AI) is an important t...  \n",
       "..                                                 ...  \n",
       "195  Background: The independent role of mild auton...  \n",
       "196  The global pandemic of coronavirus disease 201...  \n",
       "197  The term “artificial intelligence” (AI) refers...  \n",
       "198  Deep learning methods have been very effective...  \n",
       "199  Introduction: Machine learning capability hold...  \n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    " medical_AI_1 = medical_AI_1.drop(medical_AI_1.index[27])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "medical_AI_1['Abstract']=abstract"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "medical_AI_1.to_csv('medical_AI_1.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "def abstracts_a(abstract_list):\n",
    "    contents = driver.find_elements_by_xpath(abstract_list)\n",
    "    for i in contents:\n",
    "        abstract = i\n",
    "\n",
    "    return abstract"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "for i in abstract_list:\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "//*[@id=\"previewAbstract1\"]/span\n",
      "//*[@id=\"previewAbstract2\"]/span\n",
      "//*[@id=\"previewAbstract3\"]/span\n",
      "//*[@id=\"previewAbstract4\"]/span\n",
      "//*[@id=\"previewAbstract5\"]/span\n",
      "//*[@id=\"previewAbstract6\"]/span\n",
      "//*[@id=\"previewAbstract7\"]/span\n",
      "//*[@id=\"previewAbstract8\"]/span\n",
      "//*[@id=\"previewAbstract9\"]/span\n",
      "//*[@id=\"previewAbstract10\"]/span\n",
      "//*[@id=\"previewAbstract11\"]/span\n",
      "//*[@id=\"previewAbstract12\"]/span\n",
      "//*[@id=\"previewAbstract13\"]/span\n",
      "//*[@id=\"previewAbstract14\"]/span\n",
      "//*[@id=\"previewAbstract15\"]/span\n",
      "//*[@id=\"previewAbstract16\"]/span\n",
      "//*[@id=\"previewAbstract17\"]/span\n",
      "//*[@id=\"previewAbstract18\"]/span\n",
      "//*[@id=\"previewAbstract19\"]/span\n",
      "//*[@id=\"previewAbstract20\"]/span\n",
      "//*[@id=\"previewAbstract21\"]/span\n",
      "//*[@id=\"previewAbstract22\"]/span\n",
      "//*[@id=\"previewAbstract23\"]/span\n",
      "//*[@id=\"previewAbstract24\"]/span\n",
      "//*[@id=\"previewAbstract25\"]/span\n",
      "//*[@id=\"previewAbstract26\"]/span\n",
      "//*[@id=\"previewAbstract27\"]/span\n",
      "//*[@id=\"previewAbstract29\"]/span\n",
      "//*[@id=\"previewAbstract30\"]/span\n",
      "//*[@id=\"previewAbstract31\"]/span\n",
      "//*[@id=\"previewAbstract32\"]/span\n",
      "//*[@id=\"previewAbstract33\"]/span\n",
      "//*[@id=\"previewAbstract34\"]/span\n",
      "//*[@id=\"previewAbstract35\"]/span\n",
      "//*[@id=\"previewAbstract36\"]/span\n",
      "//*[@id=\"previewAbstract37\"]/span\n",
      "//*[@id=\"previewAbstract38\"]/span\n",
      "//*[@id=\"previewAbstract39\"]/span\n",
      "//*[@id=\"previewAbstract40\"]/span\n",
      "//*[@id=\"previewAbstract41\"]/span\n",
      "//*[@id=\"previewAbstract42\"]/span\n",
      "//*[@id=\"previewAbstract43\"]/span\n",
      "//*[@id=\"previewAbstract44\"]/span\n",
      "//*[@id=\"previewAbstract45\"]/span\n",
      "//*[@id=\"previewAbstract46\"]/span\n",
      "//*[@id=\"previewAbstract47\"]/span\n",
      "//*[@id=\"previewAbstract48\"]/span\n",
      "//*[@id=\"previewAbstract49\"]/span\n",
      "//*[@id=\"previewAbstract50\"]/span\n",
      "//*[@id=\"previewAbstract51\"]/span\n",
      "//*[@id=\"previewAbstract52\"]/span\n",
      "//*[@id=\"previewAbstract53\"]/span\n",
      "//*[@id=\"previewAbstract54\"]/span\n",
      "//*[@id=\"previewAbstract55\"]/span\n",
      "//*[@id=\"previewAbstract56\"]/span\n",
      "//*[@id=\"previewAbstract57\"]/span\n",
      "//*[@id=\"previewAbstract58\"]/span\n",
      "//*[@id=\"previewAbstract59\"]/span\n",
      "//*[@id=\"previewAbstract60\"]/span\n",
      "//*[@id=\"previewAbstract61\"]/span\n",
      "//*[@id=\"previewAbstract62\"]/span\n",
      "//*[@id=\"previewAbstract63\"]/span\n",
      "//*[@id=\"previewAbstract64\"]/span\n",
      "//*[@id=\"previewAbstract65\"]/span\n",
      "//*[@id=\"previewAbstract66\"]/span\n",
      "//*[@id=\"previewAbstract67\"]/span\n",
      "//*[@id=\"previewAbstract68\"]/span\n",
      "//*[@id=\"previewAbstract69\"]/span\n",
      "//*[@id=\"previewAbstract70\"]/span\n",
      "//*[@id=\"previewAbstract71\"]/span\n",
      "//*[@id=\"previewAbstract72\"]/span\n",
      "//*[@id=\"previewAbstract73\"]/span\n",
      "//*[@id=\"previewAbstract74\"]/span\n",
      "//*[@id=\"previewAbstract75\"]/span\n",
      "//*[@id=\"previewAbstract76\"]/span\n",
      "//*[@id=\"previewAbstract77\"]/span\n",
      "//*[@id=\"previewAbstract78\"]/span\n",
      "//*[@id=\"previewAbstract79\"]/span\n",
      "//*[@id=\"previewAbstract80\"]/span\n",
      "//*[@id=\"previewAbstract81\"]/span\n",
      "//*[@id=\"previewAbstract82\"]/span\n",
      "//*[@id=\"previewAbstract83\"]/span\n",
      "//*[@id=\"previewAbstract84\"]/span\n",
      "//*[@id=\"previewAbstract85\"]/span\n",
      "//*[@id=\"previewAbstract86\"]/span\n",
      "//*[@id=\"previewAbstract87\"]/span\n",
      "//*[@id=\"previewAbstract88\"]/span\n",
      "//*[@id=\"previewAbstract89\"]/span\n",
      "//*[@id=\"previewAbstract90\"]/span\n",
      "//*[@id=\"previewAbstract91\"]/span\n",
      "//*[@id=\"previewAbstract92\"]/span\n",
      "//*[@id=\"previewAbstract93\"]/span\n",
      "//*[@id=\"previewAbstract94\"]/span\n",
      "//*[@id=\"previewAbstract95\"]/span\n",
      "//*[@id=\"previewAbstract96\"]/span\n",
      "//*[@id=\"previewAbstract97\"]/span\n",
      "//*[@id=\"previewAbstract98\"]/span\n",
      "//*[@id=\"previewAbstract99\"]/span\n",
      "//*[@id=\"previewAbstract100\"]/span\n",
      "//*[@id=\"previewAbstract101\"]/span\n",
      "//*[@id=\"previewAbstract102\"]/span\n",
      "//*[@id=\"previewAbstract103\"]/span\n",
      "//*[@id=\"previewAbstract104\"]/span\n",
      "//*[@id=\"previewAbstract105\"]/span\n",
      "//*[@id=\"previewAbstract106\"]/span\n",
      "//*[@id=\"previewAbstract107\"]/span\n",
      "//*[@id=\"previewAbstract108\"]/span\n",
      "//*[@id=\"previewAbstract109\"]/span\n",
      "//*[@id=\"previewAbstract110\"]/span\n",
      "//*[@id=\"previewAbstract111\"]/span\n",
      "//*[@id=\"previewAbstract112\"]/span\n",
      "//*[@id=\"previewAbstract113\"]/span\n",
      "//*[@id=\"previewAbstract114\"]/span\n",
      "//*[@id=\"previewAbstract115\"]/span\n",
      "//*[@id=\"previewAbstract116\"]/span\n",
      "//*[@id=\"previewAbstract117\"]/span\n",
      "//*[@id=\"previewAbstract118\"]/span\n",
      "//*[@id=\"previewAbstract119\"]/span\n",
      "//*[@id=\"previewAbstract120\"]/span\n",
      "//*[@id=\"previewAbstract121\"]/span\n",
      "//*[@id=\"previewAbstract122\"]/span\n",
      "//*[@id=\"previewAbstract123\"]/span\n",
      "//*[@id=\"previewAbstract124\"]/span\n",
      "//*[@id=\"previewAbstract125\"]/span\n",
      "//*[@id=\"previewAbstract126\"]/span\n",
      "//*[@id=\"previewAbstract127\"]/span\n",
      "//*[@id=\"previewAbstract128\"]/span\n",
      "//*[@id=\"previewAbstract129\"]/span\n",
      "//*[@id=\"previewAbstract130\"]/span\n",
      "//*[@id=\"previewAbstract131\"]/span\n",
      "//*[@id=\"previewAbstract132\"]/span\n",
      "//*[@id=\"previewAbstract133\"]/span\n",
      "//*[@id=\"previewAbstract134\"]/span\n",
      "//*[@id=\"previewAbstract135\"]/span\n",
      "//*[@id=\"previewAbstract136\"]/span\n",
      "//*[@id=\"previewAbstract137\"]/span\n",
      "//*[@id=\"previewAbstract138\"]/span\n",
      "//*[@id=\"previewAbstract139\"]/span\n",
      "//*[@id=\"previewAbstract140\"]/span\n",
      "//*[@id=\"previewAbstract141\"]/span\n",
      "//*[@id=\"previewAbstract142\"]/span\n",
      "//*[@id=\"previewAbstract143\"]/span\n",
      "//*[@id=\"previewAbstract144\"]/span\n",
      "//*[@id=\"previewAbstract145\"]/span\n",
      "//*[@id=\"previewAbstract146\"]/span\n",
      "//*[@id=\"previewAbstract147\"]/span\n",
      "//*[@id=\"previewAbstract148\"]/span\n",
      "//*[@id=\"previewAbstract149\"]/span\n",
      "//*[@id=\"previewAbstract150\"]/span\n",
      "//*[@id=\"previewAbstract151\"]/span\n",
      "//*[@id=\"previewAbstract152\"]/span\n",
      "//*[@id=\"previewAbstract153\"]/span\n",
      "//*[@id=\"previewAbstract154\"]/span\n",
      "//*[@id=\"previewAbstract155\"]/span\n",
      "//*[@id=\"previewAbstract156\"]/span\n",
      "//*[@id=\"previewAbstract157\"]/span\n",
      "//*[@id=\"previewAbstract158\"]/span\n",
      "//*[@id=\"previewAbstract159\"]/span\n",
      "//*[@id=\"previewAbstract160\"]/span\n",
      "//*[@id=\"previewAbstract161\"]/span\n",
      "//*[@id=\"previewAbstract162\"]/span\n",
      "//*[@id=\"previewAbstract163\"]/span\n",
      "//*[@id=\"previewAbstract164\"]/span\n",
      "//*[@id=\"previewAbstract165\"]/span\n",
      "//*[@id=\"previewAbstract166\"]/span\n",
      "//*[@id=\"previewAbstract167\"]/span\n",
      "//*[@id=\"previewAbstract168\"]/span\n",
      "//*[@id=\"previewAbstract169\"]/span\n",
      "//*[@id=\"previewAbstract170\"]/span\n",
      "//*[@id=\"previewAbstract171\"]/span\n",
      "//*[@id=\"previewAbstract172\"]/span\n",
      "//*[@id=\"previewAbstract173\"]/span\n",
      "//*[@id=\"previewAbstract174\"]/span\n",
      "//*[@id=\"previewAbstract175\"]/span\n",
      "//*[@id=\"previewAbstract176\"]/span\n",
      "//*[@id=\"previewAbstract177\"]/span\n",
      "//*[@id=\"previewAbstract178\"]/span\n",
      "//*[@id=\"previewAbstract179\"]/span\n",
      "//*[@id=\"previewAbstract180\"]/span\n",
      "//*[@id=\"previewAbstract181\"]/span\n",
      "//*[@id=\"previewAbstract182\"]/span\n",
      "//*[@id=\"previewAbstract183\"]/span\n",
      "//*[@id=\"previewAbstract184\"]/span\n",
      "//*[@id=\"previewAbstract185\"]/span\n",
      "//*[@id=\"previewAbstract186\"]/span\n",
      "//*[@id=\"previewAbstract187\"]/span\n",
      "//*[@id=\"previewAbstract188\"]/span\n",
      "//*[@id=\"previewAbstract189\"]/span\n",
      "//*[@id=\"previewAbstract190\"]/span\n",
      "//*[@id=\"previewAbstract191\"]/span\n",
      "//*[@id=\"previewAbstract192\"]/span\n",
      "//*[@id=\"previewAbstract193\"]/span\n",
      "//*[@id=\"previewAbstract194\"]/span\n",
      "//*[@id=\"previewAbstract195\"]/span\n",
      "//*[@id=\"previewAbstract196\"]/span\n",
      "//*[@id=\"previewAbstract197\"]/span\n",
      "//*[@id=\"previewAbstract198\"]/span\n",
      "//*[@id=\"previewAbstract199\"]/span\n",
      "//*[@id=\"previewAbstract200\"]/span\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "for i in ()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1j/_j1_4nyn2dsdvt2c9kb6lr4r0000gn/T/ipykernel_2503/460703213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabstract_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstracts_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "abstract_list[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'//*[@id=\"previewAbstractLinkText1\"]/a/span[1]'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "k  = driver.find_elements_by_xpath(drive)\n",
    "for i in k:\n",
    "    i.text"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'value' must be a string\n  (Session info: chrome=93.0.4577.63)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1j/_j1_4nyn2dsdvt2c9kb6lr4r0000gn/T/ipykernel_2503/2615149331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/scrapper/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/scrapper/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[name=\"%s\"]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[0;32m/opt/anaconda3/envs/scrapper/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/opt/anaconda3/envs/scrapper/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'value' must be a string\n  (Session info: chrome=93.0.4577.63)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "abstract_list[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'//*[@id=\"previewAbstractLinkText1\"]/a/span'"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'//*[@id=\"previewAbstract2\"]/span'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "contents = driver.find_elements_by_xpath(abstract_list[0])\n",
    "for i in contents:\n",
    "    print(i.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "View abstract\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "contents = []\n",
    "for i in abstract_list:\n",
    "    abst = driver.find_elements_by_xpath(i)\n",
    "    contents.append(abst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "abstract = []\n",
    "\n",
    "for i in contents:\n",
    "    for num, j in enumerate (i):\n",
    "        print(j.text, num)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0\n",
      "Radiomics aims to quantify phenotypic characteristics on medical imaging through the use of automated algorithms. Radiomic artificial intelligence (AI) technology, either based on engineered hard-coded algorithms or deep learning methods, can be used to develop noninvasive imaging-based biomarkers. However, lack of standardized algorithm definitions and image processing severely hampers reproducibility and comparability of results. To address this issue, we developed PyRadiomics, a flexible open-source platform capable of extracting a large panel of engineered features from medical images. PyRadiomics is implemented in Python and can be used standalone or using 3D Slicer. Here, we discuss the workflow and architecture of PyRadiomics and demonstrate its application in characterizing lung lesions. Source code, documentation, and examples are publicly available at www. radiomics.io. With this platform, we aim to establish a reference standard for radiomic analyses, provide a tested and maintained resource, and to grow the community of radiomic developers addressing critical needs in cancer research. Cancer Res; 77(21); e104-7. 0\n",
      "Background and Purpose-The purpose of these guidelines is to provide an up-to-date comprehensive set of recommendationsin a single document for clinicians caring for adult patients with acute arterial ischemic stroke. The intended audiencesare prehospital care providers, physicians, allied health professionals, and hospital administrators. These guidelinessupersede the 2013 Acute Ischemic Stroke (AIS) Guidelines and are an update of the 2018 AIS Guidelines.Methods-Members of the writing group were appointed by the American Heart Association (AHA) Stroke Council'sScientific Statements Oversight Committee, representing various areas of medical expertise. Members were not allowedto participate in discussions or to vote on topics relevant to their relations with industry. An update of the 2013 AISGuidelines was originally published in January 2018. This guideline was approved by the AHA Science Advisory andCoordinating Committee and the AHA Executive Committee. In April 2018, a revision to these guidelines, deleting somerecommendations, was published online by the AHA. The writing group was asked review the original document andrevise if appropriate. In June 2018, the writing group submitted a document with minor changes and with inclusion ofimportant newly published randomized controlled trials with >100 participants and clinical outcomes at least 90 days afterAIS. The document was sent to 14 peer reviewers. The writing group evaluated the peer reviewers' comments and revised when appropriate. The current final document was approved by all members of the writing group except when relationshipswith industry precluded members from voting and by the governing bodies of the AHA. These guidelines use the AmericanCollege of Cardiology/AHA 2015 Class of Recommendations and Level of Evidence and the new AHA guidelines format.Results-These guidelines detail prehospital care, urgent and emergency evaluation and treatment with intravenous and intra-arterialtherapies, and in-hospital management, including secondary prevention measures that are appropriately instituted within the first2 weeks. The guidelines support the overarching concept of stroke systems of care in both the prehospital and hospital settings.Conclusions-These guidelines provide general recommendations based on the currently available evidence to guideclinicians caring for adult patients with acute arterial ischemic stroke. In many instances, however, only limited data existdemonstrating the urgent need for continued research on treatment of acute ischemic stroke. 0\n",
      "Artificial intelligence (AI) algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. Historically, in radiology practice, trained physicians visually assessed medical images for the detection, characterization and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. In this Opinion article, we establish a general understanding of AI methods, particularly those pertaining to image-based tasks. We explore how these methods could impact multiple facets of radiology, with a general focus on applications in oncology, and demonstrate ways in which these methods are advancing the field. Finally, we discuss the challenges facing clinical implementation and provide our perspective on how the domain could be advanced. 0\n",
      "Artificial intelligence (AI) is an important technology that supports daily social life and economic activities. It contributes greatly to the sustainable growth of Japan’s economy and solves various social problems. In recent years, AI has attracted attention as a key for growth in developed countries such as Europe and the United States and developing countries such as China and India. The attention has been focused mainly on developing new artificial intelligence information communication technology (ICT) and robot technology (RT). Although recently developed AI technology certainly excels in extracting certain patterns, there are many limitations. Most ICT models are overly dependent on big data, lack a self-idea function, and are complicated. In this paper, rather than merely developing next-generation artificial intelligence technology, we aim to develop a new concept of general-purpose intelligence cognition technology called “Beyond AI”. Specifically, we plan to develop an intelligent learning model called “Brain Intelligence (BI)” that generates new ideas about events without having experienced them by using artificial life with an imagine function. We will also conduct demonstrations of the developed BI intelligence learning model on automatic driving, precision medical care, and industrial robots. 0\n",
      "Artificial Intelligence (AI) is a general term that implies the use of a computer to model intelligent behavior with minimal human intervention. AI is generally accepted as having started with the invention of robots. The term derives from the Czech word robota, meaning biosynthetic machines used as forced labor. In this field, Leonardo Da Vinci's lasting heritage is today's burgeoning use of robotic-assisted surgery, named after him, for complex urologic and gynecologic procedures. Da Vinci's sketchbooks of robots helped set the stage for this innovation. AI, described as the science and engineering of making intelligent machines, was officially born in 1956. The term is applicable to a broad range of items in medicine such as robotics, medical diagnosis, medical statistics, and human biology—up to and including today's “omics”. AI in medicine, which is the focus of this review, has two main branches: virtual and physical. The virtual branch includes informatics approaches from deep learning information management to control of health management systems, including electronic health records, and active guidance of physicians in their treatment decisions. The physical branch is best represented by robots used to assist the elderly patient or the attending surgeon. Also embodied in this branch are targeted nanorobots, a unique new drug delivery system. The societal and ethical complexities of these applications require further reflection, proof of their medical utility, economic value, and development of interdisciplinary strategies for their wider application. 0\n",
      "Artificial intelligence (AI) is gradually changing medical practice. With recent progress in digitized data acquisition, machine learning and computing infrastructure, AI applications are expanding into areas that were previously thought to be only the province of human experts. In this Review Article, we outline recent breakthroughs in AI technologies and their biomedical applications, identify the challenges for further progress in medical AI systems, and summarize the economic, legal and social implications of AI in healthcare. 0\n",
      "Judgement, as one of the core tenets of medicine, relies upon the integration of multilayered data with nuanced decision making. Cancer offers a unique context for medical decisions given not only its variegated forms with evolution of disease but also the need to take into account the individual condition of patients, their ability to receive treatment, and their responses to treatment. Challenges remain in the accurate detection, characterization, and monitoring of cancers despite improved technologies. Radiographic assessment of disease most commonly relies upon visual evaluations, the interpretations of which may be augmented by advanced computational analyses. In particular, artificial intelligence (AI) promises to make great strides in the qualitative interpretation of cancer imaging by expert clinicians, including volumetric delineation of tumors over time, extrapolation of the tumor genotype and biological course from its radiographic phenotype, prediction of clinical outcome, and assessment of the impact of disease and treatment on adjacent organs. AI may automate processes in the initial interpretation of images and shift the clinical workflow of radiographic detection, management decisions on whether or not to administer an intervention, and subsequent observation to a yet to be envisioned paradigm. Here, the authors review the current state of AI as applied to medical imaging of cancer and describe advances in 4 tumor types (lung, brain, breast, and prostate) to illustrate how common clinical problems are being addressed. Although most studies evaluating AI applications in oncology to date have not been vigorously validated for reproducibility and generalizability, the results do highlight increasingly concerted efforts in pushing AI technology to clinical use and to impact future directions in cancer care. 0\n",
      "Sepsis is the third leading cause of death worldwide and the main cause of mortality in hospitals 1–3 , but the best treatment strategy remains uncertain. In particular, evidence suggests that current practices in the administration of intravenous fluids and vasopressors are suboptimal and likely induce harm in a proportion of patients 1,4–6 . To tackle this sequential decision-making problem, we developed a reinforcement learning agent, the Artificial Intelligence (AI) Clinician, which extracted implicit knowledge from an amount of patient data that exceeds by many-fold the life-time experience of human clinicians and learned optimal treatment by analyzing a myriad of (mostly suboptimal) treatment decisions. We demonstrate that the value of the AI Clinician’s selected treatment is on average reliably higher than human clinicians. In a large validation cohort independent of the training data, mortality was lowest in patients for whom clinicians’ actual doses matched the AI decisions. Our model provides individualized and clinically interpretable treatment decisions for sepsis that could improve patient outcomes. 0\n",
      "Background/purpose: The National Health Insurance Research Database, which uses claims data from hospitals contracted with the National Health Insurance (NHI) program in Taiwan, has been widely used for stroke research. The diagnostic accuracy of the NHI claims data with regard to acute ischemic stroke (AIS) has rarely been validated. The aim of this study was to validate the diagnosis of AIS in NHI claims data using the Taiwan Stroke Registry (TSR) as a reference. Methods: We retrieved patients' data with a discharge diagnosis of AIS [five-digit International Classification of Diseases Code, 9th version (ICD-9 code): 433xx or 434xx] in a single medical center from August 2006 to December 2008. We then linked these patients to the TSR to validate their AIS diagnosis in the claims data. The positive predictive value (PPV) and sensitivity were determined. Results: We reviewed the claims data of 1736 consecutive AIS patients, of whom 1299 (74.8%) were linked successfully to the stroke registry database. After reviewing the medical records and imaging results of other patients not linked to the registry database (n=437), 235 patients were found to have had an AIS. The PPV was 88.4% [95% confidence interval (CI): 86.8-89.8%] and sensitivity was 97.3% (95% CI: 96.4-98.1%). Forty-four (21.8%) of the false-positive cases (n = 202) were coded as 433. x0 or 434. x0. Conclusion: The PPV of a diagnosis of AIS in the NHI claims data was high. Using five-digit ICD-9 codes to identify AIS cases will markedly decrease the false-positive rate compared with using the commonly used three-digit method. 0\n",
      "The pandemic of coronavirus disease 2019 (COVID-19) is spreading all over the world. Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists. We hereby review the rapid responses in the community of medical imaging (empowered by AI) toward COVID-19. For example, AI-empowered image acquisition can significantly help automate the scanning procedure and also reshape the workflow with minimal contact to patients, providing the best protection to the imaging technicians. Also, AI can improve work efficiency by accurate delineation of infections in X-ray and CT images, facilitating subsequent quantification. Moreover, the computer-aided platforms help radiologists make clinical decisions, i.e., for disease diagnosis, tracking, and prognosis. In this review paper, we thus cover the entire pipeline of medical imaging and analysis techniques involved with COVID-19, including image acquisition, segmentation, diagnosis, and follow-up. We particularly focus on the integration of AI with X-ray and CT, both of which are widely used in the frontline hospitals, in order to depict the latest progress of medical imaging and radiology fighting against COVID-19. 0\n",
      "Automation with inherent artificial intelligence (AI) is increasingly emerging in diverse applications, for instance, autonomous vehicles and medical assistance devices. However, despite their growing use, there is still noticeable skepticism in society regarding these applications. Drawing an analogy from human social interaction, the concept of trust provides a valid foundation for describing the relationship between humans and automation. Accordingly, this paper explores how firms systematically foster trust regarding applied AI. Based on empirical analysis using nine case studies in the transportation and medical technology industries, our study illustrates the dichotomous constitution of trust in applied AI. Concretely, we emphasize the symbiosis of trust in the technology as well as in the innovating firm and its communication about the technology. In doing so, we provide tangible approaches to increase trust in the technology and illustrate the necessity of a democratic development process for applied AI. 0\n",
      "Objective: The aim of this review was to summarize major topics in artificial intelligence (AI), including their applications and limitations in surgery. This paper reviews the key capabilities of AI to help surgeons understand and critically evaluate new AI applications and to contribute to new developments. Summary Background Data: AI is composed of various subfields that each provide potential solutions to clinical problems. Each of the core subfields of AI reviewed in this piece has also been used in other industries such as the autonomous car, social networks, and deep learning computers. Methods: A review of AI papers across computer science, statistics, and medical sources was conducted to identify key concepts and techniques within AI that are driving innovation across industries, including surgery. Limitations and challenges of working with AI were also reviewed. Results: Four main subfields of AI were defined: (1) machine learning, (2) artificial neural networks, (3) natural language processing, and (4) computer vision. Their current and future applications to surgical practice were introduced, including big data analytics and clinical decision support systems. The implications of AI for surgeons and the role of surgeons in advancing the technology to optimize clinical effectiveness were discussed. Conclusions: Surgeons are well positioned to help integrate AI into modern practice. Surgeons should partner with data scientists to capture data across phases of care and to provide clinical context, for AI has the potential to revolutionize the way surgery is taught and practiced with the promise of a future optimized for the highest quality patient care. 0\n",
      "Worldwide interest in artificial intelligence (AI) applications, including imaging, is high and growing rapidly, fueled by availability of large datasets (“big data”), substantial advances in computing power, and new deep-learning algorithms. Apart from developing new AI methods per se, there are many opportunities and challenges for the imaging community, including the development of a common nomenclature, better ways to share image data, and standards for validating AI program use across different imaging platforms and patient populations. AI surveillance programs may help radiologists prioritize work lists by identifying suspicious or positive cases for early review. AI programs can be used to extract “radiomic” information from images not discernible by visual inspection, potentially increasing the diagnostic and prognostic value derived from image datasets. Predictions have been made that suggest AI will put radiologists out of business. This issue has been overstated, and it is much more likely that radiologists will beneficially incorporate AI methods into their practices. Current limitations in availability of technical expertise and even computing power will be resolved over time and can also be addressed by remote access solutions. Success for AI in imaging will be measured by value created: increased diagnostic certainty, faster turnaround, better outcomes for patients, and better quality of work life for radiologists. AI offers a new and promising set of methods for analyzing image data. Radiologists will explore these new pathways and are likely to play a leading role in medical applications of AI. 0\n",
      "Computer science advances and ultra-fast computing speeds find artificial intelligence (AI) broadly benefitting modern society—forecasting weather, recognizing faces, detecting fraud, and deciphering genomics. AI's future role in medical practice remains an unanswered question. Machines (computers) learn to detect patterns not decipherable using biostatistics by processing massive datasets (big data) through layered mathematical models (algorithms). Correcting algorithm mistakes (training) adds to AI predictive model confidence. AI is being successfully applied for image analysis in radiology, pathology, and dermatology, with diagnostic speed exceeding, and accuracy paralleling, medical experts. While diagnostic confidence never reaches 100%, combining machines plus physicians reliably enhances system performance. Cognitive programs are impacting medical practice by applying natural language processing to read the rapidly expanding scientific literature and collate years of diverse electronic medical records. In this and other ways, AI may optimize the care trajectory of chronic disease patients, suggest precision therapies for complex illnesses, reduce medical errors, and improve subject enrollment into clinical trials. 0\n",
      "In the past decade, advances in precision oncology have resulted in an increased demand for predictive assays that enable the selection and stratification of patients for treatment. The enormous divergence of signalling and transcriptional networks mediating the crosstalk between cancer, stromal and immune cells complicates the development of functionally relevant biomarkers based on a single gene or protein. However, the result of these complex processes can be uniquely captured in the morphometric features of stained tissue specimens. The possibility of digitizing whole-slide images of tissue has led to the advent of artificial intelligence (AI) and machine learning tools in digital pathology, which enable mining of subvisual morphometric phenotypes and might, ultimately, improve patient management. In this Perspective, we critically evaluate various AI-based computational approaches for digital pathology, focusing on deep neural networks and ‘hand-crafted’ feature-based methodologies. We aim to provide a broad framework for incorporating AI and machine learning tools into clinical oncology, with an emphasis on biomarker development. We discuss some of the challenges relating to the use of AI, including the need for well-curated validation datasets, regulatory approval and fair reimbursement strategies. Finally, we present potential future opportunities for precision oncology. 0\n",
      "Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal. 0\n",
      "With the popularization of the Internet, permeation of sensor networks, emergence of big data, increase in size of the information community, and interlinking and fusion of data and information throughout human society, physical space, and cyberspace, the information environment related to the current development of artificial intelligence (AI) has profoundly changed. AI faces important adjustments, and scientific foundations are confronted with new breakthroughs, as AI enters a new stage: AI 2.0. This paper briefly reviews the 60-year developmental history of AI, analyzes the external environment promoting the formation of AI 2.0 along with changes in goals, and describes both the beginning of the technology and the core idea behind AI 2.0 development. Furthermore, based on combined social demands and the information environment that exists in relation to Chinese development, suggestions on the development of AI 2.0 are given. 0\n",
      "One of the most promising areas of health innovation is the application of artificial intelligence (AI), primarily in medical imaging. This article provides basic definitions of terms such as “machine/deep learning” and analyses the integration of AI into radiology. Publications on AI have drastically increased from about 100–150 per year in 2007–2008 to 700–800 per year in 2016–2017. Magnetic resonance imaging and computed tomography collectively account for more than 50% of current articles. Neuroradiology appears in about one-third of the papers, followed by musculoskeletal, cardiovascular, breast, urogenital, lung/thorax, and abdomen, each representing 6–9% of articles. With an irreversible increase in the amount of data and the possibility to use AI to identify findings either detectable or not by the human eye, radiology is now moving from a subjective perceptual skill to a more objective science. Radiologists, who were on the forefront of the digital era in medicine, can guide the introduction of AI into healthcare. Yet, they will not be replaced because radiology includes communication of diagnosis, consideration of patient’s values and preferences, medical judgment, quality assurance, education, policy-making, and interventional procedures. The higher efficiency provided by AI will allow radiologists to perform more value-added tasks, becoming more visible to patients and playing a vital role in multidisciplinary clinical teams. 0\n",
      "Artificial intelligence (AI) is rapidly moving from an experimental phase to an implementation phase in many fields, including medicine. The combination of improved availability of large datasets, increasing computing power, and advances in learning algorithms has created major performance breakthroughs in the development of AI applications. In the last 5 years, AI techniques known as deep learning have delivered rapidly improving performance in image recognition, caption generation, and speech recognition. Radiology, in particular, is a prime candidate for early adoption of these techniques. It is anticipated that the implementation of AI in radiology over the next decade will significantly improve the quality, value, and depth of radiology's contribution to patient care and population health, and will revolutionize radiologists' workflows. The Canadian Association of Radiologists (CAR) is the national voice of radiology committed to promoting the highest standards in patient-centered imaging, lifelong learning, and research. The CAR has created an AI working group with the mandate to discuss and deliberate on practice, policy, and patient care issues related to the introduction and implementation of AI in imaging. This white paper provides recommendations for the CAR derived from deliberations between members of the AI working group. This white paper on AI in radiology will inform CAR members and policymakers on key terminology, educational needs of members, research and development, partnerships, potential clinical applications, implementation, structure and governance, role of radiologists, and potential impact of AI on radiology in Canada. 0\n",
      "Background and objective: During the recent global urgency, scientists, clinicians, and healthcare experts around the globe keep on searching for a new technology to support in tackling the Covid-19 pandemic. The evidence of Machine Learning (ML) and Artificial Intelligence (AI) application on the previous epidemic encourage researchers by giving a new angle to fight against the novel Coronavirus outbreak. This paper aims to comprehensively review the role of AI and ML as one significant method in the arena of screening, predicting, forecasting, contact tracing, and drug development for SARS-CoV-2 and its related epidemic. Method: A selective assessment of information on the research article was executed on the databases related to the application of ML and AI technology on Covid-19. Rapid and critical analysis of the three crucial parameters, i.e., abstract, methodology, and the conclusion was done to relate to the model's possibilities for tackling the SARS-CoV-2 epidemic. Result: This paper addresses on recent studies that apply ML and AI technology towards augmenting the researchers on multiple angles. It also addresses a few errors and challenges while using such algorithms in real-world problems. The paper also discusses suggestions conveying researchers on model design, medical experts, and policymakers in the current situation while tackling the Covid-19 pandemic and ahead. Conclusion: The ongoing development in AI and ML has significantly improved treatment, medication, screening, prediction, forecasting, contact tracing, and drug/vaccine development process for the Covid-19 pandemic and reduce the human intervention in medical practice. However, most of the models are not deployed enough to show their real-world operation, but they are still up to the mark to tackle the SARS-CoV-2 epidemic. 0\n",
      "Introduction: Immunotherapy is regarded as one of the major breakthroughs in cancer treatment. Despite its success, only a subset of patients responds - urging the quest for predictive biomarkers. We hypothesize that artificial intelligence (AI) algorithms can automatically quantify radiographic characteristics that are related to and may therefore act as noninvasive radiomic biomarkers for immunotherapy response. Patients and methods: In this study, we analyzed 1055 primary and metastatic lesions from 203 patients with advanced melanoma and non-small-cell lung cancer (NSCLC) undergoing anti-PD1 therapy. We carried out an AI-based characterization of each lesion on the pretreatment contrast-enhanced CT imaging data to develop and validate a noninvasive machine learning biomarker capable of distinguishing between immunotherapy responding and nonresponding. To define the biological basis of the radiographic biomarker, we carried out gene set enrichment analysis in an independent dataset of 262 NSCLC patients. Results: The biomarker reached significant performance on NSCLC lesions (up to 0.83 AUC, P < 0.001) and borderline significant for melanoma lymph nodes (0.64 AUC, P = 0.05). Combining these lesion-wide predictions on a patient level, immunotherapy response could be predicted with an AUC of up to 0.76 for both cancer types (P < 0.001), resulting in a 1-year survival difference of 24% (P = 0.02). We found highly significant associations with pathways involved in mitosis, indicating a relationship between increased proliferative potential and preferential response to immunotherapy. Conclusions: These results indicate that radiographic characteristics of lesions on standard-of-care imaging may function as noninvasive biomarkers for response to immunotherapy, and may show utility for improved patient stratification in both neoadjuvant and palliative settings. 0\n",
      "The novel coronavirus (COVID-19) outbreak, which was identified in late 2019, requires special attention because of its future epidemics and possible global threats. Beside clinical procedures and treatments, since Artificial Intelligence (AI) promises a new paradigm for healthcare, several different AI tools that are built upon Machine Learning (ML) algorithms are employed for analyzing data and decision-making processes. This means that AI-driven tools help identify COVID-19 outbreaks as well as forecast their nature of spread across the globe. However, unlike other healthcare issues, for COVID-19, to detect COVID-19, AI-driven tools are expected to have active learning-based cross-population train/test models that employs multitudinal and multimodal data, which is the primary purpose of the paper. 0\n",
      "Background: Breast cancer oncologists are challenged to personalize care with rapidly changing scientific evidence, drug approvals, and treatment guidelines. Artificial intelligence (AI) clinical decision-support systems (CDSSs) have the potential to help address this challenge. We report here the results of examining the level of agreement (concordance) between treatment recommendations made by the AI CDSS Watson for Oncology (WFO) and a multidisciplinary tumor board for breast cancer. Patients and methods: Treatment recommendations were provided for 638 breast cancers between 2014 and 2016 at the Manipal Comprehensive Cancer Center, Bengaluru, India. WFO provided treatment recommendations for the identical cases in 2016. A blinded second review was carried out by the center's tumor board in 2016 for all cases in which there was not agreement, to account for treatments and guidelines not available before 2016. Treatment recommendations were considered concordant if the tumor board recommendations were designated 'recommended' or 'for consideration' by WFO. Results: Treatment concordance between WFO and the multidisciplinary tumor board occurred in 93% of breast cancer cases. Subgroup analysis found that patients with stage I or IV disease were less likely to be concordant than patients with stage II or III disease. Increasing age was found to have a major impact on concordance. Concordance declined significantly (P≤0.02; P<0.001) in all age groups compared with patients<45 years of age, except for the age group 55-64 years. Receptor status was not found to affect concordance. Conclusion: Treatment recommendations made by WFO and the tumor board were highly concordant for breast cancer cases examined. Breast cancer stage and patient age had significant influence on concordance, while receptor status alone did not. This study demonstrates that the AI clinical decision-support system WFO may be a helpful tool for breast cancer treatment decision making, especially at centers where expert breast cancer resources are limited. 0\n",
      "Artificial intelligence (AI) is revolutionizing healthcare, but little is known about consumer receptivity to AI in medicine. Consumers are reluctant to utilize healthcare provided by AI in real and hypothetical choices, separate and joint evaluations. Consumers are less likely to utilize healthcare (study 1), exhibit lower reservation prices for healthcare (study 2), are less sensitive to differences in provider performance (studies 3A-3C), and derive negative utility if a provider is automated rather than human (study 4). Uniqueness neglect, a concern that AI providers are less able than human providers to account for consumers' unique characteristics and circumstances, drives consumer resistance to medical AI. Indeed, resistance to medical AI is stronger for consumers who perceive themselves to be more unique (study 5). Uniqueness neglect mediates resistance to medical AI (study 6), and is eliminated when AI provides care (a) that is framed as personalized (study 7), (b) to consumers other than the self (study 8), or (c) that only supports, rather than replaces, a decision made by a human healthcare provider (study 9). These findings make contributions to the psychology of automation and medical decision making, and suggest interventions to increase consumer acceptance of AI in medicine. 0\n",
      "Purpose: Tumors are continuously evolving biological systems, and medical imaging is uniquely positioned to monitor changes throughout treatment. Although qualitatively tracking lesions over space and time may be trivial, the development of clinically relevant, automated radiomics methods that incorporate serial imaging data is far more challenging. In this study, we evaluated deep learning networks for predicting clinical outcomes through analyzing time series CT images of patients with locally advanced non–small cell lung cancer (NSCLC). Experimental Design: Dataset A consists of 179 patients with stage III NSCLC treated with definitive chemoradiation, with pretreatment and posttreatment CT images at 1, 3, and 6 months follow-up (581 scans). Models were developed using transfer learning of convolutional neural networks (CNN) with recurrent neural networks (RNN), using single seed-point tumor localization. Pathologic response validation was performed on dataset B, comprising 89 patients with NSCLC treated with chemoradiation and surgery (178 scans). Results: Deep learning models using time series scans were significantly predictive of survival and cancer-specific outcomes (progression, distant metastases, and local-regional recurrence). Model performance was enhanced with each additional follow-up scan into the CNN model (e.g., 2-year overall survival: AUC ¼ 0.74, P < 0.05). The models stratified patients into low and high mortality risk groups, which were significantly associated with overall survival [HR ¼ 6.16; 95% confidence interval (CI), 2.17–17.44; P < 0.001]. The model also significantly predicted pathologic response in dataset B (P ¼ 0.016). Conclusions: We demonstrate that deep learning can integrate imaging scans at multiple timepoints to improve clinical outcome predictions. AI-based noninvasive radiomics biomarkers can have a significant impact in the clinic given their low cost and minimal requirements for human input. 0\n",
      "Artificial intelligence (AI) has transformed key aspects of human life. Machine learning (ML), which is a subset of AI wherein machines autonomously acquire information by extracting patterns from large databases, has been increasingly used within the medical community, and specifically within the domain of cardiovascular diseases. In this review, we present a brief overview of ML methodologies that are used for the construction of inferential and predictive data-driven models. We highlight several domains of ML application such as echocardiography, electrocardiography, and recently developed non-invasive imaging modalities such as coronary artery calcium scoring and coronary computed tomography angiography. We conclude by reviewing the limitations associated with contemporary application of ML algorithms within the cardiovascular disease field. 0\n",
      "To evaluate the performance of an artificial intelligence (AI) tool using a deep learning algorithm for detecting hemorrhage, mass effect, or hydrocephalus (HMH) at non-contrast material-enhanced head computed tomographic (CT) examinations and to determine algorithm performance for detection of suspected acute infarct (SAI). Materials and Methods: This HIPAA-compliant retrospective study was completed after institutional review board approval. A training and validation dataset of noncontrast-enhanced head CT examinations that comprised 100 examinations of HMH, 22 of SAI, and 124 of noncritical findings was obtained resulting in 2583 representative images. Examinations were processed by using a convolutional neural network (deep learning) using two different window and level configurations (brain window and stroke window). AI algorithm performance was tested on a separate dataset containing 50 examinations with HMH findings, 15 with SAI findings, and 35 with noncritical findings. Results: Final algorithm performance for HMH showed 90% (45 of 50) sensitivity (95% confidence interval [CI]: 78%, 97%) and 85% (68 of 80) specificity (95% CI: 76%, 92%), with area under the receiver operating characteristic curve (AUC) of 0.91 with the brain window. For SAI, the best performance was achieved with the stroke window showing 62% (13 of 21) sensitivity (95% CI: 38%, 82%) and 96% (27 of 28) specificity (95% CI: 82%, 100%), with AUC of 0.81. Conclusion: AI using deep learning demonstrates promise for detecting critical findings at noncontrast-enhanced head CT. A dedicated algorithm was required to detect SAI. Detection of SAI showed lower sensitivity in comparison to detection of HMH, but showed reasonable performance. Findings support further investigation of the algorithm in a controlled and prospective clinical setting to determine whether it can independently screen noncontrast-enhanced head CT examinations and notify the interpreting radiologist of critical findings. 0\n",
      "Background Several guidelines have been reported for bone-directed treatment in women with early breast cancer (EBC) for averting fractures, particularly during aromatase inhibitor (AI) therapy. Recently, a number of studies on additional fracture related risk factors, new treatment options as well as real world studies demonstrating a much higher fracture rate than suggested by randomized clinical controlled trials (RCTs). Therefore, this updated algorithm was developed to better assess fracture risk and direct treatment as a position statement of several interdisciplinary cancer and bone societies involved in the management of AI-associated bone loss (AIBL). Patients and methods A systematic literature review identified recent advances in the management of AIBL. Results with individual agents were assessed based on trial design, size, follow-up, and safety. Results Several fracture related risk factors in patients with EBC were identified. Although, the FRAX algorithm includes fracture risk factors (RF) in addition to BMD, it does not seem to adequately address the effects of AIBL. Several antiresorptive agents can prevent and treat AIBL. However, concerns regarding compliance and long-term safety remain. Overall, the evidence for fracture prevention is strongest for denosumab 60 mg s.c. every 6 months. Additionally, recent studies as well as an individual patient data meta-analysis of all available randomized trial data support additional anticancer benefits from adjuvant bisphosphonate treatment in postmenopausal women with a 34% relative risk reduction in bone metastasis and 17% relative risk decrease in breast cancer mortality that needs to be taken into account when advising on management of AIBL. Conclusions In all patients initiating AI treatment, fracture risk should be assessed and recommendation with regard to exercise and calcium/vitamin D supplementation given. Bone-directed therapy should be given to all patients with a T-score<−2.0 or with a T-score of <–1.5 SD with one additional RF, or with ≥2 risk factors (without BMD) for the duration of AI treatment. Patients with T-score>−1.5 SD and no risk factors should be managed based on BMD loss during the first year and the local guidelines for postmenopausal osteoporosis. Compliance should be regularly assessed as well as BMD on treatment after 12 - 24 months. Furthermore, because of the decreased incidence of bone recurrence and breast cancer specific mortality, adjuvant bisphosphonates are recommended for all postmenopausal women at significant risk of disease recurrence. 0\n",
      "Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%, 97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic where disease burden and need for preventive measures are at odds with available resources. 0\n",
      "Numerous bacteria utilize molecular communication systems referred to as quorum sensing (QS) to synchronize the expression of certain genes regulating, among other aspects, the expression of virulence factors and the synthesis of biofilm. To achieve this process, bacteria use signaling molecules, known as autoinducers (AIs), as chemical messengers to share information. Naturally occurring strategies that interfere with bacterial signaling have been extensively studied in recent years, examining their potential to control bacteria. To interfere with QS, bacteria use quorum sensing inhibitors (QSIs) to block the action of AIs and quorum quenching (QQ) enzymes to degrade signaling molecules. Recent studies have shown that these strategies are promising routes to decrease bacterial pathogenicity and decrease biofilms, potentially enhancing bacterial susceptibility to antimicrobial agents including antibiotics and bacteriophages. The efficacy of QSIs and QQ enzymes has been demonstrated in various animal models and are now considered in the development of new medical devices against bacterial infections, including dressings, and catheters for enlarging the therapeutic arsenal against bacteria. 0\n",
      "Background and purpose: Endovascular techniques are frequently employed to treat large artery occlusion in acute ischemic stroke (AIS). We sought to determine the predictors and clinical impact of intracranial hemorrhage (ICH) after endovascular therapy. 0\n",
      "Objective: To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images. Materials and Methods: PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals Results: Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals. Conclusion: Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms. 0\n",
      "Purpose: The Radiological Society of North America (RSNA) Pediatric Bone Age Machine Learning Challenge was created to show an application of machine learning (ML) and artificial intelligence (AI) in medical imaging, promote collaboration to catalyze AI model creation, and identify innovators in medical imaging. Materials and Methods: The goal of this challenge was to solicit individuals and teams to create an algorithm or model using ML techniques that would accurately determine skeletal age in a curated data set of pediatric hand radiographs. The primary evaluation measure was the mean absolute distance (MAD) in months, which was calculated as the mean of the absolute values of the difference between the model estimates and those of the reference standard, bone age. Results: A data set consisting of 14 236 hand radiographs (12 611 training set, 1425 validation set, 200 test set) was made available to registered challenge participants. A total of 260 individuals or teams registered on the Challenge website. A total of 105 submissions were uploaded from 48 unique users during the training, validation, and test phases. Almost all methods used deep neural network techniques based on one or more convolutional neural networks (CNNs). The best five results based on MAD were 4.2, 4.4, 4.4, 4.5, and 4.5 months, respectively. Conclusion: The RSNA Pediatric Bone Age Machine Learning Challenge showed how a coordinated approach to solving a medical imaging problem can be successfully conducted. Future ML challenges will catalyze collaboration and development of ML tools and methods that can potentially improve diagnostic accuracy and patient care. 0\n",
      "Objective: To determine patient and hospital characteristics associated with not providing IV tissue plasminogen activator (tPA) to eligible patients with acute ischemic stroke (AIS) in clinical practice. Methods: We performed a retrospective cohort study of patients with AIS arriving within 2 hours of onset to hospitals participating in Get With The Guidelines-Stroke without documented contraindications to IV tPA from April 2003 through December 2011, comparing those who received tPA to those who did not. Multivariable generalized estimating equation logistic regression modeling identified factors associated with not receiving tPA. Results: Of 61,698 eligible patients with AIS presenting within 2 hours of onset (median age 73 years, 51% female, 74% non-Hispanic white, median NIH Stroke Scale score 11, interquartile range 6-18), 15,282 (25%) were not treated with tPA within 3 hours. Failure to give tPA decreased over time from 55% in 2003 to 2005 to 18% in 2010 to 2011 (p < 0.0001). After adjustment for all covariates, including stroke severity, factors associated with failure to treat included older age, female sex, nonwhite race, diabetes mellitus, prior stroke, atrial fibrillation, prosthetic heart valve, NIH Stroke Scale score <5, arrival off-hours and not via emergency medical services, longer onset-to-arrival and door-to-CT times, earlier calendar year, and arrival at rural, nonteaching, non-stroke center hospitals located in the South or Midwest. Conclusions: Overall, about one-quarter of eligible patients with AIS presenting within 2 hours of stroke onset failed to receive tPA treatment. Thrombolysis has improved dramatically over time and is strongly associated with stroke center certification. Additionally, some groups, including older patients, milder strokes, women, and minorities, may be undertreated. 0\n",
      "Immunocompromised patients are at high risk of invasive fungal infections (IFI), in particular those with haematological malignancies undergoing remission-induction chemotherapy for acute myeloid leukaemia (AML) or myelodysplastic syndrome (MDS) and recipients of allogeneic haematopoietic stem cell transplants (HSCT). Despite the development of new treatment options in the past decades, IFI remains a concern due to substantial morbidity and mortality in these patient populations. In addition, the increasing use of new immune modulating drugs in cancer therapy has opened an entirely new spectrum of at risk periods. Since the last edition of antifungal prophylaxis recommendations of the German Society for Haematology and Medical Oncology in 2014, seven clinical trials regarding antifungal prophylaxis in patients with haematological malignancies have been published, comprising 1227 patients. This update assesses the impact of this additional evidence and effective revisions. Our key recommendations are the following: prophylaxis should be performed with posaconazole delayed release tablets during remission induction chemotherapy for AML and MDS (AI). Posaconazole iv can be used when the oral route is contraindicated or not feasible. Intravenous liposomal amphotericin B did not significantly decrease IFI rates in acute lymphoblastic leukaemia (ALL) patients during induction chemotherapy, and there is poor evidence to recommend it for prophylaxis in these patients (CI). Despite substantial risk of IFI, we cannot provide a stronger recommendation for these patients. There is poor evidence regarding voriconazole prophylaxis in patients with neutropenia (CII). Therapeutic drug monitoring TDM should be performed within 2 to 5 days of initiating voriconazole prophylaxis and should be repeated in case of suspicious adverse events or of dose changes of interacting drugs (BIItu). General TDM during posaconazole prophylaxis is not recommended (CIItu), but may be helpful in cases of clinical failure such as breakthrough IFI for verification of compliance or absorption. 0\n",
      "Driverless cars with artificial intelligence (AI) and automated supermarkets run by collaborative robots (cobots) working without human supervision have sparked off new debates: what will be the impacts of extreme automation, turbocharged by the Internet of Things (IoT), AI, and the Industry 4.0, on Big Data and omics implementation science? The IoT builds on (1) broadband wireless internet connectivity, (2) miniaturized sensors embedded in animate and inanimate objects ranging from the house cat to the milk carton in your smart fridge, and (3) AI and cobots making sense of Big Data collected by sensors. Industry 4.0 is a high-tech strategy for manufacturing automation that employs the IoT, thus creating the Smart Factory. Extreme automation until \"everything is connected to everything else\" poses, however, vulnerabilities that have been little considered to date. First, highly integrated systems are vulnerable to systemic risks such as total network collapse in the event of failure of one of its parts, for example, by hacking or Internet viruses that can fully invade integrated systems. Second, extreme connectivity creates new social and political power structures. If left unchecked, they might lead to authoritarian governance by one person in total control of network power, directly or through her/his connected surrogates. We propose Industry 5.0 that can democratize knowledge coproduction from Big Data, building on the new concept of symmetrical innovation. Industry 5.0 utilizes IoT, but differs from predecessor automation systems by having three-dimensional (3D) symmetry in innovation ecosystem design: (1) a built-in safe exit strategy in case of demise of hyperconnected entrenched digital knowledge networks. Importantly, such safe exists are orthogonal - in that they allow \"digital detox\" by employing pathways unrelated/unaffected by automated networks, for example, electronic patient records versus material/article trails on vital medical information; (2) equal emphasis on both acceleration and deceleration of innovation if diminishing returns become apparent; and (3) next generation social science and humanities (SSH) research for global governance of emerging technologies: \"Post-ELSI Technology Evaluation Research\" (PETER). Importantly, PETER considers the technology opportunity costs, ethics, ethics-of-ethics, framings (epistemology), independence, and reflexivity of SSH research in technology policymaking. Industry 5.0 is poised to harness extreme automation and Big Data with safety, innovative technology policy, and responsible implementation science, enabled by 3D symmetry in innovation ecosystem design. 0\n",
      "Purpose: Disease staging involves the assessment of disease severity or progression and is used for treatment selection. In diabetic retinopathy, disease staging using a wide area is more desirable than that using a limited area. We investigated if deep learning artificial intelligence (AI) could be used to grade diabetic retinopathy and determine treatment and prognosis. Methods: The retrospective study analyzed 9,939 posterior pole photographs of 2,740 patients with diabetes. Nonmydriatic 45 field color fundus photographs were taken of four fields in each eye annually at Jichi Medical University between May 2011 and June 2015. A modified fully randomly initialized GoogLeNet deep learning neural network was trained on 95% of the photographs using manual modified Davis grading of three additional adjacent photographs. We graded 4,709 of the 9,939 posterior pole fundus photographs using real prognoses. In addition, 95% of the photographs were learned by the modified GoogLeNet. Main outcome measures were prevalence and bias-adjusted Fleiss’ kappa (PABAK) of AI staging of the remaining 5% of the photographs. Results: The PABAK to modified Davis grading was 0.64 (accuracy, 81%; correct answer in 402 of 496 photographs). The PABAK to real prognosis grading was 0.37 (accuracy, 96%). Conclusions: We propose a novel AI disease-staging system for grading diabetic retinopathy that involves a retinal area not typically visualized on fundoscopy and another AI that directly suggests treatments and determines prognoses. 0\n",
      "Abstract: Worldwide interest in artificial intelligence (AI) applications is growing rapidly. In medicine, devices based on machine/deep learning have proliferated, especially for image analysis, presaging new significant challenges for the utility of AI in healthcare. This inevitably raises numerous legal and ethical questions. In this paper we analyse the state of AI regulation in the context of medical device development, and strategies to make AI applications safe and useful in the future. We analyse the legal framework regulating medical devices and data protection in Europe and in the United States, assessing developments that are currently taking place. The European Union (EU) is reforming these fields with new legislation (General Data Protection Regulation [GDPR], Cybersecurity Directive, Medical Devices Regulation, In Vitro Diagnostic Medical Device Regulation). This reform is gradual, but it has now made its first impact, with the GDPR and the Cybersecurity Directive having taken effect in May, 2018. As regards the United States (U.S.), the regulatory scene is predominantly controlled by the Food and Drug Administration. This paper considers issues of accountability, both legal and ethical. The processes of medical device decision-making are largely unpredictable, therefore holding the creators accountable for it clearly raises concerns. There is a lot that can be done in order to regulate AI applications. If this is done properly and timely, the potentiality of AI based technology, in radiology as well as in other fields, will be invaluable. Teaching Points: • AI applications are medical devices supporting detection/diagnosis, work-flow, cost-effectiveness. • Regulations for safety, privacy protection, and ethical use of sensitive information are needed. • EU and U.S. have different approaches for approving and regulating new medical devices. • EU laws consider cyberattacks, incidents (notification and minimisation), and service continuity. • U.S. laws ask for opt-in data processing and use as well as for clear consumer consent. 0\n",
      "Future of clinical development is on the verge of a major transformation due to convergence of large new digital data sources, computing power to identify clinically meaningful patterns in the data using efficient artificial intelligence and machine-learning algorithms, and regulators embracing this change through new collaborations. This perspective summarizes insights, recent developments, and recommendations for infusing actionable computational evidence into clinical development and health care from academy, biotechnology industry, nonprofit foundations, regulators, and technology corporations. Analysis and learning from publically available biomedical and clinical trial data sets, real-world evidence from sensors, and health records by machine-learning architectures are discussed. Strategies for modernizing the clinical development process by integration of AI- and ML-based digital methods and secure computing technologies through recently announced regulatory pathways at the United States Food and Drug Administration are outlined. We conclude by discussing applications and impact of digital algorithmic evidence to improve medical care for patients. 0\n",
      "The advent of Deep Learning (DL) is poised to dramatically change the delivery of healthcare in the near future. Not only has DL profoundly affected the healthcare industry it has also influenced global businesses. Within a span of very few years, advances such as self-driving cars, robots performing jobs that are hazardous to human, and chat bots talking with human operators have proved that DL has already made large impact on our lives. The open source nature of DL and decreasing prices of computer hardware will further propel such changes. In healthcare, the potential is immense due to the need to automate the processes and evolve error free paradigms. The sheer quantum of DL publications in healthcare has surpassed other domains growing at a very fast pace, particular in radiology. It is therefore imperative for the radiologists to learn about DL and how it differs from other approaches of Artificial Intelligence (AI). The next generation of radiology will see a significant role of DL and will likely serve as the base for augmented radiology (AR). Better clinical judgement by AR will help in improving the quality of life and help in life saving decisions, while lowering healthcare costs. A comprehensive review of DL as well as its implications upon the healthcare is presented in this review. We had analysed 150 articles of DL in healthcare domain from PubMed, Google Scholar, and IEEE EXPLORE focused in medical imagery only. We have further examined the ethic, moral and legal issues surrounding the use of DL in medical imaging. 0\n",
      "Background and Purpose - Published cohorts of children with arterial ischemic stroke (AIS) in the 1990s to early 2000s reported 5-year cumulative recurrence rates approaching 20%. Since then, utilization of antithrombotic agents for secondary stroke prevention in children has increased. We sought to determine rates and predictors of recurrent stroke in the current era. Methods - The Vascular Effects of Infection in Pediatric Stroke (VIPS) study enrolled 355 children with AIS at 37 international centers from 2009 to 2014 and followed them prospectively for recurrent stroke. Index and recurrent strokes underwent central review and confirmation, as well as central classification of causes of stroke, including arteriopathies. Other predictors were measured via parental interview or chart review. Results - Of the 355 children, 354 survived their acute index stroke, and 308 (87%) were treated with an antithrombotic medication. During a median follow-up of 2.0 years (interquartile range, 1.0-3.0), 40 children had a recurrent AIS, and none had a hemorrhagic stroke. The cumulative stroke recurrence rate was 6.8% (95% confidence interval, 4.6%-10%) at 1 month and 12% (8.5%-15%) at 1 year. The sole predictor of recurrence was the presence of an arteriopathy, which increased the risk of recurrence 5-fold when compared with an idiopathic AIS (hazard ratio, 5.0; 95% confidence interval, 1.8-14). The 1-year recurrence rate was 32% (95% confidence interval, 18%-51%) for moyamoya, 25% (12%-48%) for transient cerebral arteriopathy, and 19% (8.5%-40%) for arterial dissection. Conclusions - Children with AIS, particularly those with arteriopathy, remain at high risk for recurrent AIS despite increased utilization of antithrombotic agents. Therapies directed at the arteriopathies themselves are needed. 0\n",
      "COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19's spread in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to 5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning (DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs), Extreme Learning Machine (ELM), and Long/Short Term Memory (LSTM). It delineates an integrated bioinformatics approach in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers. The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of the COVID-19 disease. The most recent related publications and medical reports were investigated with the purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs for each platform, including various forms of the data, such as clinical data and medical imaging which can improve the performance of the introduced approaches toward the best responses in practical applications. 0\n",
      "Artificial intelligence (AI) is emerging as a technology with the power to transform established industries, and with applications from automated manufacturing to advertising and facial recognition to fully autonomous transportation. Advances in each of these domains have led some to call AI the “fourth” industrial revolution [1]. In healthcare, AI is emerging as both a productive and disruptive force across many disciplines. This is perhaps most evident in Diagnostic Radiology and Pathology, specialties largely built around the processing and complex interpretation of medical images, where the role of AI is increasingly seen as both a boon and a threat. In Radiation Oncology as well, AI seems poised to reshape the specialty in significant ways, though the impact of AI has been relatively limited at present, and may rightly seem more distant to many, given the predominantly interpersonal and complex interventional nature of the specialty. In this overview, we will explore the current state and anticipated future impact of AI on Radiation Oncology, in detail, focusing on key topics from multiple stakeholder perspectives, as well as the role our specialty may play in helping to shape the future of AI within the larger spectrum of medicine. 0\n",
      "Objective To summarize the current literature regarding the initial hospital management of patients with acute ischemic stroke (AIS) secondary to emergent large vessel occlusion (ELVO), and to offer recommendations designed to decrease the time to endovascular treatment (EVT) for appropriately selected patients with stroke. Methods Using guidelines for evidenced-based medicine proposed by the Stroke Council of the American Heart Association, a critical review of all available medical literature supporting best initial medical management of patients with AIS secondary to ELVO was performed. The purpose was to identify processes of care that most expeditiously determine the eligibility of a patient with an acute stroke for interventions including intravenous fibrinolysis with recombinant tissue plasminogen activator (IV tPA) and EVT using mechanical embolectomy. Results This review identifies four elements that are required to achieve timely revascularization in ELVO. (1) In addition to non-contrast CT (NCCT) brain scan, CT angiography should be performed in all patients who meet an institutional threshold for clinical stroke severity. The use of any advanced imaging beyond NCCT should not delay the administration of IV tPA in eligible patients. (2) Activation of the neurointerventional team should occur as soon as possible, based on either confirmation of large vessel occlusion or a prespecified clinical severity threshold. (3) Additional imaging techniques, particularly those intended to physiologically select patients for EVT (CT perfusion and diffusion-perfusion mismatch imaging), may provide additional value, but should not delay EVT. (4) Routine use of general anesthesia during EVT procedures, should be avoided if possible. These workflow recommendations apply to both primary and comprehensive stroke centers and should be tailored to meet the needs of individual institutions. Conclusions Patients with ELVO are at risk for severe neurologic morbidity and mortality. To achieve the best possible clinical outcomes stroke centers must optimize their triage strategies. Strategies that provide patients with ELVO with the fastest access to reperfusion depend upon detail-oriented process improvement. 0\n",
      "Artificial intelligence (AI) — the ability of a machine to perform cognitive tasks to achieve a particular goal based on provided data — is revolutionizing and reshaping our health-care systems. The current availability of ever-increasing computational power, highly developed pattern recognition algorithms and advanced image processing software working at very high speeds has led to the emergence of computer-based systems that are trained to perform complex tasks in bioinformatics, medical imaging and medical robotics. Accessibility to ‘big data’ enables the ‘cognitive’ computer to scan billions of bits of unstructured information, extract the relevant information and recognize complex patterns with increasing confidence. Computer-based decision-support systems based on machine learning (ML) have the potential to revolutionize medicine by performing complex tasks that are currently assigned to specialists to improve diagnostic accuracy, increase efficiency of throughputs, improve clinical workflow, decrease human resource costs and improve treatment choices. These characteristics could be especially helpful in the management of prostate cancer, with growing applications in diagnostic imaging, surgical interventions, skills training and assessment, digital pathology and genomics. Medicine must adapt to this changing world, and urologists, oncologists, radiologists and pathologists, as high-volume users of imaging and pathology, need to understand this burgeoning science and acknowledge that the development of highly accurate AI-based decision-support applications of ML will require collaboration between data scientists, computer researchers and engineers. 0\n",
      "Objectives: To assess undergraduate medical students’ attitudes towards artificial intelligence (AI) in radiology and medicine. Materials and methods: A web-based questionnaire was designed using SurveyMonkey, and was sent out to students at three major medical schools. It consisted of various sections aiming to evaluate the students’ prior knowledge of AI in radiology and beyond, as well as their attitude towards AI in radiology specifically and in medicine in general. Respondents’ anonymity was ensured. Results: A total of 263 students (166 female, 94 male, median age 23 years) responded to the questionnaire. Around 52% were aware of the ongoing discussion about AI in radiology and 68% stated that they were unaware of the technologies involved. Respondents agreed that AI could potentially detect pathologies in radiological examinations (83%) but felt that AI would not be able to establish a definite diagnosis (56%). The majority agreed that AI will revolutionise and improve radiology (77% and 86%), while disagreeing with statements that human radiologists will be replaced (83%). Over two-thirds agreed on the need for AI to be included in medical training (71%). In sub-group analyses male and tech-savvy respondents were more confident on the benefits of AI and less fearful of these technologies. Conclusion: Contrary to anecdotes published in the media, undergraduate medical students do not worry that AI will replace human radiologists, and are aware of the potential applications and implications of AI on radiology and medicine. Radiology should take the lead in educating students about these emerging technologies. Key Points: • Medical students are aware of the potential applications and implications of AI in radiology and medicine in general. • Medical students do not worry that the human radiologist or physician will be replaced. • Artificial intelligence should be included in medical training. 0\n",
      "Background Clip closure of large colorectal mucosal defects may reduce the rate of adverse events in a cost-effective manner. Objective To assess the adverse events and outcomes of clip closure of defects after endoscopic resection in patients with large colorectal tumors. Design Prospective, randomized, controlled study. Setting Single tertiary referral center. Patients and Interventions Patients with lesions measuring 1 to 4 cm who were scheduled for endoscopic resection between March 2012 and December 2014 were randomly assigned to a clip-closure group and a no-closure group. In the clip-closure group, the defect of the resection site was completely closed with an endoclip. In the no-closure group, the defect was left open. The following primary outcome measures were assessed: delayed postoperative bleeding, postpolypectomy coagulation syndrome, perforation, and abdominal pain. Secondary outcome measures of length of hospital stay, time required for procedure, and patient's satisfaction were also assessed. Results Patients and lesions had similar characteristics across both groups. For patients who underwent clip closure (n = 174), the rates of delayed postoperative bleeding (1.1% [2/174]) and postpolypectomy coagulation syndrome (0.6% [1/174]) were lower than those in the no-closure group (6.9% [12/174], P =.01 and 4.6% [8/174], P =.03). Two patients experienced perforation, 1 in each group. In the clip-closure group, 4 patients reported abdominal pain as opposed to 26 in the no-closure group (2.8% vs 16.7%, P <.01). The procedure took longer in the closure group (38.1 minutes vs 30.9 minutes, P =.04). The length of hospitalization was shorter in the closure group (3.1 days vs 4.7 days, P =.03). Total medical expense was similar between the 2 groups. Patients who underwent closure reported greater satisfaction. Limitation This was a single-center analysis. Conclusions Clip closure of endoscopic resection defects in patients with large colorectal tumors decreased the rate of procedure-related adverse events and did not increase the cost of hospitalization. 0\n",
      "A retrospective study to evaluate the effectiveness of 3-dimensional rapid prototyping (3DRP) technology in corrective surgery for Lenke 1 adolescent idiopathic scoliosis (AIS) patients. 3DRP technology has been widely used in medical field; however, no study has been performed on the effectiveness of 3DRP technology in corrective surgery for Lenke 1 AIS patients. Lenke 1 AIS patients who were preparing to undergo posterior corrective surgery from a single center between January 2010 and January 2012 were included in this analysis. Patients were divided into 2 groups. In group A, 3-dimensional (3D) printing technology was used to create subject-specific spine models in the preoperative planning process. Group B underwent posterior corrective surgery as usual (by free hand without image guidance). Perioperative and postoperative clinical outcomes were compared between 2 groups, including operation time, perioperative blood loss, transfusion volume, postoperative hemoglobin (Hb), postoperative complications, and length of hospital stay. Radiological outcomes were also compared, including the assessment of screw placement, postoperative Cobb angle, coronal balance, sagittal vertical axis, thoracic kyphosis, and lumbar lordosis. Subgroup was also performed according to the preoperative Cobb angle: mean Cobb angle <50° and mean Cobb angle >50°. Besides, economic evaluation was also compared between 2 groups. A total of 126 patients were included in this study (group A, 50 and group B, 76). Group A had significantly shorter operation time, significantly less blood loss and transfusion volume, and higher postoperative Hb (all, P<0.001). However, no significant differences were observed in complication rate, length of hospital stay, and postoperative radiological outcomes between 2 groups (all, P>0.05). There was also no significant difference in misplacement of screws in total populations (16.90% vs 18.82%, P=0.305), whereas a low misplacement rate of pedicle screws was observed in patients whose mean Cobb angle was >50° (9.15% vs 13.03%, P=0.02). Besides, using 3DRP increased the economic burden of patients (157,000±9948.85Ren Min Bi (RMB) vs 152,500±11,445.52RMB, P=0.03). Using the 3D printing technology before posterior corrective surgery might reduce the operation time, perioperative blood loss, and transfusion volume. There did not appear to be a benefit to using this technology with respect to complication rate and postoperative radiological outcomes; however, 3D technology could reduce the misplacement rate in patients whose preoperative mean Cobb angle was >50°. Besides, it also increased the patients' hospital cost. Therefore, future prospective studies are needed to elucidate the efficacy of this emerging technology. 0\n",
      "Purpose: To report the incidence of cancer in a cohort of adolescent idiopathic scoliosis (AIS) patients treated 25 years previously. Methods: 215 consecutive AIS patients treated between 1983 and 1990 were identified and requested to return for clinical and radiographic examination. The incidence of cancer was determined through chart review and follow-up interviews. Using the original radiographic log file that included patient position, mAs, kV and the total number of X-rays taken, a radiation physicist calculated the total radiation dose during treatment and follow-up adjusted for BMI and sex. Results: From the original cohort of 215 consecutive AIS patients, radiation information was available in 211 of the patients, and medical charts were available in 209 AIS patients. 170 (83 %) of the 205 AIS patients participated in the follow-up study with questionnaires. The calculated mean total radiation exposure was 0.8–1.4 mSV per examination and 2.4–5.6 mSv/year. An average of 16 radiographs were taken during the treatment period. Nine AIS patients developed cancer, mostly breast (3) and endometrial (4). The AIS patients had a relative risk of 4.8 (CI 2.3–5.8, p < 0.000) for developing cancer compared to the normal Danish population. Conclusions: The overall cancer rate in this AIS cohort was 4.3 % which is five times higher than compared to the age-matched Danish population, and endometrial and breast cancer was most frequent. The radiation dose applied to the patients in this study, is comparable to modern equipment. This is to our knowledge the first study to report increased rates of endometrial cancers in a cohort of AIS patients, and future attention is needed to reduce the radiation dose distributed to the AIS patients both pre-operatively and during surgery. 0\n",
      "OBJECT: Previous studies that have evaluated the prognostic value of abnormal changes in signals on T2-weighted MRI scans of an injured spinal cord have focused on the longitudinal extent of this signal abnormality in the sagittal plane. Although the transverse extent of injury and the degree of spared spinal cord white matter have been shown to be important for predicting outcomes in preclinical animal models of spinal cord injury (SCI), surprisingly little is known about the prognostic value of altered T2 relaxivity in humans in the axial plane. METHODS: The authors undertook a retrospective chart review of 60 patients who met the inclusion criteria of this study and presented to the authors' Level I trauma center with an acute blunt traumatic cervical SCI. Within 48 hours of admission, all patients underwent MRI examination, which included axial and sagittal T2 images. Neurological symptoms, evaluated with the grades according to the American Spinal Injury Association (ASIA) Impairment Scale (AIS), at the time of admission and at hospital discharge were correlated with MRI findings. Five distinct patterns of intramedullary spinal cord T2 signal abnormality were defined in the axial plane at the injury epicenter. These patterns were assigned ordinal values ranging from 0 to 4, referred to as the Brain and Spinal Injury Center (BASIC) scores, which encompassed the spectrum of SCI severity. RESULTS: The BASIC score strongly correlated with neurological symptoms at the time of both hospital admission and discharge. It also distinguished patients initially presenting with complete injury who improved by at least one AIS grade by the time of discharge from those whose injury did not improve. The authors' proposed score was rapid to apply and showed excellent interrater reliability. CONCLUSIONS: The authors describe a novel 5-point ordinal MRI score for classifying acute SCIs on the basis of axial T2-weighted imaging. The proposed BASIC score stratifies the SCIs according to the extent of transverse T2 signal abnormality during the acute phase of the injury. The new score improves on current MRI-based prognostic descriptions for SCI by reflecting functionally and anatomically significant patterns of intramedullary T2 signal abnormality in the axial plane. 0\n",
      "Aim Frail individuals may be at higher risk of death from a given acute illness severity (AIS), but this relationship has not been studied in an English National Health Service (NHS) acute hospital setting. Methods This was a retrospective observational study in a large university NHS hospital in England. We analyzed all first non-elective inpatient episodes of people aged ≥ 75 years (all specialties) between October 2014 and October 2015. Pre-admission frailty was assessed with the Clinical Frailty Scale (CFS) of the Canadian Study on Health & Aging, and AIS in the Emergency Department was measured with a Modified Early Warning Score (ED-MEWS < 4 was considered as low acuity, and ED-MEWS ≥ 4 as high acuity). A survival analysis compared times to 30-day inpatient death between CFS categories (1–4: very fit to vulnerable, 5: mildly frail, 6: moderately frail, and 7–8: severely or very severely frail). Results There were 12,282 non-elective patient episodes (8202 first episodes, of which complete data was available for 5505). In a Cox proportional hazards model controlling for age, gender, Charlson Comorbidity Index, history of dementia, current cognitive concern, and discharging specialty (medical versus surgical), ED-MEWS ≥ 4 (HR = 2.87, 95% CI: 2.27–3.62, p < 0.001), and CFS 7–8 (compared to CFS 1–4, HR = 2.10, 95% CI: 1.52–2.92, p < 0.001) were independent predictors of survival time. Conclusions We found frailty and AIS independently associated with inpatient mortality after adjustment for confounders. Hospitals may find it informative to undertake large scale assessment of frailty (vulnerability), as well as AIS (stressor), in older patients admitted to hospital as emergencies. 0\n",
      "Human-machine interfaces (HMIs) experience increasing requirements for intuitive and effective manipulation. Current commercialized solutions of glove-based HMI are limited by either detectable motions or the huge cost on fabrication, energy, and computing power. We propose the haptic-feedback smart glove with triboelectric-based finger bending sensors, palm sliding sensor, and piezoelectric mechanical stimulators. The detection of multidirectional bending and sliding events is demonstrated in virtual space using the self-generated triboelectric signals for various degrees of freedom on human hand. We also perform haptic mechanical stimulation via piezoelectric chips to realize the augmented HMI. The smart glove achieves object recognition using machine learning technique, with an accuracy of 96%. Through the integrated demonstration of multidimensional manipulation, haptic feedback, and AI-based object recognition, our glove reveals its potential as a promising solution for low-cost and advanced human-machine interaction, which can benefit diversified areas, including entertainment, home healthcare, sports training, and medical industry. 0\n",
      "Drug discovery and development are among the most important translational science activities that contribute to human health and wellbeing. However, the development of a new drug is a very complex, expensive, and long process which typically costs 2.6 billion USD and takes 12 years on average. How to decrease the costs and speed up new drug discovery has become a challenging and urgent question in industry. Artificial intelligence (AI) combined with new experimental technologies is expected to make the hunt for new pharmaceuticals quicker, cheaper, and more effective. We discuss here emerging applications of AI to improve the drug discovery process. 0\n",
      "Background: Recreational marijuana use is considered to have few adverse effects. However, recent evidence has suggested that it precipitates cardiovascular and cerebrovascular events. Here, we investigated the relationship between marijuana use and hospitalization for acute ischemic stroke (AIS) using data from the largest inpatient database in the United States. Methods: The Nationwide Inpatient Sample was queried from 2004 to 2011 for all patients (age 15-54) with a primary diagnosis of AIS. The incidence of AIS hospitalization in marijuana users and non-marijuana users was determined. We utilized multivariable logistic regression analyses to study the independent association between marijuana use and AIS. Results: Overall, the incidence of AIS was significantly greater among marijuana users compared to non-users (Relative Risk [RR]: 1.13, 95% CI: 1.11-1.15, P < 0.0001) and had the greatest difference in the 25-34 age group (RR: 2.26, 95% CI: 2.13-2.38, P < 0.0001). Marijuana use was more prevalent among younger patients, males, African Americans, and Medicaid enrollees (P < 0.0001). Marijuana users were more likely to use other illicit substances but had less overall medical comorbidity. In multivariable analysis, adjusted for potential confounders, marijuana (Odds Ratio [OR]: 1.17, 95% CI: 1.15-1.20), tobacco (OR: 1.76, 95% CI: 1.74-1.77), cocaine (OR: 1.32, 95% CI: 1.30-1.34), and amphetamine (OR: 2.21, 95% CI: 2.12-2.30) usage were found to increase the likelihood of AIS (all P < 0.0001). Conclusion: Among younger adults, recreational marijuana use is independently associated with 17% increased likelihood of AIS hospitalization. 0\n",
      "Flexible/stretchable electronic devices and systems are attracting great attention because they can have important applications in many areas, such as artificial intelligent (AI) robotics, brain–machine interfaces, medical devices, structural and environmental monitoring, and healthcare. In addition to the electronic performance, the electronic devices and systems should be mechanically flexible or even stretchable. Traditional electronic materials including metals and semiconductors usually have poor mechanical flexibility and very limited elasticity. Three main strategies are adopted for the development of flexible/stretchable electronic materials. One is to use organic or polymeric materials. These materials are flexible, and their elasticity can be improved through chemical modification or composition formation with plasticizers or elastomers. Another strategy is to exploit nanometer-scale materials. Many inorganic materials in nanometer sizes can have high flexibility. They can be stretchable through the composition formation with elastomers. Ionogels can be considered as the third type of materials because they can be stretchable and ionically conductive. This article provides the recent progress of soft functional materials development including intrinsically conductive polymers for flexible/stretchable electrodes, and thermoelectric conversion and polymer composites for large area, flexible stretchable electrodes, and tactile sensors. 0\n",
      "Artificial intelligence (AI) continues to garner substantial interest in medical imaging. The potential applications are vast and include the entirety of the medical imaging life cycle from image creation to diagnosis to outcome prediction. The chief obstacles to development and clinical implementation of AI algorithms include availability of sufficiently large, curated, and representative training data that includes expert labeling (eg, annotations). Current supervised AI methods require a curation process for data to optimally train, validate, and test algorithms. Currently, most research groups and industry have limited data access based on small sample sizes from small geographic areas. In addition, the preparation of data is a costly and time-intensive process, the results of which are algorithms with limited utility and poor generalization. In this article, the authors describe fundamental steps for preparing medical imaging data in AI algorithm development, explain current limitations to data curation, and explore new approaches to address the problem of data availability. 0\n",
      "Life sciences researchers using artificial intelligence (AI) are under pressure to innovate faster than ever. Large, multilevel, and integrated data sets offer the promise of unlocking novel insights and accelerating breakthroughs. Although more data are available than ever, only a fraction is being curated, integrated, understood, and analyzed. AI focuses on how computers learn from data and mimic human thought processes. AI increases learning capacity and provides decision support system at scales that are transforming the future of health care. This article is a review of applications for machine learning in health care with a focus on clinical, translational, and public health applications with an overview of the important role of privacy, data sharing, and genetic information. 0\n",
      "Recent advances in quantitative phase imaging (QPI) and artificial intelligence (AI) have opened up the possibility of an exciting frontier. The fast and label-free nature of QPI enables the rapid generation of large-scale and uniform-quality imaging data in two, three, and four dimensions. Subsequently, the AI-assisted interrogation of QPI data using data-driven machine learning techniques results in a variety of biomedical applications. Also, machine learning enhances QPI itself. Herein, we review the synergy between QPI and machine learning with a particular focus on deep learning. Furthermore, we provide practical guidelines and perspectives for further development. 0\n",
      "Background: Radiographic evaluation for patients with scoliosis using Cobb method is the current gold standard, but radiography has radiation hazards. Several groups have recently demonstrated the feasibility of using 3D ultrasound for the evaluation of scoliosis. Ultrasound imaging is radiation-free, comparatively more accessible, and inexpensive. However, a reliable and valid 3D ultrasound system ready for clinical scoliosis assessment has not yet been reported. Scolioscan is a newly developed system targeted for scoliosis assessment in clinics by using coronal images of spine generated by a 3D ultrasound volume projection imaging method. The aim of this study is to test the reliability of spine deformity measurement of Scolioscan and its validity compared to the gold standard Cobb angle measurements from radiography in adolescent idiopathic scoliosis (AIS) patients. Methods: Prospective study divided into two stages: 1) Investigation of intra- and inter- reliability between two operators for acquiring images using Scolioscan and among three raters for measuring spinal curves from those images; 2) Correlation between the Cobb angle obtained from radiography by a medical doctor and the spine curve angle obtained using Scolioscan (Scolioscan angle). The raters for ultrasound images and the doctors for evaluating radiographic images were mutually blinded. The two stages of tests involved 20 (80 % females, total of 26 angles, age of 16.4 ± 2.7 years, and Cobb angle of 27.6 ± 11.8°) and 49 (69 % female, 73 angles, 15.8 ± 2.7 years and 24.8 ± 9.7°) AIS patients, respectively. Intra-class correlation coefficients (ICC) and Bland-Altman plots and root-mean-square differences (RMS) were employed to determine correlations, which interpreted based on defined criteria. Results: We demonstrated a very good intra-rater and intra-operator reliability for Scolioscan angle measurement with ICC larger than 0.94 and 0.88, respectively. Very good inter-rater and inter-operator reliability was also demonstrated, with both ICC larger than 0.87. For the thoracic deformity measurement, the RMS were 2.5 and 3.3° in the intra- and inter-operator tests, and 1.5 and 3.6° in the intra- and inter-rater tests, respectively. The RMS differences were 3.1, 3.1, 1.6, 3.7° in the intra- and inter-operator and intra- and inter-rater tests, respectively, for the lumbar angle measurement. Moderate to strong correlations (R2 > 0.72) were observed between the Scolioscan angles and Cobb angles for both the thoracic and lumbar regions. It was noted that the Scolioscan angle slightly underestimated the spinal deformity in comparison with Cobb angle, and an overall regression equation y = 1.1797x (R2 = 0.76) could be used to translate the Scolioscan angle (x) to Cobb angle (y) for this group of patients. The RMS difference between Scolioscan angle and Cobb angle was 4.7 and 6.2°, with and without the correlation using the overall regression equation. Conclusions: We showed that Scolioscan is reliable for measuring coronal deformity for patients with AIS and appears promising in screening large numbers of patients, for progress monitoring, and evaluation of treatment outcomes. Due to it being radiation-free and relatively low-cost, Scolioscan has potential to be widely implemented and may contribute to reducing radiation dose during serial monitoring. 0\n",
      "Background: Radical measures are required to identify and reduce blindness due to diabetes to achieve the Sustainable Development Goals by 2030. Therefore, we evaluated the accuracy of an artificial intelligence (AI) model using deep learning in a population-based diabetic retinopathy screening programme in Zambia, a lower-middle-income country. Methods: We adopted an ensemble AI model consisting of a combination of two convolutional neural networks (an adapted VGGNet architecture and a residual neural network architecture) for classifying retinal colour fundus images. We trained our model on 76 370 retinal fundus images from 13 099 patients with diabetes who had participated in the Singapore Integrated Diabetic Retinopathy Program, between 2010 and 2013, which has been published previously. In this clinical validation study, we included all patients with a diagnosis of diabetes that attended a mobile screening unit in five urban centres in the Copperbelt province of Zambia from Feb 1 to June 31, 2012. In our model, referable diabetic retinopathy was defined as moderate non-proliferative diabetic retinopathy or worse, diabetic macular oedema, and ungradable images. Vision-threatening diabetic retinopathy comprised severe non-proliferative and proliferative diabetic retinopathy. We calculated the area under the curve (AUC), sensitivity, and specificity for referable diabetic retinopathy, and sensitivities of vision-threatening diabetic retinopathy and diabetic macular oedema compared with the grading by retinal specialists. We did a multivariate analysis for systemic risk factors and referable diabetic retinopathy between AI and human graders. Findings: A total of 4504 retinal fundus images from 3093 eyes of 1574 Zambians with diabetes were prospectively recruited. Referable diabetic retinopathy was found in 697 (22·5%) eyes, vision-threatening diabetic retinopathy in 171 (5·5%) eyes, and diabetic macular oedema in 249 (8·1%) eyes. The AUC of the AI system for referable diabetic retinopathy was 0·973 (95% CI 0·969–0·978), with corresponding sensitivity of 92·25% (90·10–94·12) and specificity of 89·04% (87·85–90·28). Vision-threatening diabetic retinopathy sensitivity was 99·42% (99·15–99·68) and diabetic macular oedema sensitivity was 97·19% (96·61–97·77). The AI model and human graders showed similar outcomes in referable diabetic retinopathy prevalence detection and systemic risk factors associations. Both the AI model and human graders identified longer duration of diabetes, higher level of glycated haemoglobin, and increased systolic blood pressure as risk factors associated with referable diabetic retinopathy. Interpretation: An AI system shows clinically acceptable performance in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, and diabetic macular oedema in population-based diabetic retinopathy screening. This shows the potential application and adoption of such AI technology in an under-resourced African population to reduce the incidence of preventable blindness, even when the model is trained in a different population. Funding: National Medical Research Council Health Service Research Grant, Large Collaborative Grant, Ministry of Health, Singapore; the SingHealth Foundation; and the Tanoto Foundation. 0\n",
      "Background An adrenal crisis (AC) is a potential life-threatening event in patients with adrenal insufficiency (AI). This study aims to determine the incidence, causes, and risk factors of AC in AI. Methods Patients with AI diagnosed and treated at the University Medical Center Utrecht for the past 30 years were identified, and all medical records were assessed by two independent investigators. The observed frequency of AC was determined as incidence rate, calculated as the number of AC divided by person-years (PY). In addition, precipitating factors and risk factors were assessed. Results We observed an incidence rate of 5·2 AC (95% CI 4·3-6·3) per 100 PY in primary adrenal insufficiency (PAI, a total of 111 patients), and 3·6 AC (95% CI 3·1-4·1) per 100 PY in secondary adrenal insufficiency (SAI a total of 319 patients). Patients with an established diagnosis of tertiary (glucocorticoid-induced) adrenal insufficiency (a total of 28 patients) had 15·1 AC (95% CI 11·0-19·9) per 100 PY. The most important risk factor was the existence of comorbidity. Gastro-enteritis and other infections were the most common precipitating factors for AC. Conclusion AC still occurs relatively frequent in patients with AI, mostly precipitated by infections and particularly in patients with high comorbidity. This should be taken into account in the education and follow-up of patients with AI. 0\n",
      "Purpose: To evaluate the total fluid intake from drinking water and beverages in adult populations from different countries and assess the percentage of individuals complying with the European Food Safety Agency (EFSA) adequate intake (AI) of water from fluids. Methods: A total of 16,276 adults (7580 men and 8696 women) aged between 18 and 70 years (mean age 39.8 years) were randomly recruited from 13 different countries from three continents. Information about the total daily fluid intake (sum of drinking water and beverages) was collected using a 24-h fluid-specific record over seven consecutive days. Results: Important differences in total fluid intake between countries were found; however, few differences between men and women were reported in most of the countries. Less than 50 % of the women and approximately 60 % of the men do not comply with the EFSA AI of water from fluids. Women were more than twice as likely as men to meet these AI (OR 2.15; 95 % CI 2.02–2.29). The odds of meeting the AI of water from fluids were lower in individuals over 50 years (OR 0.88; 95 % CI 0.80–0.96). Nine percent of the total population consumed less than half of the AI, 40.5 % between 50 and 100 %, and 50.5 % more than the AI. Conclusions: There were considerable differences in total fluid intake between countries but not between genders. Only 40 % of men and 60 % of women comply with the EFSA AI of water from fluids. Men and elderly individuals had an increased risk of not complying with this reference value. 0\n",
      "Coronaviruses (CoVs) are a large family of viruses that are common in many animal species, including camels, cattle, cats and bats. Animal CoVs, such as Middle East respiratory syndrome-CoV, severe acute respiratory syndrome (SARS)-CoV, and the new virus named SARS-CoV-2, rarely infect and spread among humans. On January 30, 2020, the International Health Regulations Emergency Committee of the World Health Organisation declared the outbreak of the resulting disease from this new CoV called ‘COVID-19’, as a ‘public health emergency of international concern’. This global pandemic has affected almost the whole planet and caused the death of more than 315,131 patients as of the date of this article. In this context, publishers, journals and researchers are urged to research different domains and stop the spread of this deadly virus. The increasing interest in developing artificial intelligence (AI) applications has addressed several medical problems. However, such applications remain insufficient given the high potential threat posed by this virus to global public health. This systematic review addresses automated AI applications based on data mining and machine learning (ML) algorithms for detecting and diagnosing COVID-19. We aimed to obtain an overview of this critical virus, address the limitations of utilising data mining and ML algorithms, and provide the health sector with the benefits of this technique. We used five databases, namely, IEEE Xplore, Web of Science, PubMed, ScienceDirect and Scopus and performed three sequences of search queries between 2010 and 2020. Accurate exclusion criteria and selection strategy were applied to screen the obtained 1305 articles. Only eight articles were fully evaluated and included in this review, and this number only emphasised the insufficiency of research in this important area. After analysing all included studies, the results were distributed following the year of publication and the commonly used data mining and ML algorithms. The results found in all papers were discussed to find the gaps in all reviewed papers. Characteristics, such as motivations, challenges, limitations, recommendations, case studies, and features and classes used, were analysed in detail. This study reviewed the state-of-the-art techniques for CoV prediction algorithms based on data mining and ML assessment. The reliability and acceptability of extracted information and datasets from implemented technologies in the literature were considered. Findings showed that researchers must proceed with insights they gain, focus on identifying solutions for CoV problems, and introduce new improvements. The growing emphasis on data mining and ML techniques in medical fields can provide the right environment for change and improvement. 0\n",
      "Background: The inability to test at scale has become humanity's Achille's heel in the ongoing war against the COVID-19 pandemic. A scalable screening tool would be a game changer. Building on the prior work on cough-based diagnosis of respiratory diseases, we propose, develop and test an Artificial Intelligence (AI)-powered screening solution for COVID-19 infection that is deployable via a smartphone app. The app, named AI4COVID-19 records and sends three 3-s cough sounds to an AI engine running in the cloud, and returns a result within 2 min. Methods: Cough is a symptom of over thirty non-COVID-19 related medical conditions. This makes the diagnosis of a COVID-19 infection by cough alone an extremely challenging multidisciplinary problem. We address this problem by investigating the distinctness of pathomorphological alterations in the respiratory system induced by COVID-19 infection when compared to other respiratory infections. To overcome the COVID-19 cough training data shortage we exploit transfer learning. To reduce the misdiagnosis risk stemming from the complex dimensionality of the problem, we leverage a multi-pronged mediator centered risk-averse AI architecture. Results: Results show AI4COVID-19 can distinguish among COVID-19 coughs and several types of non-COVID-19 coughs. The accuracy is promising enough to encourage a large-scale collection of labeled cough data to gauge the generalization capability of AI4COVID-19. AI4COVID-19 is not a clinical grade testing tool. Instead, it offers a screening tool deployable anytime, anywhere, by anyone. It can also be a clinical decision assistance tool used to channel clinical-testing and treatment to those who need it the most, thereby saving more lives. 0\n",
      "This article reviews current limitations and future opportunities for the application of computer-aided detection (CAD) systems and artificial intelligence in breast imaging. Traditional CAD systems in mammography screening have followed a rules-based approach, incorporating domain knowledge into hand-crafted features before using classical machine learning techniques as a classifier. The first commercial CAD system, ImageChecker M1000, relies on computer vision techniques for pattern recognition. Unfortunately, CAD systems have been shown to adversely affect some radiologists' performance and increase recall rates. The Digital Mammography DREAM Challenge was a multidisciplinary collaboration that provided 640,000 mammography images for teams to help decrease false-positive rates in breast cancer screening. Winning solutions leveraged deep learning's (DL) automatic hierarchical feature learning capabilities and used convolutional neural networks. Start-ups Therapixel and Kheiron Medical Technologies are using DL for breast cancer screening. With increasing use of digital breast tomosynthesis, specific artificial intelligence (AI)-CAD systems are emerging to include iCAD's PowerLook Tomo Detection and ScreenPoint Medical's Transpara. Other AI-CAD systems are focusing on breast diagnostic techniques such as ultrasound and magnetic resonance imaging (MRI). There is a gap in the market for contrast-enhanced spectral mammography AI-CAD tools. Clinical implementation of AI-CAD tools requires testing in scenarios mimicking real life to prove its usefulness in the clinical environment. This requires a large and representative dataset for testing and assessment of the reader's interaction with the tools. A cost-effectiveness assessment should be undertaken, with a large feasibility study carried out to ensure there are no unintended consequences. AI-CAD systems should incorporate explainable AI in accordance with the European Union General Data Protection Regulation (GDPR). 0\n",
      "Background: Translational research on clot composition may be advanced by the use of clot analogs for the preclinical evaluation of mechanical thrombectomy devices. This work describes a novel set of clot analogs to represent a diverse range of fibrin and red blood cell (RBC) compositions for use in acute ischemic stroke (AIS) occlusion models. Method Fresh whole blood obtained from ovine species was used to create seven different clot analog types. Five replicates were formed for each clot type. Varying amounts of whole blood constituents were mixed with thrombotic factors to create clots of varying compositions. Following histological processing, five sections from each clot were stained with H&E and Martius Scarlet Blue. Fibrin, RBC and white blood cell compositions were quantified. Results: Histological examination demonstrated that the clot types had a distinct RBC and fibrin composition. No significant difference in composition was shown between replicates (p>0.05), indicating that the method of clot formation was reproducible. Percentage fibrin composition of the clot types was 1%, 8%, 31%, 38%, 64%, 79%, and 100%. A significant difference in fibrin and RBC composition between clot types was observed (p<0.05). Conclusions: Seven different clot types were developed to replicate common AIS thrombi. These clot analogs may be beneficial for the preclinical evaluation of endovascular therapies, and may be applied to interventional technique training. 0\n",
      "An artificial intelligence (AI) using a deep-learning approach can classify retinal images from optical coherence tomography for early diagnosis of retinal diseases and has the potential to be used in other image-based medical diagnoses. 0\n",
      "Aims The majority of ventricular tachycardias (VTs) in repaired tetralogy of Fallot (rTOF) are related to anatomically defined isthmuses. We aimed to identify specific electroanatomical characteristics of anatomical isthmuses (AI) related to VT which may allow for individualized risk stratification and tailored ablation. Methods and results Seventy-four consecutive rTOF patients (40±16 years, 63% male) underwent VT induction and right ventricular electroanatomical voltage and activation mapping during sinus rhythm (SR) to identify the presence and characteristics of AI (isthmus width, length and conduction velocity index [CVi]). Twenty-eight patients were inducible for 41 VTs. All 74 patients had at least one AI. However, AI in patients with VT were longer (22±7 vs. 16±7 mm, P = 0.001), narrower (20±8 vs. 28±11 mm, P < 0.001) and had lower CVi (0.36±0.34 vs. 0.78±0.24 m/s, P < 0.001). Thirty-seven VTs in 24 patients were mapped (pace-, entrainment mapping, and/or VT termination by ablation) to 28 AI. All 28 AI related to VT had a CVi , 0.5 m/s (slow conducting AI (SCAI)). In contrast, 87 of 89 AI of the 46 patients without VT had CVi ≥ 0.5 m/s. Sixty-two patients were discharged without the presence of an SCAI (44 had no SCAI at baseline, 18 underwent ablation of the SCAI) and 10 still had an SCAI (no/failed ablation). During follow-up (50±22 months), no patient without SCAI had any VT, which occurred in 5/10 patients with SCAI (P < 0.001). Conclusion In rTOF, slow conducting anatomical isthmuses identified by electroanatomical mapping during SR are the dominant substrate for VT allowing individualized risk stratification and preventive ablation. 0\n",
      "Object Adolescent idiopathic scoliosis (AIS) can cause substantial morbidity and may require surgical intervention. In this study, the authors aimed to evaluate US trends in operative AIS as well as patient comorbidities, operative approach, in-hospital complications, hospital length of stay (LOS), and hospital charges in the US for the period from 1997 to 2012. Methods Patients with AIS (ICD-9-CM diagnosis codes 737.30) who had undergone spinal fusion (ICD-9-CM procedure codes 81.xx) from 1997 to 2012 were identified from the Kids' Inpatient Database. Parameters of interest included patient comorbidities, operative approach (posterior, anterior, or combined anteroposterior), in-hospital complications, hospital LOS, and hospital charges. Results The authors identified 20,346 patients in the age range of 0-21 years who had been admitted for AIS surgery in the defined study period. Posterior fusions composed 63.4% of procedures in 1997 and 94.1% in 2012 (r = 0.95, p < 0.01). The mean number of comorbidities among all fusion groups increased from 3.0 in 1997 to 4.2 in 2012 (r = 0.92, p = 0.01). The percentage of patients with complications increased from 15.6% in 1997 to 22.3% in 2012 (r = 0.78, p = 0.07). The average hospital LOS decreased from 6.5 days in 1997 to 5.6 days in 2012 (r = -0.86, p = 0.03). From 1997 to 2012, the mean hospital charges (adjusted to 2012 US dollars) for surgical treatment of AIS more than tripled from $55,495 in 1997 to $177,176 in 2012 (r = 0.99, p < 0.01). Conclusions Over the 15-year period considered in this study, there was an increasing trend toward using posteriorbased techniques for AIS corrective surgery. The number of comorbid conditions per patient and thus the medical complexity of patients treated for AIS have increased. The mean charges for the treatment of AIS have increased, with a national bill over $1.1 billion per year in 2012. 0\n",
      "Since December 2019, the coronavirus disease (COVID-19) outbreak has caused many death cases and affected all sectors of human life. With gradual progression of time, COVID-19 was declared by the world health organization (WHO) as an outbreak, which has imposed a heavy burden on almost all countries, especially ones with weaker health systems and ones with slow responses. In the field of healthcare, deep learning has been implemented in many applications, e.g., diabetic retinopathy detection, lung nodule classification, fetal localization, and thyroid diagnosis. Numerous sources of medical images (e.g., X-ray, CT, and MRI) make deep learning a great technique to combat the COVID-19 outbreak. Motivated by this fact, a large number of research works have been proposed and developed for the initial months of 2020. In this paper, we first focus on summarizing the state-of-the-art research works related to deep learning applications for COVID-19 medical image processing. Then, we provide an overview of deep learning and its applications to healthcare found in the last decade. Next, three use cases in China, Korea, and Canada are also presented to show deep learning applications for COVID-19 medical image processing. Finally, we discuss several challenges and issues related to deep learning implementations for COVID-19 medical image processing, which are expected to drive further studies in controlling the outbreak and controlling the crisis, which results in smart healthy cities. 0\n",
      "At the beginning of the artificial intelligence (AI)/machine learning (ML) era, the expectations are high, and experts foresee that AI/ML shows potential for diagnosing, managing and treating a wide variety of medical conditions. However, the obstacles for implementation of AI/ML in daily clinical practice are numerous, especially regarding the regulation of these technologies. Therefore, we provide an insight into the currently available AI/ML-based medical devices and algorithms that have been approved by the US Food & Drugs Administration (FDA). We aimed to raise awareness of the importance of regulatory bodies, clearly stating whether a medical device is AI/ML based or not. Cross-checking and validating all approvals, we identified 64 AI/ML based, FDA approved medical devices and algorithms. Out of those, only 29 (45%) mentioned any AI/ML-related expressions in the official FDA announcement. The majority (85.9%) was approved by the FDA with a 510(k) clearance, while 8 (12.5%) received de novo pathway clearance and one (1.6%) premarket approval (PMA) clearance. Most of these technologies, notably 30 (46.9%), 16 (25.0%), and 10 (15.6%) were developed for the fields of Radiology, Cardiology and Internal Medicine/General Practice respectively. We have launched the first comprehensive and open access database of strictly AI/ML-based medical technologies that have been approved by the FDA. The database will be constantly updated. 0\n",
      "Background: The outbreak of coronavirus disease 2019 (COVID-19) has globally strained medical resources and caused significant mortality. Objective: To develop and validate a machine-learning model based on clinical features for severity risk assessment and triage for COVID-19 patients at hospital admission. Method: 725 patients were used to train and validate the model. This included a retrospective cohort from Wuhan, China of 299 hospitalised COVID-19 patients from 23 December 2019 to 13 February 2020, and five cohorts with 426 patients from eight centres in China, Italy and Belgium from 20 February 2020 to 21 March 2020. The main outcome was the onset of severe or critical illness during hospitalisation. Model performances were quantified using the area under the receiver operating characteristic curve (AUC) and metrics derived from the confusion matrix. Results: In the retrospective cohort, the median age was 50 years and 137 (45.8%) were male. In the five test cohorts, the median age was 62 years and 236 (55.4%) were male. The model was prospectively validated on five cohorts yielding AUCs ranging from 0.84 to 0.93, with accuracies ranging from 74.4% to 87.5%, sensitivities ranging from 75.0% to 96.9%, and specificities ranging from 55.0% to 88.0%, most of which performed better than the pneumonia severity index. The cut-off values of the low-, medium- and high-risk probabilities were 0.21 and 0.80. The online calculators can be found at www.covid19risk.ai. Conclusion: The machine-learning model, nomogram and online calculator might be useful to access the onset of severe and critical illness among COVID-19 patients and triage at hospital admission. 0\n",
      "Purpose: The aim of this systematic review was to analyse literature on artificial intelligence (AI) and radiomics, including all medical imaging modalities, for oncological and non-oncological applications, in order to assess how far the image mining research stands from routine medical application. To do this, we applied a trial phases classification inspired from the drug development process. Methods: Among the articles we considered for inclusion from PubMed were multimodality AI and radiomics investigations, with a validation analysis aimed at relevant clinical objectives. Quality assessment of selected papers was performed according to the QUADAS-2 criteria. We developed the phases classification criteria for image mining studies. Results: Overall 34,626 articles were retrieved, 300 were selected applying the inclusion/exclusion criteria, and 171 high-quality papers (QUADAS-2 ≥ 7) were identified and analysed. In 27/171 (16%), 141/171 (82%), and 3/171 (2%) studies the development of an AI-based algorithm, radiomics model, and a combined radiomics/AI approach, respectively, was described. A total of 26/27(96%) and 1/27 (4%) AI studies were classified as phase II and III, respectively. Consequently, 13/141 (9%), 10/141 (7%), 111/141 (79%), and 7/141 (5%) radiomics studies were classified as phase 0, I, II, and III, respectively. All three radiomics/AI studies were categorised as phase II trials. Conclusions: The results of the studies are promising but still not mature enough for image mining tools to be implemented in the clinical setting and be widely used. The transfer learning from the well-known drug development process, with some specific adaptations to the image mining discipline could represent the most effective way for radiomics and AI algorithms to become the standard of care tools. 0\n",
      "Objectives: Minor infection can trigger adult arterial ischemic stroke (AIS) and is common in childhood. We tested the hypotheses that infection transiently increases risk of AIS in children, regardless of stroke subtype, while vaccination against infection is protective. Methods: The Vascular Effects of Infection in Pediatric Stroke study is an international case-control study that prospectively enrolled 355 centrally confirmed cases of AIS (29 days-18 years old) and 354 stroke-free controls. To determine prior exposure to infections and vaccines, we conducted parental interviews and chart review. Results: Median (interquartile range) age was 7.6 years for cases and 9.3 for controls (p 0.44). Infection in the week prior to stroke, or interview date for controls, was reported in 18% of cases, vs 3% of controls, conferring a 6.3-fold increased risk of AIS (p < 0.0001); upper respiratory infections were most common. Prevalence of preceding infection was similar across stroke subtypes: arteriopathic, cardioembolic, and idiopathic. Use of vasoactive cold medications was similarly low in both groups. Children with some/few/no routine vaccinations were at higher stroke risk than those receiving all or most (odds ratio [OR] 7.3, p 0.0002). In an age-adjusted multivariate logistic regression model, independent risk factors for AIS included infection in the prior week (OR 6.3, p < 0.0001), undervaccination (OR 8.2, p 0.0004), black race (compared to white; OR 1.9, p 0.009), and rural residence (compared to urban; OR 3.0, p 0.0003). Conclusions: Infection may act as a trigger for childhood AIS, while routine vaccinations appear protective. Hence, efforts to reduce the spread of common infections might help prevent stroke in children. 0\n",
      "Background: Deep learning (DL) based solutions have been proposed for interpretation of several imaging modalities including radiography, CT, and MR. For chest radiographs, DL algorithms have found success in the evaluation of abnormalities such as lung nodules, pulmonary tuberculosis, cystic fibrosis, pneumoconiosis, and location of peripherally inserted central catheters. Chest radiography represents the most commonly performed radiological test for a multitude of non-emergent and emergent clinical indications. This study aims to assess accuracy of deep learning (DL) algorithm for detection of abnormalities on routine frontal chest radiographs (CXR), and assessment of stability or change in findings over serial radiographs. Methods and findings: We processed 874 de-identified frontal CXR from 724 adult patients (> 18 years) with DL (Qure AI). Scores and prediction statistics from DL were generated and recorded for the presence of pulmonary opacities, pleural effusions, hilar prominence, and enlarged cardiac silhouette. To establish a standard of reference (SOR), two thoracic radiologists assessed all CXR for these abnormalities. Four other radiologists (test radiologists), unaware of SOR and DL findings, independently assessed the presence of radiographic abnormalities. A total 724 radiographs were assessed for detection of findings. A subset of 150 radiographs with follow up examinations was used to asses change over time. Data were analyzed with receiver operating characteristics analyses and post-hoc power analysis. Results: About 42% (305/ 724) CXR had no findings according to SOR; single and multiple abnormalities were seen in 23% (168/724) and 35% (251/724) of CXR. There was no statistical difference between DL and SOR for all abnormalities (p = 0.2-0.8). The area under the curve (AUC) for DL and test radiologists ranged between 0.837-0.929 and 0.693-0.923, respectively. DL had lowest AUC (0.758) for assessing changes in pulmonary opacities over follow up CXR. Presence of chest wall implanted devices negatively affected the accuracy of DL algorithm for evaluation of pulmonary and hilar abnormalities. Conclusions: DL algorithm can aid in interpretation of CXR findings and their stability over follow up CXR. However, in its present version, it is unlikely to replace radiologists due to its limited specificity for categorizing specific findings. 0\n",
      "Background Acute ischemic stroke (AIS) due to emergent large-vessel occlusion (ELVO) has a poor prognosis. Objective To examine the hypothesis that a better collateral score on pretreatment CT angiography (CTA) would correlate with a smaller final infarct volume and a more favorable clinical outcome after endovascular therapy (EVT). Methods A retrospective chart review of the University of Tennessee AIS database from February 2011 to February 2013 was conducted. All patients with CTA-proven LVO treated with EVT were included. Recanalization after EVT was defined by Thrombolysis in Cerebral Infarction (TICI) score ≥2. Favorable outcome was assessed as a modified Rankin Score ≤3. Results Fifty patients with ELVO were studied. The mean National Institutes of Health Stroke Scale score was 17 (2-27) and 38 of the patients (76%) received intravenous tissue plasminogen activator. The recanalization rate for EVT was 86.6%. Good clinical outcome was achieved in 32% of patients. Univariate predictors of good outcome included good collateral scores (CS) on presenting CTA (p=0.043) and successful recanalization (p=0.02). Multivariate analysis confirmed both good CS (p=0.024) and successful recanalization (p=0.009) as predictors of favorable outcome. Applying results of the multivariate analysis to our cohort we were able to determine the likelihood of good clinical outcome as well as predictors of smaller final infarct volume after successful recanalization. Conclusions Good CS predict smaller infarct volumes and better clinical outcome in patients recanalized with EVT. These data support the use of this technique in selecting patients for EVT. Poor CS should be considered as an exclusion criterion for EVT as patients with poor CS have poor clinical outcomes despite recanalization. 0\n",
      "Radiomics is a relatively new word for the field of radiology, meaning the extraction of a high number of quantitative features from medical images. Artificial intelligence (AI) is broadly a set of advanced computational algorithms that basically learn the patterns in the data provided to make predictions on unseen data sets. Radiomics can be coupled with AI because of its better capability of handling a massive amount of data compared with the traditional statistical methods. Together, the primary purpose of these fields is to extract and analyze as much and meaningful hidden quantitative data as possible to be used in decision support. Nowadays, both radiomics and AI have been getting attention for their remarkable success in various radiological tasks, which has been met with anxiety by most of the radiologists due to the fear of replacement by intelligent machines. Considering ever-developing advances in computational power and availability of large data sets, the marriage of humans and machines in future clinical practice seems inevitable. Therefore, regardless of their feelings, the radiologists should be familiar with these concepts. Our goal in this paper was three-fold: first, to familiarize radiologists with the radiomics and AI; second, to encourage the radiologists to get involved in these ever-developing fields; and, third, to provide a set of recommendations for good practice in design and assessment of future works. 0\n",
      "Aim and scope: Artificial intelligence (AI) in medicine is a fast-growing field. The rise of deep learning algorithms, such as convolutional neural networks (CNNs), offers fascinating perspectives for the automation of medical image analysis. In this systematic review article, we screened the current literature and investigated the following question: “Can deep learning algorithms for image recognition improve visual diagnosis in medicine?” Materials and methods: We provide a systematic review of the articles using CNNs for medical image analysis, published in the medical literature before May 2019. Articles were screened based on the following items: type of image analysis approach (detection or classification), algorithm architecture, dataset used, training phase, test, comparison method (with specialists or other), results (accuracy, sensibility and specificity) and conclusion. Results: We identified 352 articles in the PubMed database and excluded 327 items for which performance was not assessed (review articles) or for which tasks other than detection or classification, such as segmentation, were assessed. The 25 included papers were published from 2013 to 2019 and were related to a vast array of medical specialties. Authors were mostly from North America and Asia. Large amounts of qualitative medical images were necessary to train the CNNs, often resulting from international collaboration. The most common CNNs such as AlexNet and GoogleNet, designed for the analysis of natural images, proved their applicability to medical images. Conclusion: CNNs are not replacement solutions for medical doctors, but will contribute to optimize routine tasks and thus have a potential positive impact on our practice. Specialties with a strong visual component such as radiology and pathology will be deeply transformed. Medical practitioners, including surgeons, have a key role to play in the development and implementation of such devices. 0\n",
      "Artificial intelligence (AI) has the potential to ease the human resources crisis in healthcare by facilitating diagnostics, decision-making, big data analytics and administration, among others. For this we must first tackle the technological, ethical and legal obstacles. The human resource crisis is widening worldwide, and it is obvious that it is not possible to provide care without workforce. How can disruptive technologies in healthcare help solve the variety of human resource problems? Will technology empower physicians or replace them? How can the medical curriculum, including post-graduate education prepare professionals for the meaningful use of technology? These questions have been growing for decades, and the promise of disruptive technologies filling them is imminent with digital health becoming widespread. Authors of this essay argue that AI might not only fill the human resources gap, but also raises ethical questions we need to deal with today. While there are even more questions to address, our stand is that AI is not meant to replace caregivers, but those who use AI will probably replace those who don't. And it is possible to prepare for that. 0\n",
      "Background and Purpose-Proximal large vessel occlusion (LVO) is present in up to 30% of minor strokes. The effectiveness of mechanical thrombectomy (MT) in the subgroup of minor stroke with LVO in the anterior circulation is still open to debate. Data about MT in this subgroup of patients are sparse, and their optimal management has not yet been defined. The purpose of this multicenter cohort study was to evaluate the effectiveness of MT in patients experiencing acute ischemic stroke (AIS) because of LVO in the anterior circulation, presenting with minor-to-mild stroke symptoms (National Institutes of Health Stroke Scale score of <8). Methods-Multicenter cohort study involving 4 comprehensive stroke centers having 2 therapeutic approaches (urgent thrombectomy associated with best medical treatment [BMT] versus BMT first and MT if worsening occurs) about management of patients with minor and mild acute ischemic stroke harboring LVO in the anterior circulation. An intentionto- treat analysis was conducted. The primary end point was the rate of excellent outcome defined as the achievement of a modified Rankin Scale score of 0 to 1 at 3 months. Results-Three hundred one patients were included, 170 with urgent MT associated with BMT, and 131 with BMT alone as first-line treatment. Patients treated with MT were younger, more often received intravenous thrombolysis, and had shorter time to imaging. Twenty-four patients (18.0%) in the medical group had rescue MT because of neurological worsening. Overall, excellent outcome was achieved in 64.5% of patients, with no difference between the 2 groups. Stratified analysis according to key subgroups did not find heterogeneity in the treatment effect size. Conclusions-Minor-to-mild stroke patients with LVO achieved excellent and favorable functional outcomes at 3 months in similar proportions between urgent MT versus delayed MT associated with BMT. There is thus an urgent need for randomized trials to define the effectiveness of MT in this patient subgroup. 0\n",
      "Background: As machine learning becomes increasingly common in health care applications, concerns have been raised about bias in these systems' data, algorithms, and recommendations. Simply put, as health care improves for some, it might not improve for all. Methods: Two case studies are examined using a machine learning algorithm on unstructured clinical and psychiatric notes to predict intensive care unit (ICU) mortality and 30-day psychiatric readmission with respect to race, gender, and insurance payer type as a proxy for socioeconomic status. Results: Clinical note topics and psychiatric note topics were heterogenous with respect to race, gender, and insurance payer type, which reflects known clinical findings. Differences in prediction accuracy and therefore machine bias are shown with respect to gender and insurance type for ICU mortality and with respect to insurance policy for psychiatric 30-day readmission. Conclusions: This analysis can provide a framework for assessing and identifying disparate impacts of artificial intelligence in health care. 0\n",
      "This study presents a systematic review of artificial intelligence (AI) techniques used in the detection and classification of coronavirus disease 2019 (COVID-19) medical images in terms of evaluation and benchmarking. Five reliable databases, namely, IEEE Xplore, Web of Science, PubMed, ScienceDirect and Scopus were used to obtain relevant studies of the given topic. Several filtering and scanning stages were performed according to the inclusion/exclusion criteria to screen the 36 studies obtained; however, only 11 studies met the criteria. Taxonomy was performed, and the 11 studies were classified on the basis of two categories, namely, review and research studies. Then, a deep analysis and critical review were performed to highlight the challenges and critical gaps outlined in the academic literature of the given subject. Results showed that no relevant study evaluated and benchmarked AI techniques utilised in classification tasks (i.e. binary, multi-class, multi-labelled and hierarchical classifications) of COVID-19 medical images. In case evaluation and benchmarking will be conducted, three future challenges will be encountered, namely, multiple evaluation criteria within each classification task, trade-off amongst criteria and importance of these criteria. According to the discussed future challenges, the process of evaluation and benchmarking AI techniques used in the classification of COVID-19 medical images considered multi-complex attribute problems. Thus, adopting multi-criteria decision analysis (MCDA) is an essential and effective approach to tackle the problem complexity. Moreover, this study proposes a detailed methodology for the evaluation and benchmarking of AI techniques used in all classification tasks of COVID-19 medical images as future directions; such methodology is presented on the basis of three sequential phases. Firstly, the identification procedure for the construction of four decision matrices, namely, binary, multi-class, multi-labelled and hierarchical, is presented on the basis of the intersection of evaluation criteria of each classification task and AI classification techniques. Secondly, the development of the MCDA approach for benchmarking AI classification techniques is provided on the basis of the integrated analytic hierarchy process and VlseKriterijumska Optimizacija I Kompromisno Resenje methods. Lastly, objective and subjective validation procedures are described to validate the proposed benchmarking solutions. 0\n",
      "Objective: To evaluate sleep disturbances of Chinese frontline medical workers (FMW) under the outbreak of coronavirus disease 2019 (COVID-19), and make a comparison with non-FMW. Methods: The medical workers from multiple hospitals in Hubei Province, China, volunteered to participate in this cross-sectional study. An online questionnaire, including Pittsburgh Sleep Quality Index (PSQI), Athens Insomnia Scale (AIS) and Visual Analogue Scale (VAS), was used to evaluate sleep disturbances and mental status. Sleep disturbances were defined as PSQI>6 points or/and AIS>6 points. We compared the scores of PSQI, AIS, anxiety and depression VAS, as well as prevalence of sleep disturbances between FMW and non-FMW. Results: A total of 1306 subjects (801 FMW and 505 non-FMW) were enrolled. Compared to non-FMW, FMW had significantly higher scores of PSQI (9.3 ± 3.8 vs 7.5 ± 3.7; P < 0.001; Cohen's d = 0.47), AIS (6.9 ± 4.3 vs 5.3 ± 3.8; P < 0.001; Cohen's d = 0.38), anxiety (4.9 ± 2.7 vs 4.3 ± 2.6; P < 0.001; Cohen's d = 0.22) and depression (4.1 ± 2.5 vs 3.6 ± 2.4; P = 0.001; Cohen's d = 0.21), as well as higher prevalence of sleep disturbances according to PSQI > 6 points (78.4% vs 61.0%; relative risk [RR] = 1.29; P < 0.001) and AIS > 6 points (51.7% vs 35.6%; RR = 1.45; P < 0.001). Conclusion: FMW have higher prevalence of sleep disturbances and worse sleep quality than non-FMW. Further interventions should be administrated for FMW, aiming to maintain their healthy condition and guarantee their professional performance in the battle against COVID-19. 0\n",
      "Background: Polycystic ovary syndrome (PCOS) is the most common cause of infrequent periods (oligomenorrhoea) and absence of periods (amenorrhoea). It affects about 4% to 8% of women worldwide and often leads to anovulatory subfertility. Aromatase inhibitors (AIs) are a class of drugs that were introduced for ovulation induction in 2001. Since about 2001 clinical trials have reached differing conclusions as to whether the AI letrozole is at least as effective as the first-line treatment clomiphene citrate (CC). Objectives: To evaluate the effectiveness and safety of aromatase inhibitors for subfertile women with anovulatory PCOS for ovulation induction followed by timed intercourse or intrauterine insemination (IUI). Search methods: We searched the following sources from inception to November 2017 to identify relevant randomised controlled trials (RCTs): the Cochrane Gynaecology and Fertility Group Specialised Register, the Cochrane Central Register of Controlled Trials, MEDLINE, Embase, PsycINFO, Pubmed, LILACS, Web of Knowledge, the World Health Organization (WHO) clinical trials register and Clinicaltrials.gov. We also searched the references of relevant articles. We did not restrict the searches by language or publication status. Selection criteria: We included all RCTs of AIs used alone or with other medical therapies for ovulation induction in women of reproductive age with anovulatory PCOS. Data collection and analysis: Two review authors independently selected trials, extracted the data and assessed risks of bias. We pooled studies where appropriate using a fixed-effect model to calculate odds ratios (ORs) and 95% confidence intervals (CIs) for most outcomes, and risk differences (RDs) for ovarian hyperstimulation syndrome (OHSS). The primary outcomes were live birth and OHSS. Secondary outcomes were clinical pregnancy, miscarriage and multiple pregnancy. We assessed the quality of the evidence for each comparison using GRADE methods. Main results: This is a substantive update of a previous review. We identified 16 additional studies for the 2018 update. We include 42 RCTs (7935 women). The aromatase inhibitor letrozole was used in all studies. Letrozole compared to clomiphene citrate (CC) with or without adjuncts followed by timed intercourse Live birth rates were higher with letrozole (with or without adjuncts) compared to clomiphene citrate (with our without adjuncts) followed by timed intercourse (OR 1.68, 95% CI 1.42 to 1.99; 2954 participants; 13 studies; I2 = 0%; number needed to treat for an additional beneficial outcome (NNTB) = 10; moderate-quality evidence). There is high-quality evidence that OHSS rates are similar with letrozole or clomiphene citrate (0.5% in both arms: risk difference (RD) -0.00, 95% CI -0.01 to 0.00; 2536 participants; 12 studies; I2 = 0%; high-quality evidence). There is evidence for a higher pregnancy rate in favour of letrozole (OR 1.56, 95% CI 1.37 to 1.78; 4629 participants; 25 studies; I2 = 1%; NNTB = 10; moderate-quality evidence). There is little or no difference between treatment groups in the rate of miscarriage by pregnancy (20% with CC versus 19% with letrozole; OR 0.94, 95% CI 0.70 to 1.26; 1210 participants; 18 studies; I2 = 0%; high-quality evidence) and multiple pregnancy rate (1.7% with CC versus 1.3% with letrozole; OR 0.69, 95% CI 0.41 to 1.16; 3579 participants; 17 studies; I2 = 0%; high-quality evidence). However, a funnel plot showed mild asymmetry, indicating that some studies in favour of clomiphene might be missing. Letrozole compared to laparoscopic ovarian drilling There is low-quality evidence that live birth rates are similar with letrozole or laparoscopic ovarian drilling (OR 1.38, 95% CI 0.95 to 2.02; 548 participants; 3 studies; I2 = 23%; low-quality evidence). There is insufficient evidence for a difference in OHSS rates (RD 0.00, 95% CI -0.01 to 0.01; 260 participants; 1 study; low-quality evidence). There is low-quality evidence that pregnancy rates are similar (OR 1.28, 95% CI 0.94 to 1.74; 774 participants; 5 studies; I2 = 0%; moderate-quality evidence). There is insufficient evidence for a difference in miscarriage rate by pregnancy (OR 0.66, 95% CI 0.30 to 1.43; 240 participants; 5 studies; I2 = 0%; moderate-quality evidence), or multiple pregnancies (OR 3.00, 95% CI 0.12 to 74.90; 548 participants; 3 studies; I2 = 0%; low-quality evidence). Additional comparisons were made for Letrozole versus placebo, Selective oestrogen receptor modulators (SERMS) followed by intrauterine insemination (IUI), follicle stimulating hormone (FSH), Anastrozole, as well as dosage and administration protocols. There is insufficient evidence for a difference in either group of treatment due to a limited number of studies. Hence more research is necessary. Authors' conclusions: Letrozole appears to improve live birth and pregnancy rates in subfertile women with anovulatory polycystic ovary syndrome, compared to clomiphene citrate. There is high-quality evidence that OHSS rates are similar with letrozole or clomiphene citrate. There is high-quality evidence of no difference in miscarriage rates or multiple pregnancy rates. There is low-quality evidence of no difference in live birth and pregnancy rates between letrozole and laparoscopic ovarian drilling, although there were few relevant studies. For the 2018 update, we added good-quality trials, upgrading the quality of the evidence. 0\n",
      "Objective: To analyze relations among injury, demographic, and environmental factors on function, health-related quality of life (HRQoL), and life satisfaction in individuals with traumatic spinal cord injury (SCI). Design: Prospective observational registry cohort study. Setting: Specialized acute and rehabilitation SCI centers. Participants: Participants (N=340) from the Rick Hansen Spinal Cord Injury Registry (RHSCIR) who were prospectively recruited from 2004 to 2014 were included. The model cohort participants were 79.1% men, with a mean age of 41.6±17.3 years. Of the participants, 34.7% were motor/sensory complete (ASIA Impairment Scale [AIS] grade A). Interventions: None. Main Outcome Measures: Path analysis was used to determine relations among SCI severity (AIS grade and anatomic level [cervical/thoracolumbar]), age at injury, education, number of health conditions, functional independence (FIM motor score), HRQoL (Medical Outcomes Study 36-Item Short-Form Health Survey [Version 2] Physical Component Score [PCS] and Mental Component Score [MCS]), and life satisfaction (Life Satisfaction-11 [LiSat-11]). Model fit was assessed using recommended published indices. Results: Goodness of fit of the model was supported by all indices, indicating the model results closely matched the RHSCIR data. Higher age, higher severity injuries, cervical injuries, and more health conditions negatively affected FIM motor score, whereas employment had a positive effect. Higher age, less education, more severe injuries (AIS grades A–C), and more health conditions negatively correlated with PCS (worse physical health). More health conditions were negatively correlated with a lower MCS (worse mental health), however were positively associated with reduced function. Being married and having higher function positively affected Lisat-11, but more health conditions had a negative effect. Conclusions: Complex interactions and enduring effects of health conditions after SCI have a negative effect on function, HRQoL, and life satisfaction. Modeling relations among these types of concepts will inform clinicians how to positively effect outcomes after SCI (eg, development of screening tools and protocols for managing individuals with traumatic SCI who have multiple health conditions). 0\n",
      "Dowling-Degos disease (DDD) is an autosomal-dominant disorder of skin pigmentation associated with mutations in keratin 5 (KRT5), protein O-fucosyltransferase 1 (POFUT1), or protein O-glucosyltransferase 1 (POGLUT1). Here, we have identified 6 heterozygous truncating mutations in PSENEN, encoding presenilin enhancer protein 2, in 6 unrelated patients and families with DDD in whom mutations in KRT5, POFUT1, and POGLUT1 have been excluded. Further examination revealed that the histopathologic feature of follicular hyperkeratosis distinguished these 6 patients from previously studied individuals with DDD. Knockdown of psenen in zebrafish larvae resulted in a phenotype with scattered pigmentation that mimicked human DDD. In the developing zebrafish larvae, in vivo monitoring of pigment cells suggested that disturbances in melanocyte migration and differentiation underlie the DDD pathogenesis associated with PSENEN. Six of the PSENEN mutation carriers presented with comorbid acne inversa (AI), an inflammatory hair follicle disorder, and had a history of nicotine abuse and/or obesity, which are known trigger factors for AI. Previously, PSENEN mutations were identified in familial AI, and comanifestation of DDD and AI has been reported for decades. The present work suggests that PSENEN mutations can indeed cause a comanifestation of DDD and AI that is likely triggered by predisposing factors for AI. Thus, the present report describes a DDD subphenotype in PSENEN mutation carriers that is associated with increased susceptibility to AI. 0\n",
      "Artificial intelligence (AI) and nanotechnology are two fields that are instrumental in realizing the goal of precision medicine—tailoring the best treatment for each cancer patient. Recent conversion between these two fields is enabling better patient data acquisition and improved design of nanomaterials for precision cancer medicine. Diagnostic nanomaterials are used to assemble a patient-specific disease profile, which is then leveraged, through a set of therapeutic nanotechnologies, to improve the treatment outcome. However, high intratumor and interpatient heterogeneities make the rational design of diagnostic and therapeutic platforms, and analysis of their output, extremely difficult. Integration of AI approaches can bridge this gap, using pattern analysis and classification algorithms for improved diagnostic and therapeutic accuracy. Nanomedicine design also benefits from the application of AI, by optimizing material properties according to predicted interactions with the target drug, biological fluids, immune system, vasculature, and cell membranes, all affecting therapeutic efficacy. Here, fundamental concepts in AI are described and the contributions and promise of nanotechnology coupled with AI to the future of precision cancer medicine are reviewed. 0\n",
      "Triple-negative breast cancer (TNBC) is the most complex and aggressive type of breast cancer encountered world widely in women. Absence of hormonal receptors on breast cancer cells necessitates the chemotherapy as the only treatment regime. High propensity to metastasize and relapse in addition to poor prognosis and survival motivated the oncologist, nano-medical scientist to develop novel and efficient nanotherapies to solve such a big TNBC challenge. Recently, the focus for enhanced availability, targeted cellular uptake with minimal toxicity is achieved by nano-carriers. These smart nano-carriers carrying all the necessary arsenals (drugs, tracking probe, and ligand) designed in such a way that specifically targets the TNBC cells at site. Articulating the targeted delivery system with multifunctional molecules for high specificity, tracking, diagnosis, and treatment emerged as theranostic approach. In this review, in addition to classical treatment modalities, recent advances in nanotheranostics for early and effective diagnostic and treatment is discussed. This review highlighted the recently FDA approved immunotherapy and all the ongoing clinical trials for TNBC, in addition to nanoparticle assisted immunotherapy. Futuristic but realistic advancements in artificial intelligence (AI) and machine learning not only improve early diagnosis but also assist clinicians for their workup in TNBC. The novel concept of Nanoparticles induced endothelial leakiness (NanoEL) as a way of tumor invasion is also discussed in addition to classical EPR effect. This review intends to provide basic insight and understanding of the novel nano-therapeutic modalities in TNBC diagnosis and treatment and to sensitize the readers for continue designing the novel nanomedicine. This is the first time that designing nanoparticles with stoichiometric definable number of antibodies per nanoparticle now represents the next level of precision by design in nanomedicine. 0\n",
      "Purpose: Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology. Materials and Methods: A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality. Results: Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry. Conclusion: Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field. 0\n",
      "The practice of medicine is changing with the development of new Artificial Intelligence (AI) methods of machine learning. Coupled with rapid improvements in computer processing, these AI-based systems are already improving the accuracy and efficiency of diagnosis and treatment across various specializations. The increasing focus of AI in radiology has led to some experts suggesting that someday AI may even replace radiologists. These suggestions raise the question of whether AI-based systems will eventually replace physicians in some specializations or will augment the role of physicians without actually replacing them. To assess the impact on physicians this research seeks to better understand this technology and how it is transforming medicine. To that end this paper researches the role of AI-based systems in performing medical work in specializations including radiology, pathology, ophthalmology, and cardiology. It concludes that AI-based systems will augment physicians and are unlikely to replace the traditional physician–patient relationship. 0\n",
      "Technology advancements have a rapid effect on every field of life, be it medical field or any other field. Artificial intelligence has shown the promising results in health care through its decision making by analysing the data. COVID-19 has affected more than 100 countries in a matter of no time. People all over the world are vulnerable to its consequences in future. It is imperative to develop a control system that will detect the coronavirus. One of the solution to control the current havoc can be the diagnosis of disease with the help of various AI tools. In this paper, we classified textual clinical reports into four classes by using classical and ensemble machine learning algorithms. Feature engineering was performed using techniques like Term frequency/inverse document frequency (TF/IDF), Bag of words (BOW) and report length. These features were supplied to traditional and ensemble machine learning classifiers. Logistic regression and Multinomial Naïve Bayes showed better results than other ML algorithms by having 96.2% testing accuracy. In future recurrent neural network can be used for better accuracy. 0\n",
      "Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field “deep learning,” have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practice—polyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing. 0\n",
      "Background: Research in embodied artificial intelligence (AI) has increasing clinical relevance for therapeutic applications in mental health services. With innovations ranging from 'virtual psychotherapists' to social robots in dementia care and autism disorder, to robots for sexual disorders, artificially intelligent virtual and robotic agents are increasingly taking on high-level therapeutic interventions that used to be offered exclusively by highly trained, skilled health professionals. In order to enable responsible clinical implementation, ethical and social implications of the increasing use of embodied AI in mental health need to be identified and addressed. Objective: This paper assesses the ethical and social implications of translating embodied AI applications into mental health care across the fields of Psychiatry, Psychology and Psychotherapy. Building on this analysis, it develops a set of preliminary recommendations on how to address ethical and social challenges in current and future applications of embodied AI. Methods: Based on a thematic literature search and established principles of medical ethics, an analysis of the ethical and social aspects of currently embodied AI applications was conducted across the fields of Psychiatry, Psychology, and Psychotherapy. To enable a comprehensive evaluation, the analysis was structured around the following three steps: assessment of potential benefits; analysis of overarching ethical issues and concerns; discussion of specific ethical and social issues of the interventions. Results: From an ethical perspective, important benefits of embodied AI applications in mental health include new modes of treatment, opportunities to engage hard-to-reach populations, better patient response, and freeing up time for physicians. Overarching ethical issues and concerns include: harm prevention and various questions of data ethics; a lack of guidance on development of AI applications, their clinical integration and training of health professionals; 'gaps' in ethical and regulatory frameworks; the potential for misuse including using the technologies to replace established services, thereby potentially exacerbating existing health inequalities. Specific challenges identified and discussed in the application of embodied AI include: matters of risk-assessment, referrals, and supervision; the need to respect and protect patient autonomy; the role of non-human therapy; transparency in the use of algorithms; and specific concerns regarding long-term effects of these applications on understandings of illness and the human condition. Conclusions: We argue that embodied AI is a promising approach across the field of mental health; however, further research is needed to address the broader ethical and societal concerns of these technologies to negotiate best research and medical practices in innovative mental health care. We conclude by indicating areas of future research and developing recommendations for high-priority areas in need of concrete ethical guidance. 0\n",
      "Rationale and Objectives: Artificial intelligence (AI) has the potential to transform the clinical practice of radiology. This study investigated Canadian medical students’ perceptions of the impact of AI on radiology, and their influence on the students’ preference for radiology specialty. Materials and Methods: In March 2018, an anonymous online survey was distributed to students at all 17 Canadian medical schools. Results: Among 322 respondents, 70 students considered radiology as the top specialty choice, and 133 as among the top three choices. Only a minority (29.3%) of respondents agreed AI would replace radiologists in foreseeable future, but a majority (67.7%) agreed AI would reduce the demand for radiologists. Even among first-choice respondents, 48.6% agreed AI caused anxiety when considering the radiology specialty. Furthermore, one-sixth of respondents who would otherwise rank radiology as the first choice would not consider radiology because of the anxiety about AI. Prior significant exposure to radiology and high confidence in understanding of AI were shown to decrease the anxiety level. Interested students valued the opinions of local radiologists, radiology conferences, and journals. Students were most interested in “expert opinions on AI” and “discussing AI in preclinical radiology lectures” to understand the impact of AI. Conclusion: Anxiety related to “displacement” (not “replacement”) of radiologists by AI discouraged many medical students from considering the radiology specialty. The radiology community should educate medical students about the potential impact of AI, to ensure radiology is perceived as a viable long-term career choice. 0\n",
      "In the field of cancer genomics, the broad availability of genetic information offered by next-generation sequencing technologies and rapid growth in biomedical publication has led to the advent of the big-data era. Integration of artificial intelligence (AI) approaches such as machine learning, deep learning, and natural language processing (NLP) to tackle the challenges of scalability and high dimensionality of data and to transform big data into clinically actionable knowledge is expanding and becoming the foundation of precision medicine. In this paper, we review the current status and future directions of AI application in cancer genomics within the context of workflows to integrate genomic analysis for precision cancer care. The existing solutions of AI and their limitations in cancer genetic testing and diagnostics such as variant calling and interpretation are critically analyzed. Publicly available tools or algorithms for key NLP technologies in the literature mining for evidence-based clinical recommendations are reviewed and compared. In addition, the present paper highlights the challenges to AI adoption in digital healthcare with regard to data requirements, algorithmic transparency, reproducibility, and real-world assessment, and discusses the importance of preparing patients and physicians for modern digitized healthcare. We believe that AI will remain the main driver to healthcare transformation toward precision medicine, yet the unprecedented challenges posed should be addressed to ensure safety and beneficial impact to healthcare. 0\n",
      "Favorable outcomes in intraarterial therapy (IAT) for acute ischemic stroke (AIS) are related to early vessel recanalization. The mobile stroke treatment unit (MSTU) is an on-site, prehospital, treatment team, laboratory, and CT scanner that reduces time to treatment for intravenous thrombolysis and may also shorten time to IAT. Using our MSTU database, we identified patients that underwent IAT for AIS. We compared the key time metrics to historical controls, which included patients that underwent IAT at our institution six months prior to implementation of the MSTU. We further divided the controls into two groups: (1) transferred to our institution for IAT and (2) directly presented to our emergency room and underwent IAT. RESULTS: After 164 days of service, the MSTU transported 155 patients of which 5 underwent IAT. We identified 5 historical controls that were transferred to our center for IAT. Substantial reduction in times including median door to initial CT (12 minute vs. 32 minute), CT to IAT (82 minute vs. 165 minute), and door to MSTU/primary stroke center departure (37 minute vs. 106 minute) were noted among the two groups. Compared to the 6 patients who presented to our institution directly, the MSTU process times were also shorter. CONCLUSION: Our initial experience shows that MSTU may help in early triage and shorten the time to IAT for AIS. 0\n",
      "Background: This paper aims to move the debate forward regarding the potential for artificial intelligence (AI) and autonomous robotic surgery with a particular focus on ethics, regulation and legal aspects (such as civil law, international law, tort law, liability, medical malpractice, privacy and product/device legislation, among other aspects). Methods: We conducted an intensive literature search on current or emerging AI and autonomous technologies (eg, vehicles), military and medical technologies (eg, surgical robots), relevant frameworks and standards, cyber security/safety- and legal-systems worldwide. We provide a discussion on unique challenges for robotic surgery faced by proposals made for AI more generally (eg, Explainable AI) and machine learning more specifically (eg, black box), as well as recommendations for developing and improving relevant frameworks or standards. Conclusion: We classify responsibility into the following: (1) Accountability; (2) Liability; and (3) Culpability. All three aspects were addressed when discussing responsibility for AI and autonomous surgical robots, be these civil or military patients (however, these aspects may require revision in cases where robots become citizens). The component which produces the least clarity is Culpability, since it is unthinkable in the current state of technology. We envision that in the near future a surgical robot can learn and perform routine operative tasks that can then be supervised by a human surgeon. This represents a surgical parallel to autonomously driven vehicles. Here a human remains in the ‘driving seat’ as a ‘doctor-in-the-loop’ thereby safeguarding patients undergoing operations that are supported by surgical machines with autonomous capabilities. 0\n",
      " 0\n",
      "OBJECTIVE. Machine learning (ML) and artificial intelligence (AI) are rapidly becoming the most talked about and controversial topics in radiology and medicine. Over the past few years, the numbers of ML- or AI-focused studies in the literature have increased almost exponentially, and ML has become a hot topic at academic and industry conferences. However, despite the increased awareness of ML as a tool, many medical professionals have a poor understanding of how ML works and how to critically appraise studies and tools that are presented to us. Thus, we present a brief overview of ML, explain the metrics used in ML and how to interpret them, and explain some of the technical jargon associated with the field so that readers with a medical background and basic knowledge of statistics can feel more comfortable when examining ML applications. CONCLUSION. Attention to sample size, overfitting, underfitting, cross validation, as well as a broad knowledge of the metrics of machine learning, can help those with little or no technical knowledge begin to assess machine learning studies. However, transparency in methods and sharing of algorithms is vital to allow clinicians to assess these tools themselves. 0\n",
      "Background & Aims: Unsedated colonoscopy is acceptable for diagnostic, surveillance, and screening indications worldwide. However, insertion of the colonoscope can be painful; it is not clear which technique is least painful and thereby increases the likelihood of colonoscopy completion. We performed a head-to-head comparison of air insufflation (AI), carbon dioxide (CO2) insufflation, water immersion (WI), and water exchange (WE) to determine which combination of insertion techniques produces the least amount of pain. Methods: In a patient-blinded prospective trial, 624 subjects were assigned randomly to groups that underwent colonoscopy with AI-AI, CO2-CO2, WI-AI, WE-AI, WI-CO2, or WE-CO2 insertion and withdrawal techniques, including on-demand sedation, at the St. Barbara Hospital (Iglesias, Italy) or the Vìtkovice Hospital (Ostrava, Czech Republic), from October 2013 through June 2014. The primary outcome was real-time maximum insertion pain (0 = none, 10 = worst), recorded by an unblinded nurse assistant. At discharge, a blinded observer recorded the recalled maximum insertion pain and patients' and investigators' guesses about method or gas used. Results: Patients and investigators correctly guessed the method used for fewer than 44% of procedures, confirming adequate blinding. The correlation between real-time and recalled maximum insertion pain (r = 0.9; P < .0005) confirmed internal validation of the primary outcome. The WE group had the lowest scores: mean pain values were 5.2 for AI-AI (95% confidence interval [CI], 4.6-5.8), 4.9 for CO2-CO2 (95% CI, 4.3-5.4), 4.3 for WI-CO2 (95% CI, 3.8-4.9), 4.0 for WI-AI (95% CI, 3.5-4.5), 3.1 for WE-CO2 (95% CI, 2.7-3.4), and 3.1 for WE-AI (95% CI, 2.7-3.6) (P < .0005). The highest proportions of patients completing unsedated colonoscopy were in the WE groups. WE groups also had significantly better colon cleanliness, particularly in the transverse and right colon (P < .0005). One limitation of the study was that colonoscopists and assistants were not blinded to water-aided insertion methods. Conclusions: In a prospective study of colonoscopy insertion methods, CO2 insufflation did not reduce real-time maximum insertion pain. Compared with AI or CO2, WI and WE reduced insertion pain. The least painful technique was WE, which significantly increased completion of unsedated colonoscopy and bowel cleanliness without prolonging insertion time. ClinicalTrials.gov number: NCT01954862. 0\n",
      "This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. 0\n",
      "Artificial intelligence (AI) is already widely employed in various medical roles, and ongoing technological advances are encouraging more widespread use of AI in imaging. This is partly driven by the recognition of the significant frequency and clinical impact of human errors in radiology reporting, and the promise that AI can help improve the reliability as well the efficiency of imaging interpretation. AI in imaging was first envisioned in the 1960s, but initial attempts were limited by the technology of the day. It was the introduction of artificial neural networks and AI based computer aided detection (CAD) software in the 1980s that marked the advent of widespread integration of AI within radiology reporting. CAD is now routinely used in mammography, with consistent evidence of equivalent or improved lesion detection, with small increases in recall rates. Significant false positive rates remain a limitation for CAD, although these have markedly improved in the last decade. Other challenges include the difficulty clinicians encounter in trying to understand the reasoning of an AI system, which may limit their confidence in its advice, and a question mark hangs over who should be liable if CAD makes an error. The future integration of CAD with PACS promises the development of more comprehensively intelligent systems that can identify multiple, challenging diagnoses, and a move towards more individualised patient outcome predictions based upon AI analysis. 0\n",
      "Advances in nanomedicine, coupled with novel methods of creating advanced materials at the nanoscale, have opened new perspectives for the development of healthcare and medical products. Special attention must be paid toward safe design approaches for nanomaterial-based products. Recently, artificial intelligence (AI) and machine learning (ML) gifted the computational tool for enhancing and improving the simulation and modeling process for nanotoxicology and nanotherapeutics. In particular, the correlation of in vitro generated pharmacokinetics and pharmacodynamics to in vivo application scenarios is an important step toward the development of safe nanomedicinal products. This review portrays how in vitro and in vivo datasets are used in in silico models to unlock and empower nanomedicine. Physiologically based pharmacokinetic (PBPK) modeling and absorption, distribution, metabolism, and excretion (ADME)-based in silico methods along with dosimetry models as a focus area for nanomedicine are mainly described. The computational OMICS, colloidal particle determination, and algorithms to establish dosimetry for inhalation toxicology, and quantitative structure–activity relationships at nanoscale (nano-QSAR) are revisited. The challenges and opportunities facing the blind spots in nanotoxicology in this computationally dominated era are highlighted as the future to accelerate nanomedicine clinical translation. 0\n",
      "Background: Coronavirus disease (COVID-19) has spread explosively worldwide since the beginning of 2020. According to a multinational consensus statement from the Fleischner Society, computed tomography (CT) is a relevant screening tool due to its higher sensitivity for detecting early pneumonic changes. However, physicians are extremely occupied fighting COVID-19 in this era of worldwide crisis. Thus, it is crucial to accelerate the development of an artificial intelligence (AI) diagnostic tool to support physicians. Objective: We aimed to rapidly develop an AI technique to diagnose COVID-19 pneumonia in CT images and differentiate it from non-COVID-19 pneumonia and nonpneumonia diseases. Methods: A simple 2D deep learning framework, named the fast-track COVID-19 classification network (FCONet), was developed to diagnose COVID-19 pneumonia based on a single chest CT image. FCONet was developed by transfer learning using one of four state-of-the-art pretrained deep learning models (VGG16, ResNet-50, Inception-v3, or Xception) as a backbone. For training and testing of FCONet, we collected 3993 chest CT images of patients with COVID-19 pneumonia, other pneumonia, and nonpneumonia diseases from Wonkwang University Hospital, Chonnam National University Hospital, and the Italian Society of Medical and Interventional Radiology public database. These CT images were split into a training set and a testing set at a ratio of 8:2. For the testing data set, the diagnostic performance of the four pretrained FCONet models to diagnose COVID-19 pneumonia was compared. In addition, we tested the FCONet models on an external testing data set extracted from embedded low-quality chest CT images of COVID-19 pneumonia in recently published papers. Results: Among the four pretrained models of FCONet, ResNet-50 showed excellent diagnostic performance (sensitivity 99.58%, specificity 100.00%, and accuracy 99.87%) and outperformed the other three pretrained models in the testing data set. In the additional external testing data set using low-quality CT images, the detection accuracy of the ResNet-50 model was the highest (96.97%), followed by Xception, Inception-v3, and VGG16 (90.71%, 89.38%, and 87.12%, respectively). Conclusions: FCONet, a simple 2D deep learning framework based on a single chest CT image, provides excellent diagnostic performance in detecting COVID-19 pneumonia. Based on our testing data set, the FCONet model based on ResNet-50 appears to be the best model, as it outperformed other FCONet models based on VGG16, Xception, and Inception-v3. 0\n",
      "Recent success in Artificial Intelligence (AI) and Machine Learning (ML) allow problem solving automatically without any human intervention. Autonomous approaches can be very convenient. However, in certain domains, e.g., in the medical domain, it is necessary to enable a domain expert to understand, why an algorithm came up with a certain result. Consequently, the field of Explainable AI (xAI) rapidly gained interest worldwide in various domains, particularly in medicine. Explainable AI studies transparency and traceability of opaque AI/ML and there are already a huge variety of methods. For example with layer-wise relevance propagation relevant parts of inputs to, and representations in, a neural network which caused a result, can be highlighted. This is a first important step to ensure that end users, e.g., medical professionals, assume responsibility for decision making with AI/ML and of interest to professionals and regulators. Interactive ML adds the component of human expertise to AI/ML processes by enabling them to re-enact and retrace AI/ML results, e.g. let them check it for plausibility. This requires new human–AI interfaces for explainable AI. In order to build effective and efficient interactive human–AI interfaces we have to deal with the question of how to evaluate the quality of explanations given by an explainable AI system. In this paper we introduce our System Causability Scale to measure the quality of explanations. It is based on our notion of Causability (Holzinger et al. in Wiley Interdiscip Rev Data Min Knowl Discov 9(4), 2019) combined with concepts adapted from a widely-accepted usability scale. 0\n",
      " 0\n",
      "The term Artificial Intelligence (AI) was coined by John McCarthy in 1956 during a conference held on this subject. However, the possibility of machines being able to simulate human behavior and actually think was raised earlier by Alan Turing who developed the Turing test in order to differentiate humans from machines. Since then, computational power has grown to the point of instant calculations and the ability evaluate new data, according to previously assessed data, in real time. Today, AI is integrated into our daily lives in many forms, such as personal assistants (Siri, Alexa, Google assistant etc.), automated mass transportation, aviation and computer gaming. More recently, AI has also begun to be incorporated into medicine to improve patient care by speeding up processes and achieving greater accuracy, opening the path to providing better healthcare overall. Radiological images, pathology slides, and patients’ electronic medical records (EMR) are being evaluated by machine learning, aiding in the process of diagnosis and treatment of patients and augmenting physicians’ capabilities. Herein we describe the current status of AI in medicine, the way it is used in the different disciplines and future trends. 0\n",
      "Artificial intelligence (AI) using deep-learning (DL) has emerged as a breakthrough computer technology. By the era of big data, the accumulation of an enormous number of digital images and medical records drove the need for the utilization of AI to efficiently deal with these data, which have become fundamental resources for a machine to learn by itself. Among several DL models, the convolutional neural network showed outstanding performance in image analysis. In the field of gastroenterology, physicians handle large amounts of clinical data and various kinds of image devices such as endoscopy and ultrasound. AI has been applied in gastroenterology in terms of diagnosis, prognosis, and image analysis. However, potential inherent selection bias cannot be excluded in the form of retrospective study. Because overfitting and spectrum bias (class imbalance) have the possibility of overestimating the accuracy, external validation using unused datasets for model development, collected in a way that minimizes the spectrum bias, is mandatory. For robust verification, prospective studies with adequate inclusion/exclusion criteria, which represent the target populations, are needed. DL has its own lack of interpretability. Because interpretability is important in that it can provide safety measures, help to detect bias, and create social acceptance, further investigations should be performed. 0\n",
      "Purpose: This article reports on the prevalence and correlates of microaggressive experiences in health care settings reported by American Indian (AI) adults with type 2 diabetes mellitus (T2DM). Methods: This community-based participatory research project includes two AI reservation communities. Data were collected via in-person article-and-pencil survey interviews with 218 AI adults diagnosed with T2DM. Results: Greater than one third of the sample reported experiencing a microaggression in interactions with their health providers. Reports of microaggressions were correlated with self-reported history of heart attack, worse depressive symptoms, and prior-year hospitalization. Depressive symptom ratings seemed to account for some of the association between microaggressions and hospitalization (but not history of heart attack) in multivariate models. Conclusions: Microaggressive experiences undermine the ideals of patient-centered care and in this study were correlated with worse mental and physical health reports for AIs living with a chronic disease. Providers should be cognizant of these subtle, often unconscious forms of discrimination. (J Am Board Fam Med 2015;28:231-239.) 0\n",
      "In the past few months, several works were published in regards to the dynamics and early detection of COVID-19 via mathematical modeling and Artificial intelligence (AI). The aim of this work is to provide the research community with comprehensive overview of the methods used in these studies as well as a compendium of available open source datasets in regards to COVID-19. In all, 61 journal articles, reports, fact sheets, and websites dealing with COVID-19 were studied and reviewed. It was found that most mathematical modeling done were based on the Susceptible-Exposed-Infected-Removed (SEIR) and Susceptible-infected-recovered (SIR) models while most of the AI implementations were Convolutional Neural Network (CNN) on X-ray and CT images. In terms of available datasets, they include aggregated case reports, medical images, management strategies, healthcare workforce, demography, and mobility during the outbreak. Both Mathematical modeling and AI have both shown to be reliable tools in the fight against this pandemic. Several datasets concerning the COVID-19 have also been collected and shared open source. However, much work is needed to be done in the diversification of the datasets. Other AI and modeling applications in healthcare should be explored in regards to this COVID-19. 0\n",
      "Artificial intelligence (AI) has the potential to significantly transform the role of the doctor and revolutionise the practice of medicine. This qualitative review paper summarises the past 12 months of health research in AI, across different medical specialties, and discusses the current strengths as well as challenges, relating to this emerging technology. Doctors, especially those in leadership roles, need to be aware of how quickly AI is advancing in health, so that they are ready to lead the change required for its adoption by the health system. Key points: 'AI has now been shown to be as effective as humans in the diagnosis of various medical conditions, and in some cases, more effective.' When it comes to predicting suicide attempts, recent research suggest AI is better than human beings. 'AI's current strength is in its ability to learn from a large dataset and recognise patterns that can be used to diagnose conditions, putting it in direct competition with medical specialties that are involved in diagnostic tests that involve pattern recognition, such as pathology and radiology'. The current challenges in AI include legal liability and attribution of negligence when errors occur, and the ethical issues relating to patient choices. 'AI systems can also be developed with, or learn, biases, that will need to be identified and mitigated'. As doctors and health leaders, we need to start preparing the profession to be supported by, partnered with, and, in future, potentially be replaced by, AI and advanced robotics systems. 0\n",
      "IMPORTANCE The treatment effects of individual mechanical thrombectomy devices in large-vessel acute ischemic stroke (AIS) remain unclear. OBJECTIVE To determine whether the novel 3-dimensional (3-D) stent retriever used in conjunction with an aspiration-based mechanical thrombectomy device (Penumbra System; Penumbra) is noninferior to aspiration-based thrombectomy alone in AIS. DESIGN, SETTING, AND PARTICIPANTS This randomized, noninferiority clinical trial enrolled patients at 25 North American centers from May 19, 2012, through November 19, 2015, with follow-up for 90 days. Adjudicators of the primary end points were masked to treatment allocation. Patients with large-vessel intracranial occlusion AIS presenting with a National Institutes of Health Stroke Scale (NIHSS) score of at least 8 within 8 hours of onset underwent 1:1 randomization to 3-D stent retriever with aspiration or aspiration alone. The primary analyses were conducted in the intention-To-Treat population. INTERVENTIONS Mechanical thrombectomy using intracranial aspiration with or without the 3-D stent retriever. MAIN OUTCOMES AND MEASURES The primary effectiveness end pointwas the rate of a modified Thrombolysis in Cerebral Infarction (mTICI) grade of 2 to 3 with a 15%noninferiority margin. Device-and procedure-related serious adverse events at 24 hours were the primary safety end points. RESULTS Of 8082 patients screened, 198 patients were enrolled (111 women [56.1%] and 87 men [43.9%]; mean [SD] age, 66.9 [13.0] years) and randomized, including 98 in the 3-D stent retriever with aspiration group and 100 in the aspiration alone group; an additional 238 patients were eligible but not enrolled. The median baseline NIHSS score was 18.0 (interquartile range, 14.0-23.0). Eighty-Two of 94 patients in the 3-D stent retriever and aspiration group (87.2%) had an mTICI grade of 2 to 3 compared with 79 of 96 in the aspiration alone group (82.3%; difference, 4.9%; 90% CI, -3.6%to 13.5%). None of the other measures were significantly different between the 2 groups. Device-related serious adverse events were reported by 4 of 98 patients in the 3-D stent retriever with aspiration group (4.1%) vs 5 of 100 patients in the aspiration only group (5.0%); procedure-related serious adverse events, 10 of 98 (10.2%) vs 14 of 100 (14.0%). A 90-day modified Rankin Scale score of 0 to 2 was reported by 39 of 86 patients in the 3-D stent retriever with aspiration group (45.3%) vs 44 of 96 patients in the aspiration only group (45.8%). CONCLUSIONS AND RELEVANCE The present study provides class 1 evidence for the noninferiority of the 3-D stent retriever with aspiration vs aspiration alone in AIS. Future trials should evaluate whether these results can be generalized to other stent retrievers. TRIAL REGISTRATION clinicaltrials.gov Identifier: NCT01584609 0\n",
      "Objective: To explore rural-urban differences and trends in tissue plasminogen activator (tPA) utilization among acute ischemic stroke (AIS) patients and examine the association between primary stroke center (PSC) growth and geographic disparity in tPA use. Methods: We used hospital discharge data from the National Inpatient Sample (NIS) from 2000 to 2010 and indicators of tPA utilization and describe temporal trends in geographic disparities in AIS care during PSC growth. The Gini coefficient was used to quantify rural-urban inequity in tPA use at the state level (from 0% to 100% of maximum potential rural-urban inequity) in tPA use. Results: Of 914,500 cases of AIS between 2001 and 2010, 2.3% (n 5 21, 190) received tPA. The rural-urban disparity in tPA worsened: TPA use in urban hospitals quadrupled (1.17%- 4.87%) compared to rural hospitals (0.87%-1.59%). Of 33 states with NIS data, 15 reached at least 75% of the maximum rural-urban inequality from 2004 to 2010. Conclusions: Geographic disparities in tPA use for AIS are increasing. Greater understanding of the effectors of tPA utilization is necessary to ensure that access to tPA treatment is equitable for all communities in the United States. 0\n",
      "Background: Patients with adolescent idiopathic scoliosis (AIS) frequently receive x-ray imaging at diagnosis and subsequent follow monitoring. The ionizing radiation exposure has accumulated through their development stage and the effect of radiation to this young vulnerable group of patients is uncertain. To achieve the ALARA (as low as reasonably achievable) concept of radiation dose in medical imaging, a slot-scanning x-ray technique by the EOS system has been adopted and the radiation dose using micro-dose protocol was compared with the standard digital radiography on patients with AIS. Methods: Ninety-nine participants with AIS underwent micro-dose EOS and 33 underwent standard digital radiography (DR) for imaging of the whole spine. Entrance-skin dose was measured using thermoluminescent dosimeters (TLD) at three regions (i.e. dorsal sites at the level of sternal notch, nipple line, symphysis pubis). Effective dose and organ dose were calculated by simulation using PCXMC 2.0. Data from two x-ray systems were compared using independent-samples t-test and significance level at 0.05. All TLD measurements were conducted on PA projection only. Image quality was also assessed by two raters using Cobb angle measurement and a set of imaging parameters for optimization purposes. Results: Entrance-skin dose from micro-dose EOS system was 5.9-27.0 times lower at various regions compared with standard DR. The calculated effective dose was 2.6 ± 0.5 (μSv) and 67.5 ± 23.3 (μSv) from micro-dose and standard DR, respectively. The reduction in the micro-dose was approximately 26 times. Organ doses at thyroid, lung and gonad regions were significantly lower in micro-dose (p < 0.001). Data were further compared within the different gender groups. Females received significantly higher (p < 0.001) organ dose at ovaries compared to the testes in males. Patients with AIS received approximately 16-34 times lesser organ dose from micro-dose x-ray as compared with the standard DR. There was no significant difference in overall rating of imaging quality between EOS and DR. Micro-dose protocol provided enough quality to perform consistent measurement on Cobb angle. Conclusions: Entrance-skin dose, effective dose and organ dose were significantly reduced in micro-dose x-ray. The effective dose of a single micro-dose x-ray (2.6 μSv) was less than a day of background radiation. As AIS patients require periodic x-ray follow up for surveillance of curve progression, clinical use of micro-dose x-ray system is beneficial for these young patients to reduce the intake of ionizing radiation. 0\n",
      "BACKGROUND Falls represent the leading cause of traumatic brain injury in adults older than 65, with nearly one third experiencing a fall each year. Evidence suggests that up to 0.5% of anticoagulated patients suffer from intracranial hemorrhage (ICH) annually. Direct oral anticoagulants (DOACs) have become an increasingly popular alternative to warfarin for anticoagulation; however, there is a dearth of research regarding the safety of DOACs, in particular on the outcome of traumatic ICH while taking DOACs. METHODS We queried our Trauma Quality Improvement Project registry for patients who presented with traumatic intracranial hemorrhage during anticoagulant use. Patients were grouped into those prescribed warfarin and patients prescribed DOAC medications. The groups were compared with respect to age, gender, Glasgow Coma Score (GCS) on arrival, Abbreviated Injury Scale (AIS) (head), Injury Severity Score (ISS), mortality, need for operative intervention, hospital and ICU lengths of stay, proportion of patients transfused (and their transfusion requirements), and rates of discharge to skilled nursing facility. Poisson regression was conducted to determine the relationship between mortality and treatment group while controlling for covariates (comorbidities, ISS). RESULTS There were no differences between DOAC and warfarin groups in terms of age, gender, median ISS, median AIS head, or median admission GCS. Mechanisms of injury, median hospital and ICU lengths of stay, ICU free days, and transfusion requirements were also not significantly different. DOAC use was associated with significantly lower mortality (4.9% vs. 20.8%; p < 0.008) and a lower rate of operative intervention (8.2% vs. 26.7%; p = 0.023) when compared with warfarin. Excluding patients who died, the observed rate of discharge to skilled nursing facility was lower in the DOAC group (28.8% compared with 39.7%; p = 0.03). Multivariate Poisson regression analysis demonstrated that warfarin use was associated with an increased mortality when controlling for injury severity, and comorbidities. CONCLUSIONS We report improved mortality and reduced rates of operative intervention in patients with traumatic ICH associated with DOACs compared with a similar group taking warfarin. We also noted an association with decreased rate of discharge to SNF in patients taking DOACs compared with warfarin. LEVEL OF EVIDENCE Therapeutic study, level IV. 0\n",
      " 0\n",
      "OBJECTIVE: There is substantial heterogeneity in the number of screws used per level fused in adolescent idiopathic scoliosis (AIS) surgery. Assuming equivalent clinical outcomes, the potential cost savings of using fewer pedicle screws were estimated using a medical decision model with sensitivity analysis. METHODS: Descriptive analyses explored the annual costs for 5710 AIS inpatient stays using discharge data from the 2009 Kids' Inpatient Database (Healthcare Cost and Utilization Project, Agency for Healthcare Research and Quality), which is a national all-payer inpatient database. Patients between 10 and 17 years of age were identified using the ICD-9-CM code for idiopathic scoliosis (737.30). All inpatient stays were assumed to represent 10-level fusions with pedicle screws for AIS. High screw density was defined at 1.8 screws per level fused, and the standard screw density was defined as 1.48 screws per level fused. The surgical return for screw malposition was set at $23,762. A sensitivity analysis was performed by varying the cost per screw ($600-$1000) and the rate of surgical revisions for screw malposition (0.117%-0.483% of screws; 0.8%-4.3% of patients). The reported outcomes include estimated prevented malpositioned screws (set at 5.1%), averted revision surgeries, and annual cost savings in 2009 US dollars, assuming similar clinical outcomes (rates of complications, revision) using a standard- versus high-density pattern. RESULTS: The total annual costs for 5710 AIS hospital stays was $278 million ($48,900 per patient). Substituting a high for a standard screw density yields 3.2 fewer screws implanted per patient, with 932 malpositioned screws prevented and 21 to 88 revision surgeries for implant malposition averted, and a potential annual cost savings of $11 million to $20 million (4%-7% reduction in the total cost of AIS hospitalizations). CONCLUSIONS: Reducing the number of screws used in scoliosis surgery could potentially decrease national AIS hospitalization costs by up to 7%, which may improve the safety and efficiency of care. However, such a screw construct must first be proven safe and effective. 0\n",
      " 0\n",
      "Introduction A recent randomized controlled trial (RCT), the Multicenter Randomized CLinical trial of Endovascular treatment for Acute ischemic stroke in the Netherlands (MR CLEAN), demonstrated better outcomes with endovascular treatment compared with medical therapy for acute ischemic stroke (AIS). However, previous trials have provided mixed results regarding the efficacy of endovascular treatment for AIS. A meta-analysis of all available trial data was performed to summarize the available evidence. Methods A literature search was performed to identify all prospective RCTs comparing endovascular therapies with medical management for AIS. Two datasets were created: (1) all patients randomized after confirmation of large vessel occlusion (LVO) (consistent with the contemporary standard of practice at the majority of centers); and (2) all patients with outcome data who underwent randomization regardless of qualifying vascular imaging. The pre-specified primary outcome measure was modified Rankin Scale score of 0-2 at 90 days. A fixed-effect model was used to determine significance. Results Five prospective RCTs comparing endovascular therapies with medical management were included in dataset 1 (1183 patients) and six were included in dataset 2 (1903 total patients). Endovascular therapies were associated with significantly improved outcomes compared with medical management (OR 1.67, 95% CI 1.29 to 1.16, p=0.0001) for patients with LVO (dataset 1). This benefit persisted when patients from all six RCTs were included, even in the absence of confirmation of LVO (OR 1.27, 95% CI 1.05 to 1.54, p=0.019; dataset 2). Conclusions A meta-analysis of prospective RCTs comparing endovascular therapies with medical management demonstrates superior outcomes in patients randomized to endovascular therapy. 0\n",
      "This study employed deep-learning convolutional neural networks to stage lung disease severity of Coronavirus Disease 2019 (COVID-19) infection on portable chest x-ray (CXR) with radiologist score of disease severity as ground truth. This study consisted of 131 portable CXR from 84 COVID-19 patients (51M 55.1±14.9yo; 29F 60.1±14.3yo; 4 missing information). Three expert chest radiologists scored the left and right lung separately based on the degree of opacity (0–3) and geographic extent (0–4). Deep-learning convolutional neural network (CNN) was used to predict lung disease severity scores. Data were split into 80% training and 20% testing datasets. Correlation analysis between AI-predicted versus radiologist scores were analyzed. Comparison was made with traditional and transfer learning. The average opacity score was 2.52 (range: 0–6) with a standard deviation of 0.25 (9.9%) across three readers. The average geographic extent score was 3.42 (range: 0–8) with a standard deviation of 0.57 (16.7%) across three readers. The inter-rater agreement yielded a Fleiss’ Kappa of 0.45 for opacity score and 0.71 for extent score. AI-predicted scores strongly correlated with radiologist scores, with the top model yielding a correlation coefficient (R2) of 0.90 (range: 0.73–0.90 for traditional learning and 0.83–0.90 for transfer learning) and a mean absolute error of 8.5% (ranges: 17.2–21.0% and 8.5%-15.5, respectively). Transfer learning generally performed better. In conclusion, deep-learning CNN accurately stages disease severity on portable chest x-ray of COVID-19 lung infection. This approach may prove useful to stage lung disease severity, prognosticate, and predict treatment response and survival, thereby informing risk management and resource allocation. 0\n",
      "The spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has already assumed pandemic proportions, affecting over 100 countries in few weeks. A global response is needed to prepare health systems worldwide. Covid-19 can be diagnosed both on chest X-ray and on computed tomography (CT). Asymptomatic patients may also have lung lesions on imaging. CT investigation in patients with suspicion Covid-19 pneumonia involves the use of the high-resolution technique (HRCT). Artificial intelligence (AI) software has been employed to facilitate CT diagnosis. AI software must be useful categorizing the disease into different severities, integrating the structured report, prepared according to subjective considerations, with quantitative, objective assessments of the extent of the lesions. In this communication, we present an example of a good tool for the radiologist (Thoracic VCAR software, GE Healthcare, Italy) in Covid-19 diagnosis (Pan et al. in Radiology, 2020. https://doi.org/10.1148/radiol.2020200370). Thoracic VCAR offers quantitative measurements of the lung involvement. Thoracic VCAR can generate a clear, fast and concise report that communicates vital medical information to referring physicians. In the post-processing phase, software, thanks to the help of a colorimetric map, recognizes the ground glass and differentiates it from consolidation and quantifies them as a percentage with respect to the healthy parenchyma. AI software therefore allows to accurately calculate the volume of each of these areas. Therefore, keeping in mind that CT has high diagnostic sensitivity in identifying lesions, but not specific for Covid-19 and similar to other infectious viral diseases, it is mandatory to have an AI software that expresses objective evaluations of the percentage of ventilated lung parenchyma compared to the affected one. 0\n",
      " 0\n",
      "The Japan Society of Gynecologic Oncology (JSGO) Guidelines 2017 for the Treatment of Uterine Cervical Cancer are for the purpose of providing standard treatment strategies for cervical cancer, indicating treatment methods currently considered appropriate for cervical cancer, minimizing variances in treatment methods among institutions, improving the safety of treatment and prognosis of diseases, reducing the economic and psychosomatic burden of patients by promoting performance of appropriate treatment, and enhancing mutual understanding between patients and healthcare professionals. The guidelines were prepared through consensus of the JSGO Guideline Committee, based on careful review of evidence gathered through the literature searches and in view of the medical health insurance system and actual clinical practice situations in Japan. The guidelines comprise eight chapters and five algorithms. The main features of the 2017 revision are as follows: (1) evidence was collected using a search formula and with cooperation of the Japan Library Association. The bibliographical search formula was placed at the end of the book; (2) regarding clinical questions (CQs) where evidence or clinical inspection in Japan was lacking, opinions of the Guidelines Committee were described as “proposals for future directions”; (3) cervical intraepithelial neoplasia (CIN) 3 and adenocarcinoma in situ (AIS) were treated as a cervical precancerous lesion; (4) the CQs of endoscopic surgery, radical trachelectomy, and sentinel node biopsy were newly added in Chapter 3, “primary treatment for stage IB–II cervical cancer”; and (5) the CQ about hormone replacement therapy after cancer treatment was newly established. Each recommendation is accompanied by a classification of recommendation categories based on the consensus reached by the Guideline Committee members. Here, we present the English version of the JSGO Guidelines 2017 for the Treatment of Uterine Cervical Cancer. 0\n",
      "Recently, there has been an upsurge of attention focused on bias and its impact on specialized artificial intelligence (AI) applications. Allegations of racism and sexism have permeated the conversation as stories surface about search engines delivering job postings for well-paying technical jobs to men and not women, or providing arrest mugshots when keywords such as “black teenagers” are entered. Learning algorithms are evolving; they are often created from parsing through large datasets of online information while having truth labels bestowed on them by crowd-sourced masses. These specialized AI algorithms have been liberated from the minds of researchers and startups, and released onto the public. Yet intelligent though they may be, these algorithms maintain some of the same biases that permeate society. They find patterns within datasets that reflect implicit biases and, in so doing, emphasize and reinforce these biases as global truth. This paper describes specific examples of how bias has infused itself into current AI and robotic systems, and how it may affect the future design of such systems. More specifically, we draw attention to how bias may affect the functioning of (1) a robot peacekeeper, (2) a self-driving car, and (3) a medical robot. We conclude with an overview of measures that could be taken to mitigate or halt bias from permeating robotic technology. 0\n",
      "Purpose: Noticing the fast growing translation of artificial intelligence (AI) technologies to medical image analysis this paper emphasizes the future role of the medical physicist in this evolving field. Specific challenges are addressed when implementing big data concepts with high-throughput image data processing like radiomics and machine learning in a radiooncology environment to support clinical decisions. Methods: Based on the experience of our interdisciplinary radiomics working group, techniques for processing minable data, extracting radiomics features and associating this information with clinical, physical and biological data for the development of prediction models are described. A special emphasis was placed on the potential clinical significance of such an approach. Results: Clinical studies demonstrate the role of radiomics analysis as an additional independent source of information with the potential to influence the radiooncology practice, i.e. to predict patient prognosis, treatment response and underlying genetic changes. Extending the radiomics approach to integrate imaging, clinical, genetic and dosimetric data (‘panomics’) challenges the medical physicist as member of the radiooncology team. Conclusions: The new field of big data processing in radiooncology offers opportunities to support clinical decisions, to improve predicting treatment outcome and to stimulate fundamental research on radiation response both of tumor and normal tissue. The integration of physical data (e.g. treatment planning, dosimetric, image guidance data) demands an involvement of the medical physicist in the radiomics approach of radiooncology. To cope with this challenge national and international organizations for medical physics should organize more training opportunities in artificial intelligence technologies in radiooncology. 0\n",
      "BACKGROUND An association between stress-induced hyperglycemia (SIH) and increased mortality has been demonstrated following trauma. Experimental animal model data regarding the association between hyperglycemia and outcomes following traumatic brain injury (TBI) are inconsistent, suggesting that hyperglycemia may be harmful, neutral, or beneficial. The purpose of this study was to examine the effects of SIH versus diabetic hyperglycemia (DH) on severe TBI. METHODS Admission glycosylated hemoglobin (HbA1c), glucose levels, and comorbidity data were collected during a 4-year period from September 2009 to December 2013 for patients with severe TBI (i.e., admission Glasgow Coma Scale [GCS] score of 3-8 and head Abbreviated Injury Scale [AIS] score ≥ 3). Diabetes mellitus was determined by patient history or admission HbA1c of 6.5% or greater. SIH was determined by the absence of diabetes mellitus and admission glucose of 200 mg/dL or greater. A Cox proportional hazards model adjusted for age, sex, injury mechanism, and Injury Severity Score (ISS) was used to calculate hazard ratios (HRs) and associated 95% confidence intervals (CIs) for the association between SIH and the outcomes of interest. RESULTS During the study period, a total of 626 patients were included in the study group, having severe TBI defined by both GCS score of 3 to 8 and head AIS score being 3 or greater and also had available HbA1c and admission glucose levels. A total of 184 patients were admitted with hyperglycemia; 152 patients (82.6%) were diagnosed with SIH, and 32 patients (17.4%) were diagnosed with DH. When comparing patients with severe TBI adjusted for age, sex, injury mechanism, ISS, Revised Trauma Score (RTS), and lactic acid greater than 2.5 mmol/L, patients with SIH had a 50% increased mortality (HR, 1.49; 95% CI, 1.13-1.95) compared with the nondiabetic normoglycemia patients. DH patients did not have a significant increase in mortality (HR, 0.94; 95% CI, 0.56-1.58). CONCLUSION SIH is associated with higher mortality after severe TBI. This association was not observed among patients with DH, which suggests that hyperglycemia related to diabetes is of less importance compared with SIH in terms of mortality in the acute trauma and TBI patient. Further research is warranted to identify mechanisms causing SIH and subsequent worse outcomes after TBI. LEVEL OF EVIDENCE Prognostic/epidemiologic study, leve III. 0\n",
      "Progression to exudative ‘wet’ age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80% at 55% specificity, and 34% sensitivity at 90% specificity. This level of performance corresponds to true positives in 78% and 41% of individual eyes, and false positives in 56% and 17% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression. 0\n",
      "With the recent increase in the interest of individuals in health, lifecare, and disease, hospital medical services have been shifting from a treatment focus to prevention and health management. The medical industry is creating additional services for health- and life-promotion programs. This change represents a medical-service paradigm shift due to the prolonged life expectancy, aging, lifestyle changes, and income increases, and consequently, the concept of the smart health service has emerged as a major issue. Due to smart health, the existing health-promotion medical services that typically have been operated by large hospitals have been developing into remote medical-treatment services where personal health records are used in small hospitals; moreover, a further expansion has been occurring in the direction of u-Healthcare in which health conditions are continuously monitored in the everyday lives of the users. However, as the amount of data is increasing and the medical-data complexity is intensifying, the limitations of the previous approaches are increasingly problematic; furthermore, since even the same disease can show different symptoms depending on the personal health conditions, lifestyle, and genome information, universal healthcare is not effective for some patients, and it can even generate severe side effects. Thus, research on the AI-based healthcare that is in the form of mining-based smart health, which is a convergence technology of the 4IR, is actively being carried out. Particularly, the introduction of various smart medical equipment for which healthcare big data and a running machine have been combined and the expansion of the distribution of smartphone wearable devices have led to innovations such as personalized diagnostic and treatment services and chronic-disease management and prevention services. In addition, various already launched applications allow users to check their own health conditions and receive the corresponding feedback in real time. Based on these innovations, the preparation of a way to determine a user’s current health conditions, and to respond properly through contextual feedback in the case of unsound health conditions, is underway. However, since the previously made healthcare-related applications need to be linked to a wearable device, and they provide medical feedback to users based solely on specific biometric data, inaccurate information can be provided. In addition, the user interfaces of some healthcare applications are very complicated, causing user inconvenience regarding the attainment of desired information. Therefore, we propose a chatbot-based healthcare service with a knowledge base for cloud computing. The proposed method is a mobile health service in the form of a chatbot for the provision of fast treatment in response to accidents that may occur in everyday life, and also in response to changes of the conditions of patients with chronic diseases. A chatbot is an intelligent conversation platform that interacts with users via a chatting interface, and since its use can be facilitated by linkages with the major social network service messengers, general users can easily access and receive various health services. The proposed framework enables a smooth human–robot interaction that supports the efficient implementation of the chatbot healthcare service. The design of the framework comprises the following four levels: data level, information level, knowledge level, and service level. 0\n",
      "Artificial intelligence (AI) based on convolutional neural networks (CNNs) has a great potential to enhance medical workflow and improve health care quality. Of particular interest is practical implementation of such AI-based software as a cloud-based tool aimed for telemedicine, the practice of providing medical care from a distance using electronic interfaces. Methods: In this study, we used a dataset of labeled 35,900 optical coherence tomography (OCT) images obtained from age-related macular degeneration (AMD) patients and used them to train three types of CNNs to perform AMD diagnosis. Results: Here, we present an AI- and cloud-based telemedicine interaction tool for diagnosis and proposed treatment of AMD. Through deep learning process based on the analysis of preprocessed optical coherence tomography (OCT) imaging data, our AI-based system achieved the same image discrimination rate as that of retinal specialists in our hospital. The AI platform’s detection accuracy was generally higher than 90% and was significantly superior (p < 0.001) to that of medical students (69.4% and 68.9%) and equal (p = 0.99) to that of retinal specialists (92.73% and 91.90%). Furthermore, it provided appropriate treatment recommendations comparable to those of retinal specialists. Conclusions: We therefore developed a website for realistic cloud computing based on this AI platform, available at https://www.ym.edu.tw/~AI-OCT/. Patients can upload their OCT images to the website to verify whether they have AMD and require treatment. Using an AI-based cloud service represents a real solution for medical imaging diagnostics and telemedicine. 0\n",
      " 0\n",
      "Objective(s):To develop and assess AI algorithms to identify operative steps in laparoscopic sleeve gastrectomy (LSG).Background:Computer vision, a form of artificial intelligence (AI), allows for quantitative analysis of video by computers for identification of objects and patterns, such as in autonomous driving.Methods:Intraoperative video from LSG from an academic institution was annotated by 2 fellowship-Trained, board-certified bariatric surgeons. Videos were segmented into the following steps: 1) port placement, 2) liver retraction, 3) liver biopsy, 4) gastrocolic ligament dissection, 5) stapling of the stomach, 6) bagging specimen, and 7) final inspection of staple line. Deep neural networks were used to analyze videos. Accuracy of operative step identification by the AI was determined by comparing to surgeon annotations.Results:Eighty-eight cases of LSG were analyzed. A random 70% sample of these clips was used to train the AI and 30% to test the AI's performance. Mean concordance correlation coefficient for human annotators was 0.862, suggesting excellent agreement. Mean (±SD) accuracy of the AI in identifying operative steps in the test set was 82%±4% with a maximum of 85.6%.Conclusions:AI can extract quantitative surgical data from video with 85.6% accuracy. This suggests operative video could be used as a quantitative data source for research in intraoperative clinical decision support, risk prediction, or outcomes studies. 0\n",
      "Background: Artificial intelligence (AI) has been extensively used in a range of medical fields to promote therapeutic development. The development of diverse AI techniques has also contributed to early detections, disease diagnoses, and referral management. However, concerns about the value of advanced AI in disease diagnosis have been raised by health care professionals, medical service providers, and health policy decision makers. Objective: This review aimed to systematically examine the literature, in particular, focusing on the performance comparison between advanced AI and human clinicians to provide an up-to-date summary regarding the extent of the application of AI to disease diagnoses. By doing so, this review discussed the relationship between the current advanced AI development and clinicians with respect to disease diagnosis and thus therapeutic development in the long run. Methods: We systematically searched articles published between January 2000 and March 2019 following the Preferred Reporting Items for Systematic reviews and Meta-Analysis in the following databases: Scopus, PubMed, CINAHL, Web of Science, and the Cochrane Library. According to the preset inclusion and exclusion criteria, only articles comparing the medical performance between advanced AI and human experts were considered. Results: A total of 9 articles were identified. A convolutional neural network was the commonly applied advanced AI technology. Owing to the variation in medical fields, there is a distinction between individual studies in terms of classification, labeling, training process, dataset size, and algorithm validation of AI. Performance indices reported in articles included diagnostic accuracy, weighted errors, false-positive rate, sensitivity, specificity, and the area under the receiver operating characteristic curve. The results showed that the performance of AI was at par with that of clinicians and exceeded that of clinicians with less experience. Conclusions: Current AI development has a diagnostic performance that is comparable with medical experts, especially in image recognition-related fields. Further studies can be extended to other types of medical imaging such as magnetic resonance imaging and other medical practices unrelated to images. With the continued development of AI-assisted technologies, the clinical implications underpinned by clinicians' experience and guided by patient-centered health care principle should be constantly considered in future AI-related and other technology-based medical research. 0\n",
      "Background: CC-Cruiser is an artificial intelligence (AI) platform developed for diagnosing childhood cataracts and providing risk stratification and treatment recommendations. The high accuracy of CC-Cruiser was previously validated using specific datasets. The objective of this study was to compare the diagnostic efficacy and treatment decision-making capacity between CC-Cruiser and ophthalmologists in real-world clinical settings. Methods: This multicentre randomized controlled trial was performed in five ophthalmic clinics in different areas across China. Pediatric patients (aged ≤ 14 years) without a definitive diagnosis of cataracts or history of previous eye surgery were randomized (1:1) to receive a diagnosis and treatment recommendation from either CC-Cruiser or senior consultants (with over 5 years of clinical experience in pediatric ophthalmology). The experts who provided a gold standard diagnosis, and the investigators who performed slit-lamp photography and data analysis were blinded to the group assignments. The primary outcome was the diagnostic performance for childhood cataracts with reference to cataract experts' standards. The secondary outcomes included the evaluation of disease severity and treatment determination, the time required for the diagnosis, and patient satisfaction, which was determined by the mean rating. This trial is registered with ClinicalTrials.gov (NCT03240848). Findings: Between August 9, 2017 and May 25, 2018, 350 participants (700 eyes) were randomly assigned for diagnosis by CC-Cruiser (350 eyes) or senior consultants (350 eyes). The accuracies of cataract diagnosis and treatment determination were 87.4% and 70.8%, respectively, for CC-Cruiser, which were significantly lower than 99.1% and 96.7%, respectively, for senior consultants (p < 0.001, OR = 0.06 [95% CI 0.02 to 0.19]; and p < 0.001, OR = 0.08 [95% CI 0.03 to 0.25], respectively). The mean time for receiving a diagnosis from CC-Cruiser was 2.79 min, which was significantly less than 8.53 min for senior consultants (p < 0.001, mean difference 5.74 [95% CI 5.43 to 6.05]). The patients were satisfied with the overall medical service quality provided by CC-Cruiser, typically with its time-saving feature in cataract diagnosis. Interpretation: CC-Cruiser exhibited less accurate performance comparing to senior consultants in diagnosing childhood cataracts and making treatment decisions. However, the medical service provided by CC-Cruiser was less time-consuming and achieved a high level of patient satisfaction. CC-Cruiser has the capacity to assist human doctors in clinical practice in its current state. Funding: National Key R&D Program of China (2018YFC0116500) and the Key Research Plan for the National Natural Science Foundation of China in Cultivation Project (91846109). 0\n",
      "Background Aromatase inhibitors (AIs) may increase cardiovascular risk relative to tamoxifen in post-menopausal women with breast cancer. This risk has not been well-quantified outside of clinical trials. Methods Observational population-based cohort study of women aged >55 years diagnosed with stage I–III breast cancer between 2005 and 2010. Women treated with AIs or tamoxifen were followed to March 2012. The primary outcome was hospitalisation for myocardial infarction (MI). Cause-specific hazards were compared using tamoxifen as the reference group. Inverse probability of treatment weighting using the propensity score was used to reduce confounding due to measured baseline covariates. Results were confirmed using two cause-specific hazards models. Subgroup analyses included women aged ≥66 years, those with prior ischaemic heart disease, and a ‘lower-risk group’ aged <74 years with stage I–II cancer and no prior ischaemic heart disease. Results In 7409 aromatase inhibitor-treated and 1941 tamoxifen-treated women, the median age was 71 versus 74 years, respectively (p < 0.001). Baseline prevalence of ischaemic heart disease was similar (17.0% versus 16.9%, p = 0.96). Over a mean of 1184 d of follow-up, there were 123 hospitalisations for MI; the cause-specific hazard was higher with AIs (hazard ratio 2.02; 95% confidence interval 1.16–3.53 in the weighted sample). We observed comparable patterns within pre-defined subgroups and when adjusted using cause-specific hazards models. Conclusion Aromatase inhibitors are associated with a higher risk of MI compared with tamoxifen. This risk should be accounted for when managing aromatase inhibitor-treated women. 0\n",
      "Artificial intelligence (AI) algorithms continue to rival human performance on a variety of clinical tasks, while their actual impact on human diagnosticians, when incorporated into clinical workflows, remains relatively unexplored. In this study, we developed a deep learning-based assistant to help pathologists differentiate between two subtypes of primary liver cancer, hepatocellular carcinoma and cholangiocarcinoma, on hematoxylin and eosin-stained whole-slide images (WSI), and evaluated its effect on the diagnostic performance of 11 pathologists with varying levels of expertise. Our model achieved accuracies of 0.885 on a validation set of 26 WSI, and 0.842 on an independent test set of 80 WSI. Although use of the assistant did not change the mean accuracy of the 11 pathologists (p = 0.184, OR = 1.281), it significantly improved the accuracy (p = 0.045, OR = 1.499) of a subset of nine pathologists who fell within well-defined experience levels (GI subspecialists, non-GI subspecialists, and trainees). In the assisted state, model accuracy significantly impacted the diagnostic decisions of all 11 pathologists. As expected, when the model’s prediction was correct, assistance significantly improved accuracy (p = 0.000, OR = 4.289), whereas when the model’s prediction was incorrect, assistance significantly decreased accuracy (p = 0.000, OR = 0.253), with both effects holding across all pathologist experience levels and case difficulty levels. Our results highlight the challenges of translating AI models into the clinical setting, and emphasize the importance of taking into account potential unintended negative consequences of model assistance when designing and testing medical AI-assistance tools. 0\n",
      "Artificial intelligence (AI) and machine learning (ML) techniques are revolutionizing several industrial and research fields like computer vision, autonomous driving, natural language processing, and speech recognition. These novel tools are already having a major impact in radiology, diagnostics, and many other fields in which the availability of automated solution may benefit the accuracy and repeatability of the execution of critical tasks. In this narrative review, we first present a brief description of the various techniques that are being developed nowadays, with special focus on those used in spine research. Then, we describe the applications of AI and ML to problems related to the spine which have been published so far, including the localization of vertebrae and discs in radiological images, image segmentation, computer-aided diagnosis, prediction of clinical outcomes and complications, decision support systems, content-based image retrieval, biomechanics, and motion analysis. Finally, we briefly discuss major ethical issues related to the use of AI in healthcare, namely, accountability, risk of biased decisions as well as data privacy and security, which are nowadays being debated in the scientific community and by regulatory agencies. 0\n",
      "Purpose of Review: Artificial intelligence (AI) technology holds both great promise to transform mental healthcare and potential pitfalls. This article provides an overview of AI and current applications in healthcare, a review of recent original research on AI specific to mental health, and a discussion of how AI can supplement clinical practice while considering its current limitations, areas needing additional research, and ethical implications regarding AI technology. Recent Findings: We reviewed 28 studies of AI and mental health that used electronic health records (EHRs), mood rating scales, brain imaging data, novel monitoring systems (e.g., smartphone, video), and social media platforms to predict, classify, or subgroup mental health illnesses including depression, schizophrenia or other psychiatric illnesses, and suicide ideation and attempts. Collectively, these studies revealed high accuracies and provided excellent examples of AI’s potential in mental healthcare, but most should be considered early proof-of-concept works demonstrating the potential of using machine learning (ML) algorithms to address mental health questions, and which types of algorithms yield the best performance. Summary: As AI techniques continue to be refined and improved, it will be possible to help mental health practitioners re-define mental illnesses more objectively than currently done in the DSM-5, identify these illnesses at an earlier or prodromal stage when interventions may be more effective, and personalize treatments based on an individual’s unique characteristics. However, caution is necessary in order to avoid over-interpreting preliminary results, and more work is required to bridge the gap between AI in mental health research and clinical care. 0\n",
      "Study design: Prospective, population-based cohort study. Objectives: To determine the prevalence of selected complications following traumatic spinal cord injury during acute care and to identify the risk factors for pressure ulcers. Setting: The only tertiary academic (Groote Schuur) hospital in the catchment region providing specialised acute care. Methods: A descriptive, observational study of an inception cohort. Secondary complications were predefined and consisted of pressure ulcers, pulmonary complications (pneumonia and atelectasis), urinary tract infections, autonomic dysreflexia, deep vein thrombosis, pulmonary embolism, postural hypotension, neuropathic pain and spasticity. Possible risk factors for pressure ulcers included variables concerning demographic and injury characteristics and complications. Both univariate and multivariate logistic regression analyses were used. Results: Data of 141 patients (97%) were analysed. In total, 71 (50.3%) patients had one or more complication. The most common was pressure ulcers (n=42; 29.8%), followed by pulmonary complications (n=33; 23.4%) and urinary tract infections (n=24; 17%). Significant risk factors were gun-shot injury, motor completeness (American Spinal Injury Association Impairment Scale (AIS) AB), vertebral injury, no spinal surgery, pulmonary complications, urinary tract infection and level of consciousness. In the final multivariate model that correctly predicted 81.6% of subjects, motor completeness and vertebral injury remained significant independent factors, whereas having a urinary tract infection was associated with an increased risk (odds ratio: 2.86), but not significant at the 5% level. Conclusion: Pressure ulcers and pulmonary complications were prevalent during specialised acute phase. The occurrence of pressure ulcers, despite protocols in place, is worrisome. To prevent pressure ulcers, special attention seems necessary for persons with motor complete lesions and those with vertebral injuries. 0\n",
      "Tuberculosis [TB] has afflicted numerous nations in the world. As per a report by the World Health Organization [WHO], an estimated 1.4 million TB deaths in 2015 and an additional 0.4 million deaths resulting from TB disease among people living with HIV, were observed. Most of the TB deaths can be prevented if it is detected at an early stage. The existing processes of diagnosis like blood tests or sputum tests are not only tedious but also take a long time for analysis and cannot differentiate between different drug resistant stages of TB. The need to find newer prompt methods for disease detection has been aided by the latest Artificial Intelligence [AI] tools. Artificial Neural Network [ANN] is one of the important tools that is being used widely in diagnosis and evaluation of medical conditions. This review aims at providing brief introduction to various AI tools that are used in TB detection and gives a detailed description about the utilization of ANN as an efficient diagnostic technique. The paper also provides a critical assessment of ANN and the existing techniques for their diagnosis of TB. Researchers and Practitioners in the field are looking forward to use ANN and other upcoming AI tools such as Fuzzy-logic, genetic algorithms and artificial intelligence simulation as a promising current and future technology tools towards tackling the global menace of Tuberculosis. Latest advancements in the diagnostic field include the combined use of ANN with various other AI tools like the Fuzzy-logic, which has led to an increase in the efficacy and specificity of the diagnostic techniques. 0\n",
      "Introduction The natural history of acute ischemic stroke (AIS) due to basilar artery occlusion (BAO) is poor. Endovascular reperfusion therapy (EVT) improves recanalization rates in patients with emergent large vessel intracranial occlusion. Objective To examine the hypothesis that good collateral patterns identified by pretreatment CT angiography (CTA) might be associated with favorable outcomes after EVT. Methods We conducted a retrospective chart review of patients presenting with AIS due to BAO in a tertiary care stroke center during a 4-year period. BAO was diagnosed by CTA in all cases. Admission stroke severity was documented using the National Institute of Health Stroke Scale (NIHSS) score. Pretreatment collateral score for posterior circulation was defined as follows: 0, no posterior communicating artery (PCOM); 1, unilateral PCOM; 2, bilateral PCOM. Favorable outcome was defined as modified Rankin Scale score of 0-2 at 3 months. Results A total of 21 patients with AIS due to BAO (age range 31-84 years, median admission NIHSS score: 18 points, range 2-38) underwent EVT. Eleven of 21 patients (52.4%) had bilateral PCOMs, while unilateral PCOM was seen in 3 patients (14.3%). Patients with bilateral PCOMs tended ( p=0.261) to have less severe stroke at admission than those with absent/unilateral PCOM (median NIHSS score 18 vs 27 points). Neurological improvement during hospitalization (quantified by the median decrease in NIHSS score) and the rate of 3-month functional independence were greater in patients with good collaterals (16 vs 0 points (p=0.016) and 72.7% vs 0% (p=0.001)). Conclusions The presence of bilateral PCOMs on pretreatment CTA appears to be associated with more favorable outcomes in BAO treated with EVT. 0\n",
      "Background: We examined (a) the expression of the antioxidative factor glutathione peroxidase (GPx) and the transcription factor nuclear factor E2-related factor 2 (Nrf2) following low-dose X-irradiation in endothelial cells (ECs) and (b) the impact of reactive oxygen species (ROS) and Nrf2 on functional properties of ECs to gain further knowledge about the anti-inflammatory mode of action of low doses of ionizing radiation. Material and methods: EA.hy926 ECs and primary human dermal microvascular ECs (HMVEC) were stimulated by tumor necrosis factor-α (TNF-α, 20 ng/ml) 4 h before irradiation with single doses ranging from 0.3 to 3 Gy. The expression and activity of GPx and Nrf2 were analyzed by flow cytometry, colorimetric assays, and real-time PCR. The impact of ROS and Nrf2 on peripheral blood mononuclear cell (PBMC) adhesion was assayed in the presence of the ROS scavenger N-acetyl-L-cysteine (NAC) and Nrf2 activator AI-1. Results: Following a low-dose exposure, we observed in EA.hy926 EC and HMVECs a discontinuous expression and enzymatic activity of GPx concomitant with a lowered expression and DNA binding activity of Nrf2 that was most pronounced at a dose of 0.5 Gy. Scavenging of ROS by NAC and activation of Nrf2 by AI-1 significantly diminished a lowered adhesion of PBMC to EC at a dose of 0.5 Gy. Conclusion: Low-dose irradiation resulted in a nonlinear expression and activity of major compounds of the antioxidative system that might contribute to anti-inflammatory effects in stimulated ECs. 0\n",
      "Aim: Conventional air insufflation (AI) may cause prolonged abdominal bloating, excessive abdominal pain and discomfort during colonoscopy. Carbon dioxide may be an acceptable alternative to avoid these complications. The object of this study was to evaluate systematically the effectiveness of carbon dioxide insufflation (CI) for colonoscopy compared with AI. Method: Randomized controlled trials (RCTs) comparing the effectiveness of CI with that of AI during colonoscopy were retrieved from medical electronic databases and combined analysis was performed using the RevMan statistical package. The combined outcome of dichotomous and continuous variables was expressed as an odds ratio (OR) and standardized mean difference (SMD). Results: Twenty-one RCTs comprising 3607 patients were included in the study. There was statistically significant heterogeneity among included studies. CI showed a significant trend towards reduced procedural pain [SMD -1.34; 95% confidence interval (95% CI) -2.23 to -0.45; z = 2.96; P < 0.003] and also postprocedural pain at 1 h (SMD -1.11; 95% CI -1.83 to -0.38; z = 2.97; P < 0.003), 6 and 24 h (OR 0.44; 95% CI 0.23-0.85; z = 2.44; P < 0.01). CI was associated with faster caecal intubation (SMD -0.20; 95% CI -0.37 to -0.02; z = 2.23; P < 0.03) but the caecal intubation rate was similar (P = 0.59) in both colonic insufflation techniques. Conclusion: CI seems to have clinical advantages over AI for colonoscopy with regard to pain during and after the procedure. 0\n",
      "COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a pandemic by the World Health Organization, which has reported over 18 million confirmed cases as of August 5, 2020. In this review, we present an overview of recent studies using Machine Learning and, more broadly, Artificial Intelligence, to tackle many aspects of the COVID-19 crisis. We have identified applications that address challenges posed by COVID-19 at different scales, including: molecular, by identifying new or existing drugs for treatment; clinical, by supporting diagnosis and evaluating prognosis based on medical imaging and non-invasive measures; and societal, by tracking both the epidemic and the accompanying infodemic using multiple data sources. We also review datasets, tools, and resources needed to facilitate Artificial Intelligence research, and discuss strategic considerations related to the operational implementation of multidisciplinary partnerships and open science. We highlight the need for international cooperation to maximize the potential of AI in this and future pandemics. 0\n",
      "Humans with good health condition is some more difficult in today’s life, because of changing food habit and environment. So we need awareness about the health condition to the survival. The health-support systems faces significant challenges like lack of adequate medical information, preventable errors, data threat, misdiagnosis, and delayed transmission. To overcome this problem, here we proposed wearable sensor which is connected to Internet of things (IoT) based big data i.e. data mining analysis in healthcare. Moreover, here we design Generalize approximate Reasoning base Intelligence Control (GARIC) with regression rules to gather the information about the patient from the IoT. Finally, Train the data to the Artificial intelligence (AI) with the use of deep learning mechanism Boltzmann belief network. Subsequently Regularization _ Genome wide association study (GWAS) is used to predict the diseases. Thus, if the people has affected by some diseases they will get warning by SMS, emails. Etc., after that they got some treatments and advisory from the doctors. 0\n",
      "Background: Artificial intelligence (AI) and the Internet of Intelligent Things (IIoT) are promising technologies to prevent the concerningly rapid spread of coronavirus disease (COVID-19) and to maximize safety during the pandemic. With the exponential increase in the number of COVID-19 patients, it is highly possible that physicians and health care workers will not be able to treat all cases. Thus, computer scientists can contribute to the fight against COVID-19 by introducing more intelligent solutions to achieve rapid control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes the disease. Objective: The objectives of this review were to analyze the current literature, discuss the applicability of reported ideas for using AI to prevent and control COVID-19, and build a comprehensive view of how current systems may be useful in particular areas. This may be of great help to many health care administrators, computer scientists, and policy makers worldwide. Methods: We conducted an electronic search of articles in the MEDLINE, Google Scholar, Embase, and Web of Knowledge databases to formulate a comprehensive review that summarizes different categories of the most recently reported AI-based approaches to prevent and control the spread of COVID-19. Results: Our search identified the 10 most recent AI approaches that were suggested to provide the best solutions for maximizing safety and preventing the spread of COVID-19. These approaches included detection of suspected cases, large-scale screening, monitoring, interactions with experimental therapies, pneumonia screening, use of the IIoT for data and information gathering and integration, resource allocation, predictions, modeling and simulation, and robotics for medical quarantine. Conclusions: We found few or almost no studies regarding the use of AI to examine COVID-19 interactions with experimental therapies, the use of AI for resource allocation to COVID-19 patients, or the use of AI and the IIoT for COVID-19 data and information gathering/integration. Moreover, the adoption of other approaches, including use of AI for COVID-19 prediction, use of AI for COVID-19 modeling and simulation, and use of AI robotics for medical quarantine, should be further emphasized by researchers because these important approaches lack sufficient numbers of studies. Therefore, we recommend that computer scientists focus on these approaches, which are still not being adequately addressed. 0\n",
      "The continuous improvements in the area of medical imaging, makes the patient monitoring a crucial concern. The internet of things (IoT) embedded in a medical technologies to collect data from human body through sensors, wireless connectivity etc. The junction of medicine and IT like medical informatics will transform healthcare, curbing cost, make more efficient, and saving lives. Various computerized techniques are implemented in the area of Artificial Intelligence (AI) for the application of medical imaging to diagnose the infected regions in the images and videos such as WCE and pathology. The famous stomach infections are ulcer, polyp, and bleeding. Stomach cancer is the most common infection and a leading cause of human deaths worldwide. In the USA, since 2019, a total of 27,510 new cases are reported including 17,230 men and 10,230 women. While the number of deaths is 11,140 consists of 6,800 men and 4,340 women. The manual diagnosis of these stomach infections is a difficult and agitated process therefore it is required to design a fully automated system using AI. In this article, we presented a fully automated system for stomach infection recognition based on deep learning features fusion and selection. In this design, ulcer images are assigned manually and support to a saliency-based method for ulcer detection. Later, pre-trained deep learning model named VGG16 is employing and re-trained using transfer learning. Features of re-trained model are extracted from two consecutive fully connected layers and fused by array-based approach. Besides, the best individuals are selected through the metaheuristic approach name PSO along mean value-based fitness function. The selected individuals are finally recognized through Cubic SVM. The experiments are conducted on Private collected dataset and achieved an accuracy of 98.4%, which is best as compared to existing state-of-the-art techniques. 0\n",
      "The aim of this paper is to present several approaches by which technology can assist medical decision-making. This is an essential, but also a difficult activity, which implies a large number of medical and technical aspects. But, more important, it involves humans: on the one hand, the patient, who has a medical problem and who requires the best solution; on the other hand, the physician, who should be able to provide, in any circumstances, a decision or a prediction regarding the current and the future medical status of the patient. The technology, in general, and particularly the Artificial Intelligence (AI) tools could help both of them, and it is assisted by appropriate theory regarding modeling tools. One of the most powerful mechanisms that can be used in this field is the Artificial Neural Networks (ANNs). This paper presents some of the results obtained by the Process Control group of the Politehnica University Timisoara, Romania, in the field of ANNs applied to modeling, prediction and decision-making related to medical systems. An Iterative Learning Control-based approach to batch training a feedforward ANN architecture is given. The paper includes authors’ concerns in this domain and emphasizes that these intelligent models, even if they are artificial, are able to make decisions, being useful tools for prevention, early detection and personalized healthcare. 0\n",
      "Artificial intelligence (AI) is increasingly being developed for use in medicine, including for diagnosis and in treatment decision making. The use of AI in medical treatment raises many ethical issues that are yet to be explored in depth by bioethicists. In this paper, I focus specifically on the relationship between the ethical ideal of shared decision making and AI systems that generate treatment recommendations, using the example of IBM's Watson for Oncology. I argue that use of this type of system creates both important risks and significant opportunities for promoting shared decision making. If value judgements are fixed and covert in AI systems, then we risk a shift back to more paternalistic medical care. However, if designed and used in an ethically informed way, AI could offer a potentially powerful way of supporting shared decision making. It could be used to incorporate explicit value reflection, promoting patient autonomy. In the context of medical treatment, we need value-flexible AI that can both respond to the values and treatment goals of individual patients and support clinicians to engage in shared decision making. 0\n",
      "Context: The prevalence of phenotypic females with a 46,XY karyotype is low, thus current knowledge about age and clinical presentation at diagnosis is sparse even for the most frequent conditions, androgen insensitivity syndrome (AIS), and gonadal dysgenesis. Objective: To estimate incidence, prevalence, age at diagnosis, and clinical presentation at diagnosis in 46,XY females. Design and Setting: A nationwide study covering all known females with a 46,XY karyotype in Denmarksince 1960.Thediagnosis of 46,XY disorder of sex development (DSD)wasdetermined by medical record evaluation, data from the Danish National Patient Registry, and genetic testing, if available. Patients: A total of 166 females registered as 46,XY females in the Danish Cytogenetic Central Registry were identified. Results:Atotal of 124 females were classified as having 46,XY DSD, 78 with AIS and 25 with gonadal dysgenesis, whereas the remaining subjects had a variety of different diagnoses. The prevalence of 46,XY females was 6.4 per 100 000 live born females, and for AIS and gonadal dysgenesis, it was 4.1 and 1.5 per 100 000, respectively. Median age at diagnosis was 7.5 years (95% confidence interval, 4.0 -13.5; range, 0-34 y) in AIS and 17.0 years (95% confidence interval, 15.5-19.0; range, 0-28 y) in gonadal dysgenesis (P = .001). Clinical presentation was dependent on cause of DSD. Conclusions: The first estimate on prevalence of 46,XY females is 6.4 per 100 000 live born females. The presentation of AIS and gonadal dysgenesis is distinctly different, with AIS being diagnosed during childhood and gonadal dysgenesis during pubertal years. The presenting phenotype is dependent on the cause of 46,XY DSD. 0\n",
      "Objective: To assess cardiometabolic syndrome (CMS) risk definitions in spinal cord injury/disease (SCI/D). Design: Cross-sectional analysis of a pooled sample. Setting: Two SCI/D academic medical and rehabilitation centers. Participants: Baseline data from subjects in 7 clinical studies were pooled; not all variables were collected in all studies; therefore, participant numbers varied from 119 to 389. The pooled sample included men (79%) and women (21%) with SCI/D >1 year at spinal cord levels spanning C3-T2 (American Spinal Injury Association Impairment Scale [AIS] grades A–D). Interventions: Not applicable. Main Outcome Measures: We computed the prevalence of CMS using the American Heart Association/National Heart, Lung, and Blood Institute guideline (CMS diagnosis as sum of risks ≥3 method) for the following risk components: overweight/obesity, insulin resistance, hypertension, and dyslipidemia. We compared this prevalence with the risk calculated from 2 routinely used nonguideline CMS risk assessments: (1) key cut scores identifying insulin resistance derived from the homeostatic model 2 (HOMA2) method or quantitative insulin sensitivity check index (QUICKI), and (2) a cardioendocrine risk ratio based on an inflammation (C-reactive protein [CRP])–adjusted total cholesterol/high-density lipoprotein cholesterol ratio. Results: After adjustment for multiple comparisons, injury level and AIS grade were unrelated to CMS or risk factors. Of the participants, 13% and 32.1% had CMS when using the sum of risks or HOMA2/QUICKI model, respectively. Overweight/obesity and (pre)hypertension were highly prevalent (83% and 62.1%, respectively), with risk for overweight/obesity being significantly associated with CMS diagnosis (sum of risks, χ2=10.105; adjusted P=.008). Insulin resistance was significantly associated with CMS when using the HOMA2/QUICKI model (χ22=21.23, adjusted P<.001). Of the subjects, 76.4% were at moderate to high risk from elevated CRP, which was significantly associated with CMS determination (both methods; sum of risks, χ22=10.198; adjusted P=.048 and HOMA2/QUICKI, χ22=10.532; adjusted P=.04). Conclusions: As expected, guideline-derived CMS risk factors were prevalent in individuals with SCI/D. Overweight/obesity, hypertension, and elevated CRP were common in SCI/D and, because they may compound risks associated with CMS, should be considered population-specific risk determinants. Heightened surveillance for risk, and adoption of healthy living recommendations specifically directed toward weight reduction, hypertension management, and inflammation control, should be incorporated as a priority for disease prevention and management. 0\n",
      "Bacterial cell-cell communication (quorum sensing, QS) represents a fundamental process crucial for biofilm formation, pathogenicity, and virulence allowing coordinated, concerted actions of bacteria depending on their cell density. With the widespread appearance of antibiotic-resistance of biofilms, there is an increasing need for novel strategies to control harmful biofilms. One attractive and most likely effective approach is to target bacterial communication systems for novel drug design in biotechnological and medical applications. In this study, metagenomic large-insert libraries were constructed and screened for QS interfering activities (quorum quenching, QQ) using recently established reporter strains. Overall, 142 out of 46,400 metagenomic clones were identified to interfere with acyl-homoserine lactones (AHLs), 13 with autoinducer-2 (AI-2). Five cosmid clones with highest simultaneous interfering activities were further analyzed and the respective open reading frames conferring QQ activities identified. Those showed homologies to bacterial oxidoreductases, proteases, amidases and aminotransferases. Evaluating the ability of the respective purified QQ-proteins to prevent biofilm formation of several model systems demonstrated highest inhibitory effects of QQ-2 using the crystal violet biofilm assay. This was confirmed by heterologous expression of the respective QQ proteins in Klebsiella oxytoca M5a1 and monitoring biofilm formation in a continuous flow cell system. Moreover, QQ-2 chemically immobilized to the glass surface of the flow cell effectively inhibited biofilm formation of K. oxytoca as well as clinical K. pneumoniae isolates derived from patients with urinary tract infections. Indications were obtained by molecular and biochemical characterizations that QQ-2 represents an oxidoreductase most likely reducing the signaling molecules AHL and AI-2 to QS-inactive hydroxy-derivatives. Overall, we propose that the identified novel QQ-2 protein efficiently inhibits AI-2 modulated biofilm formation by modifying the signal molecule; and thus appears particularly attractive for medical and biotechnological applications. 0\n",
      "Objective. This study was conducted to associate tourniquet use and survival in casualty care over a decade of war in order to provide evidence to emergency medical personnel for the implementation and efficacy of tourniquet use in a large trauma system. Methods. This survey is a retrospective review of data extracted from a trauma registry. The decade (2001-2010) outcome trend analysis of tourniquet use in the current wars was made in order to associate tourniquet use and survival in an observational cohort design. Results. Of 4,297 casualties with extremity trauma in the total study, 30% (1,272/4,297) had tourniquet use and 70% (3,025/4,297) did not. For all 4,297 casualties, the proportion of casualties with severe or critical extremity Abbreviated Injury Scales (AIS) increased during the years surveyed (p < 0.0001); the mean annual Injury Severity Score (ISS) rose from 13 to 21. Tourniquet use increased during the decade by almost tenfold from 4 to nearly 40% (p < 0.0001). Survival for casualties with isolated extremity injury varied by injury severity; the survival rate for AIS 3 (serious) was 98%, the rate for AIS 4 (severe) was 76%, and the rate for AIS 5 (critical) was 0%. Survival rates increased for casualties with injuries amenable to tourniquets but decreased for extremity injuries too proximal for tourniquets. Conclusions. Average injury severity increased during the decade of war for casualties with extremity injury. Both tourniquet use rates and casualty survival rates rose when injuries were amenable to tourniquets. 0\n",
      "Despite advances in artificial intelligence (AI), its application in medical imaging has been burdened and limited by expert-generated labels. We used images from optical coherence tomography angiography (OCTA), a relatively new imaging modality that measures retinal blood flow, to train an AI algorithm to generate flow maps from standard optical coherence tomography (OCT) images, exceeding the ability and bypassing the need for expert labeling. Deep learning was able to infer flow from single structural OCT images with similar fidelity to OCTA and significantly better than expert clinicians (P < 0.00001). Our model allows generating flow maps from large volumes of previously collected OCT data in existing clinical trials and clinical practice. This finding demonstrates a novel application of AI to medical imaging, whereby subtle regularities between different modalities are used to image the same body part and AI is used to generate detailed inferences of tissue function from structure imaging. 0\n",
      "Digital medicine, digital research and artificial intelligence (AI) have the power to transform the field of diabetes with continuous and no-burden remote monitoring of patients’ symptoms, physiological data, behaviours, and social and environmental contexts through the use of wearables, sensors and smartphone technologies. Moreover, data generated online and by digital technologies – which the authors suggest be grouped under the term ‘digitosome’ – constitute, through the quantity and variety of information they represent, a powerful potential for identifying new digital markers and patterns of risk that, ultimately, when combined with clinical data, can improve diabetes management and quality of life, and also prevent diabetes-related complications. Moving from a world in which patients are characterized by only a few recent measurements of fasting glucose levels and glycated haemoglobin to a world where patients, healthcare professionals and research scientists can consider various key parameters at thousands of time points simultaneously will profoundly change the way diabetes is prevented, managed and characterized in patients living with diabetes, as well as how it is scientifically researched. Indeed, the present review looks at how the digitization of diabetes can impact all fields of diabetes – its prevention, management, technology and research – and how it can complement, but not replace, what is usually done in traditional clinical settings. Such a profound shift is a genuine game changer that should be embraced by all, as it can provide solid research results transferable to patients, improve general health literacy, and provide tools to facilitate the everyday decision-making process by both healthcare professionals and patients living with diabetes. 0\n",
      "Artificial intelligence (AI) software that analyzes medical images is becoming increasingly prevalent. Unlike earlier generations of AI software, which relied on expert knowledge to identify imaging features, machine learning approaches automatically learn to recognize these features. However, the promise of accurate personalized medicine can only be fulfilled with access to large quantities of medical data from patients. This data could be used for purposes such as predicting disease, diagnosis, treatment optimization, and prognostication. Radiology is positioned to lead development and implementation of AI algorithms and to manage the associated ethical and legal challenges. This white paper from the Canadian Association of Radiologists provides a framework for study of the legal and ethical issues related to AI in medical imaging, related to patient data (privacy, confidentiality, ownership, and sharing); algorithms (levels of autonomy, liability, and jurisprudence); practice (best practices and current legal framework); and finally, opportunities in AI from the perspective of a universal health care system. 0\n",
      "In the cloud-based Internet of Things (IoT) environments, quantifying uncertainty is an important element input to keep the acceptable level of reliability in various configurations. In this paper, we aim to address the pricing model of delivering data over the cloud while taking into consideration the dynamic uncertainty factors such as network topology, transmission/reception energy, nodal charge and power, and computation capacity. These uncertainty factors are mapped to different nodes with varying capabilities to be processed using Artificial Intelligence (AI)-based algorithms. Accordingly, we aim to find a way to calculate and predict the price per big data service over the cloud using AI and deep learning. Therefore, in this paper, we propose a framework to address big data delivery issues in cloud-based IoT environments by considering uncertainty factors. We compare the performance of the framework using two AI-based techniques called Genetic Algorithm (GA) and Simulated Annealing Algorithm (SAA) in both centralized and distributed versions. The use of AI techniques can be applied in multilevel to provide a kind of deep learning to further improve the performance of the system under study. The results reveal that the distributed algorithm outperforms the centralized one. In addition, the results show that the GA has lower running time compared to the SAA in all the test cases such as 68% of improvement in the centralized version, and 66% of improvement in the distributed version in case when the size of uncertainty array is 256. Moreover, when the size of uncertainty array increases, the results show 60% speed up in the distributed GA compared to its centralized version. The improvements achieved would help the service providers to actually improve their profit using the proposed framework. 0\n",
      "The applications of modern artificial intelligence (AI) algorithms within the field of aging research offer tremendous opportunities. Aging is an almost universal unifying feature possessed by all living organisms, tissues, and cells. Modern deep learning techniques used to develop age predictors offer new possibilities for formerly incompatible dynamic and static data types. AI biomarkers of aging enable a holistic view of biological processes and allow for novel methods for building causal models—extracting the most important features and identifying biological targets and mechanisms. Recent developments in generative adversarial networks (GANs) and reinforcement learning (RL) permit the generation of diverse synthetic molecular and patient data, identification of novel biological targets, and generation of novel molecular compounds with desired properties and geroprotectors. These novel techniques can be combined into a unified, seamless end-to-end biomarker development, target identification, drug discovery and real world evidence pipeline that may help accelerate and improve pharmaceutical research and development practices. Modern AI is therefore expected to contribute to the credibility and prominence of longevity biotechnology in the healthcare and pharmaceutical industry, and to the convergence of countless areas of research. 0\n",
      "Introduction C ompleted randomized trials on endovascular thrombectomy (ET) did not independently assess the efficacy of ET in the elderly (≥80 years old) who were often excluded or under-represented in trials. There were also inconsistent criteria for patient selection in this population across the different trials. This work evaluates outcomes after ET for acute ischemic stroke (AIS) in the elderly at a high volume stroke center. Methods We reviewed all cases of AIS that underwent a direct aspiration first pass technique (ADAPT) thrombectomy for large vessel occlusions between March 2013 and October 2017 while comparing outcomes in the elderly with younger counterparts. We also reviewed AIS cases in elderly patients undergoing medical management who were matched to the ET counterparts by demographics, comorbidities, baseline deficits, and stroke severity. Results Of 560 patients undergoing ET for AIS, 108 patients were in the elderly group (≥80 years of age), and had a significantly lower likelihood of functional independence (defined as a modified Rankin Scale score of 0-2) at 90 days compared with younger patients (20.5% vs 44.4%, P<0.001), and higher mortality rates (34.3% vs 20%, P<0.001). When compared with patients undergoing medical management, elderly patients did not have a significant improvement in rates of good outcomes (20.5% vs 19.5%, P>0.05), and had significantly higher rates of hemorrhage (40.7% vs 9.3%, P<0.001). We also identified baseline stroke severity and the incidence of hemorrhage as two independent predictors of outcome in the elderly patients. Conclusions E T in the elderly did not show a similar benefit to younger patients when compared with medical management. These findings emphasize the need for more optimal selection criteria for the elderly population to improve the risk to benefit ratio of ET. 0\n",
      "Artificial intelligence (AI) is a commonly used term in daily life, and there are now two subconcepts that divide the entire range of meanings currently encompassed by the term. The coexistence of the concepts of strong and weak AI can be seen as a result of the recognition of the limits of mathematical and engineering concepts that have dominated the definition. This presentation reviewed the concept, history, and the current application of AI in daily life. Applications of AI are becoming a reality that is commonplace in all areas of modern human life. Efforts to develop robots controlled by AI have been continuously carried out to maximize human convenience. AI has also been applied in the medical decision-making process, and these AI systems can help nonspecialists to obtain expert-level information. Artificial neural networks are highly interconnected networks of computer processors inspired by biological nervous systems. These systems may help connect dental professionals all over the world. Currently, the use of AI is rapidly advancing beyond text-based, image-based dental practice. This presentation reviewed the history of artificial neural networks in the medical and dental fields, as well as current application in dentistry. As the use of AI in the entire medical field increases, the role of AI in dentistry will be greatly expanded. Currently, the use of AI is rapidly advancing beyond text-based, image-based dental practice. In addition to diagnosis of visually confirmed dental caries and impacted teeth, studies applying machine learning based on artificial neural networks to dental treatment through analysis of dental magnetic resonance imaging, computed tomography, and cephalometric radiography are actively underway, and some visible results are emerging at a rapid pace for commercialization. 0\n",
      "With the emergence of unmanned plane, autonomous vehicles, face recognition, and language processing, the artificial intelligence (AI) has remarkably revolutionized our lifestyle. Recent studies indicate that AI has astounding potential to perform much better than human beings in some tasks, especially in the image recognition field. As the amount of image data in imaging center of ophthalmology is increasing dramatically, analyzing and processing these data is in urgent need. AI has been tried to apply to decipher medical data and has made extraordinary progress in intelligent diagnosis. In this paper, we presented the basic workflow for building an AI model and systematically reviewed applications of AI in the diagnosis of eye diseases. Future work should focus on setting up systematic AI platforms to diagnose general eye diseases based on multimodal data in the real world. 0\n",
      "The effects of long-term replacement therapy of adrenal insufficiency (AI) are still a matter of controversy. In fact, the established glucocorticoid replacement regimens do not completely reproduce the endogenous hormonal production and the monitoring of AI treatment may be a challenge for the lack of reliable clinical and biochemical markers. Consequently, several AI patients are frequently exposed to relative glucocorticoid excess potentially leading to develop chronic complications, such as diabetes mellitus, dyslipidemia, hypertension and fragility fractures with consequent impaired QoL and increased mortality risk. This review deals with the pathophysiological and clinical aspects concerning the over-replacement therapy of primary and secondary AI. 0\n",
      "Aims: To review the outcomes of studies and the safety of newer transcatheter aortic valves (THV). Methods and results: All studies reporting on second-generation THV were identified and pooled using the systematic review guidelines. Twenty-four reports on 1,708 patients and eight THV were included in the analysis. The pooled 30-day event rate for mortality after transcatheter aortic valve implantation (TAVI) was 5.7% (95% CI: 4.0-7.8), myocardial infarction (MI) was 1.7% (95% CI: 1.1-2.6), stage 3 acute kidney injury (AKI) was 3.4% (95% CI: 2.0-5.6), life-threatening bleeding was 5.1% (95% CI: 3.3-7.8), major vascular complications was 4.9% (95% CI: 3.5-6.6%), major bleeding was 10.5% (95% CI: 5.1-20.4), major stroke was 2.4% (95% CI: 1.7-3.4), permanent pacemaker utilisation was 13.5% (95% CI: 10.8-16.9), and coronary obstruction was 1.2% (95% CI: 0.6%-2.4%). Moderate or severe aortic insufficiency (AI) after TAVI was 4.2% (95% CI: 2.0-8.5). The pooled 30-day mean gradient and effective orifice area (EOA) were 11.63 mmHg (95% CI: 10.19-13.07) and 1.60 cm2 (95% CI: 1.5-1.7), respectively. All estimates compare favourably to events reported for first-generation valves. Conclusions: Our findings suggest that the new THV have a low risk of TAVI-related short-term complications. 0\n",
      "Background: Violence is a leading cause of injury among youth 15-24. years and is frequently associated with drug use. To inform optimal violence interventions, it is critical to understand the baseline characteristics and intent to retaliate of drug-using, assault-injured (AI) youth in the Emergency Department (ED) setting, where care for violent injury commonly occurs. Methods: At an urban ED, AI youth ages 14-24 endorsing any past six-month substance use (n. =. 350), and a proportionally-sampled substance-using comparison group (CG) presenting for non-assault-related care (n. =. 250), were recruited and completed a baseline assessment (82% participation). Medical chart review was also conducted. Conditional logistic regression was performed to examine correlates associated with AI. Results: Over half (57%) of all youth met the criteria for drug and/or alcohol use disorder, with only 9% receiving prior treatment. Among the AI group, 1 in 4 intended to retaliate, of which 49% had firearm access. From bivariate analyses, AI youth had poorer mental health, greater substance use, and were more likely to report prior ED visits for assault or psychiatric evaluation. Based on multivariable modeling, AI youth had greater odds of being on probation/parole (AOR. =. 2.26; CI. =. 1.28, 3.90) and having PTSD (AOR. =. 1.88; CI. =. 1.01, 3.50) than the CG. Conclusions: AI youth may have unmet needs for substance use and mental health treatment, including PTSD. These characteristics along with the risk of retaliation, increased ED service utilization, low utilization of other health care venues, and firearm access highlight the need for interventions that initiate at the time of ED visit. 0\n",
      "This paper describes a framework using disruptive technologies for COVID-19 analysis. Disruptive technologies include high-tech and emerging technologies such as AI, industry 4.0, IoT, Internet of Medical Things (IoMT), big data, virtual reality (VR), Drone technology, and Autonomous Robots, 5 G, and blockchain to offer digital transformation, research and development and service delivery. Disruptive technologies are essential for Industry 4.0 development, which can be applied to many disciplines. In this paper, we present a framework that uses disruptive technologies for COVID-19 analysis. The proposed framework restricts the spread of COVID-19 outbreaks, ensures the safety of the healthcare teams and maintains patients' physical and psychological healthcare conditions. The framework is designed to deal with the severe shortage of PPE for the medical team, reduce the massive pressure on hospitals, and track recovered patients to treat COVID-19 patients with plasma. The study provides oversight for governments on how to adopt technologies to reduce the impact of unprecedented outbreaks for COVID-19. Our work illustrates an empirical case study on the analysis of real COVID-19 patients and shows the importance of the proposed intelligent framework to limit the current outbreaks for COVID-19. The aim is to help the healthcare team make rapid decisions to treat COVID-19 patients in hospitals, home quarantine, or identifying and treating patients with typical cold or flu. 0\n",
      "Background and aim: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario. Methods: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are ‘COVID-19′, ’ AI ′, and ‘Drug Repurposing’. Results: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool. Conclusions: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly. 0\n",
      "Background: Acute treatment of cerebral edema and elevated intracranial pressure is a common issue in patients with neurological injury. Practical recommendations regarding selection and monitoring of therapies for initial management of cerebral edema for optimal efficacy and safety are generally lacking. This guideline evaluates the role of hyperosmolar agents (mannitol, HTS), corticosteroids, and selected non-pharmacologic therapies in the acute treatment of cerebral edema. Clinicians must be able to select appropriate therapies for initial cerebral edema management based on available evidence while balancing efficacy and safety. Methods: The Neurocritical Care Society recruited experts in neurocritical care, nursing, and pharmacy to create a panel in 2017. The group generated 16 clinical questions related to initial management of cerebral edema in various neurological insults using the PICO format. A research librarian executed a comprehensive literature search through July 2018. The panel screened the identified articles for inclusion related to each specific PICO question and abstracted necessary information for pertinent publications. The panel used GRADE methodology to categorize the quality of evidence as high, moderate, low, or very low based on their confidence that the findings of each publication approximate the true effect of the therapy. Results: The panel generated recommendations regarding initial management of cerebral edema in neurocritical care patients with subarachnoid hemorrhage, traumatic brain injury, acute ischemic stroke, intracerebral hemorrhage, bacterial meningitis, and hepatic encephalopathy. Conclusion: The available evidence suggests hyperosmolar therapy may be helpful in reducing ICP elevations or cerebral edema in patients with SAH, TBI, AIS, ICH, and HE, although neurological outcomes do not appear to be affected. Corticosteroids appear to be helpful in reducing cerebral edema in patients with bacterial meningitis, but not ICH. Differences in therapeutic response and safety may exist between HTS and mannitol. The use of these agents in these critical clinical situations merits close monitoring for adverse effects. There is a dire need for high-quality research to better inform clinicians of the best options for individualized care of patients with cerebral edema. 0\n",
      "As the efficacy of artificial intelligence (AI) in improving aspects of healthcare delivery is increasingly becoming evident, it becomes likely that AI will be incorporated in routine clinical care in the near future. This promise has led to growing focus and investment in AI medical applications both from governmental organizations and technological companies. However, concern has been expressed about the ethical and regulatory aspects of the application of AI in health care. These concerns include the possibility of biases, lack of transparency with certain AI algorithms, privacy concerns with the data used for training AI models, and safety and liability issues with AI application in clinical environments. While there has been extensive discussion about the ethics of AI in health care, there has been little dialogue or recommendations as to how to practically address these concerns in health care. In this article, we propose a governance model that aims to not only address the ethical and regulatory issues that arise out of the application of AI in health care, but also stimulate further discussion about governance of AI in health care. 0\n",
      "INTRODUCTION: Artificial intelligence (AI) technologies continue to attract interest from a broad range of disciplines in recent years, including health. The increase in computer hardware and software applications in medicine, as well as digitization of health-related data together fuel progress in the development and use of AI in medicine. This progress provides new opportunities and challenges, as well as directions for the future of AI in health. OBJECTIVE: The goals of this survey are to review the current state of AI in health, along with opportunities, challenges, and practical implications. This review highlights recent developments over the past five years and directions for the future. METHODS: Publications over the past five years reporting the use of AI in health in clinical and biomedical informatics journals, as well as computer science conferences, were selected according to Google Scholar citations. Publications were then categorized into five different classes, according to the type of data analyzed. RESULTS: The major data types identified were multi-omics, clinical, behavioral, environmental and pharmaceutical research and development (R&D) data. The current state of AI related to each data type is described, followed by associated challenges and practical implications that have emerged over the last several years. Opportunities and future directions based on these advances are discussed. CONCLUSION: Technologies have enabled the development of AI-assisted approaches to healthcare. However, there remain challenges. Work is currently underway to address multi-modal data integration, balancing quantitative algorithm performance and qualitative model interpretability, protection of model security, federated learning, and model bias. 0\n",
      "Introduction: Endometriosis is a hormone-dependent benign chronic disease that requires a chronic medical therapy. Although currently available drugs are efficacious in treating endometriosis-related pain, some women experience partial or no improvement. Moreover, the recurrence of symptoms is expected after discontinuation of the therapies. Currently, new drugs are under intense clinical investigation for the treatment of endometriosis. Areas covered: This review aims to offer the reader a complete and updated overview on new investigational drugs and early molecular targets for the treatment of endometriosis. The authors describe the pre-clinical and clinical development of these agents. Expert opinion: Among the drugs under investigation, late clinical trials on gonadotropin-releasing hormone antagonists (GnRH-ant) showed the most promising results for the treatment of endometriosis. Aromatase inhibitors (AIs) are efficacious in treating endometriosis related pain symptoms but they cause significant adverse effects that limit their long-term use. New targets have been identified to produce drugs for the treatment of endometriosis, but the majority of these new compounds have only been investigated in laboratory studies or early clinical trials. Thus, further clinical research is required in order to elucidate their efficacy and safety in human. 0\n",
      "Sellar and parasellar masses are a common finding, and most of them are treated surgically via transsphenoidal approach. This type of surgery has revolutionized the approach to several hypothalamic-pituitary diseases and is usually effective, and well-tolerated by the patient. However, given the complex anatomy and high density of glandular, neurological and vascular structures in a confined space, transsphenoidal surgery harbors a substantial risk of complications. Hypopituitarism is one of the most frequent sequelae, with central adrenal insufficiency being the deficit that requires a timely diagnosis and treatment. The perioperative management of AI is influenced by the preoperative status of the hypothalamic–pituitary–adrenal axis. Disorders of water metabolism are another common complication, and they can span from diabetes insipidus, to the syndrome of inappropriate antidiuretic hormone secretion, up to the rare cerebral salt-wasting syndrome. These abnormalities are often transient, but require careful monitoring and management in order to avoid abrupt variations of blood sodium levels. Cerebrospinal fluid leaks, damage to neurological structures such as the optic chiasm, and vascular complications can worsen the postoperative course after transsphenoidal surgery as well. Finally, long-term follow up after surgery varies depending on the underlying pathology, and is most challenging in patients with acromegaly and Cushing disease, in whom failure of primary pituitary surgery is a major concern. When these pituitary functioning adenomas persist or relapse after neurosurgery other treatment options are considered, including repeated surgery, radiotherapy, and medical therapy. 0\n",
      "BACKGROUND: Defining laboratory biomarker reference values in a healthy population and understanding the fluctuations in biomarker concentrations throughout life and between sexes are critical to clinical interpretation of laboratory test results in different disease states. The Canadian Health Measures Survey (CHMS) has collected blood samples and health information from the Canadian household population. In collaboration with the Canadian Laboratory Initiative on Pediatric Reference Intervals (CALIPER), the data have been analyzed to determine reference value distributions and reference intervals for several endocrine and special chemistry biomarkers in pediatric, adult, and geriatric age groups. METHODS: CHMS collected data and blood samples from thousands of community participants aged 3 to 79 years. We used serum samples to measure 13 immunoassay-based special chemistry and endocrine markers. We assessed reference value distributions and, after excluding outliers, calculated age- and sexspecific reference intervals, along with corresponding 90% CIs, according to CLSI C28-A3 guidelines. RESULTS: We observed fluctuations in biomarker reference values across the pediatric, adult, and geriatric age range, with stratification required on the basis of age for all analytes. Additional sex partitions were required for apolipoprotein AI, homocysteine, ferritin, and high sensitivity C-reactive protein. CONCLUSIONS: The unique collaboration between CALIPER and CHMS has enabled, for the first time, a detailed examination of the changes in various immunochemical markers that occur in healthy individuals of different ages. The robust age- and sex-specific reference intervals established in this study provide insight into the complex biological changes that take place throughout development and aging and will contribute to improved clinical test interpretation. 0\n",
      "Artificial intelligence (AI) is the development of computer systems that are able to perform tasks that normally require human intelligence. Advances in AI software and hardware, especially deep learning algorithms and the graphics processing units (GPUs) that power their training, have led to a recent and rapidly increasing interest in medical AI applications. In clinical diagnostics, AI-based computer vision approaches are poised to revolutionize image-based diagnostics, while other AI subtypes have begun to show similar promise in various diagnostic modalities. In some areas, such as clinical genomics, a specific type of AI algorithm known as deep learning is used to process large and complex genomic datasets. In this review, we first summarize the main classes of problems that AI systems are well suited to solve and describe the clinical diagnostic tasks that benefit from these solutions. Next, we focus on emerging methods for specific tasks in clinical genomics, including variant calling, genome annotation and variant classification, and phenotype-to-genotype correspondence. Finally, we end with a discussion on the future potential of AI in individualized medicine applications, especially for risk prediction in common complex diseases, and the challenges, limitations, and biases that must be carefully addressed for the successful deployment of AI in medical applications, particularly those utilizing human genetics and genomics data. 0\n",
      "The sudden outbreak of novel coronavirus 2019 (COVID-19) increased the diagnostic burden of radiologists. In the time of an epidemic crisis, we hope artificial intelligence (AI) to reduce physician workload in regions with the outbreak, and improve the diagnosis accuracy for physicians before they could acquire enough experience with the new disease. In this paper, we present our experience in building and deploying an AI system that automatically analyzes CT images and provides the probability of infection to rapidly detect COVID-19 pneumonia. The proposed system which consists of classification and segmentation will save about 30%–40% of the detection time for physicians and promote the performance of COVID-19 detection. Specifically, working in an interdisciplinary team of over 30 people with medical and/or AI background, geographically distributed in Beijing and Wuhan, we are able to overcome a series of challenges (e.g. data discrepancy, testing time-effectiveness of model, data security, etc.) in this particular situation and deploy the system in four weeks. In addition, since the proposed AI system provides the priority of each CT image with probability of infection, the physicians can confirm and segregate the infected patients in time. Using 1,136 training cases (723 positives for COVID-19) from five hospitals, we are able to achieve a sensitivity of 0.974 and specificity of 0.922 on the test dataset, which included a variety of pulmonary diseases. 0\n",
      "The emergence of the 2019 novel coronavirus (COVID-19) which was declared a pandemic has spread to 210 countries worldwide. It has had a significant impact on health systems and economic, educational and social facets of contemporary society. As the rate of transmission increases, various collaborative approaches among stakeholders to develop innovative means of screening, detecting and diagnosing COVID-19’s cases among human beings at a commensurate rate have evolved. Further, the utility of computing models associated with the fourth industrial revolution technologies in achieving the desired feat has been highlighted. However, there is a gap in terms of the accuracy of detection and prediction of COVID-19 cases and tracing contacts of infected persons. This paper presents a review of computing models that can be adopted to enhance the performance of detecting and predicting the COVID-19 pandemic cases. We focus on big data, artificial intelligence (AI) and nature-inspired computing (NIC) models that can be adopted in the current pandemic. The review suggested that artificial intelligence models have been used for the case detection of COVID-19. Similarly, big data platforms have also been applied for tracing contacts. However, the nature-inspired computing (NIC) models that have demonstrated good performance in feature selection of medical issues are yet to be explored for case detection and tracing of contacts in the current COVID-19 pandemic. This study holds salient implications for practitioners and researchers alike as it elucidates the potentials of NIC in the accurate detection of pandemic cases and optimized contact tracing. 0\n",
      "Artificial Intelligence (AI) intent is to facilitate human limits. It is getting a standpoint on human administrations, filled by the growing availability of restorative clinical data and quick progression of insightful strategies. Motivated by the need to highlight the need for employing AI in battling the COVID-19 Crisis, this survey summarizes the current state of AI applications in clinical administrations while battling COVID-19. Furthermore, we highlight the application of Big Data while understanding this virus. We also overview various intelligence techniques and methods that can be applied to various types of medical information-based pandemic. We classify the existing AI techniques in clinical data analysis, including neural systems, classical SVM, and edge significant learning. Also, an emphasis has been made on regions that utilize AI-oriented cloud computing in combating various similar viruses to COVID-19. This survey study is an attempt to benefit medical practitioners and medical researchers in overpowering their faced difficulties while handling COVID-19 big data. The investigated techniques put forth advances in medical data analysis with an exactness of up to 90%. We further end up with a detailed discussion about how AI implementation can be a huge advantage in combating various similar viruses. 0\n",
      "Objective: To develop an artificial intelligence (AI)-based algorithm which can automatically detect food items from images acquired by an egocentric wearable camera for dietary assessment. Design: To study human diet and lifestyle, large sets of egocentric images were acquired using a wearable device, called eButton, from free-living individuals. Three thousand nine hundred images containing real-world activities, which formed eButton data set 1, were manually selected from thirty subjects. eButton data set 2 contained 29 515 images acquired from a research participant in a week-long unrestricted recording. They included both food- and non-food-related real-life activities, such as dining at both home and restaurants, cooking, shopping, gardening, housekeeping chores, taking classes, gym exercise, etc. All images in these data sets were classified as food/non-food images based on their tags generated by a convolutional neural network. Results: A cross data-set test was conducted on eButton data set 1. The overall accuracy of food detection was 91.5 and 86.4 %, respectively, when one-half of data set 1 was used for training and the other half for testing. For eButton data set 2, 74.0 % sensitivity and 87.0 % specificity were obtained if both 'food' and 'drink' were considered as food images. Alternatively, if only 'food' items were considered, the sensitivity and specificity reached 85.0 and 85.8 %, respectively. Conclusions: The AI technology can automatically detect foods from low-quality, wearable camera-acquired real-world egocentric images with reasonable accuracy, reducing both the burden of data processing and privacy concerns. 0\n",
      "Background: Risk stratification systems for thyroid nodules are often complicated and affected by low specificity. Continual improvement of these systems is necessary to reduce the number of unnecessary thyroid biopsies. Purpose: To use artificial intelligence (AI) to optimize the American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS). Materials and Methods: A total of 1425 biopsy-proven thyroid nodules from 1264 consecutive patients (1026 women; mean age, 52.9 years [range, 18-93 years]) were evaluated retrospectively. Expert readers assigned points based on five ACR TI-RADS categories (composition, echogenicity, shape, margin, echogenic foci), and a genetic AI algorithm was applied to a training set (1325 nodules). Point and pathologic data were used to create an optimized scoring system (hereafter, AI TI-RADS). Performance of the systems was compared by using a test set of the final 100 nodules with interpretations from the expert reader, eight nonexpert readers, and an expert panel. Initial performance of AI TI-RADS was calculated by using a test for differences between binomial proportions. Additional comparisons across readers were conducted by using bootstrapping; diagnostic performance was assessed by using area under the receiver operating curve. Results: AI TI-RADS assigned new point values for eight ACR TI-RADS features. Six features were assigned zero points, which simplified categorization. By using expert reader data, the diagnostic performance of ACR TI-RADS and AI TI-RADS was area under the receiver operating curve of 0.91 and 0.93, respectively. For the same expert, specificity of AI TI-RADS (65%, 55 of 85) was higher (P < .001) than that of ACR TI-RADS (47%, 40 of 85). For the eight nonexpert radiologists, mean specificity for AI TIRADS (55%) was also higher (P < .001) than that of ACR TI-RADS (48%). An interactive AI TI-RADS calculator can be viewed at http://deckard.duhs.duke.edu/~ai-ti-rads. Conclusion: An artificial intelligence-optimized Thyroid Imaging Reporting and Data System (TI-RADS) validates the American College of Radiology TI-RADS while slightly improving specificity and maintaining sensitivity. Additionally, it simplifies feature assignments, which may improve ease of use. 0\n",
      "Acute ischemic stroke (AIS) is among the leading causes of death and long-term disability. Intravenous tissue plasminogen activator has been the mainstay of acute therapy. Recently, several prospective randomized trials documented the value of endovascular revascularization in selected patients with large-vessel occlusion within the anterior circulation. This finding has led to a paradigm shift in the management of AIS, including wide adoption of noninvasive neuroimaging to assess vessel patency and tissue viability, with the supplemental and independent use of intravenous tissue plasminogen activator to improve clinical outcomes. In this article, we review the landmark studies on management of AIS and the current position on the diagnosis and management of AIS. The review also highlights the importance of early stabilization and prompt initiation of therapeutic interventions before, during, and after the diagnosis of AIS within and outside of the hospital. 0\n",
      "Background: Artificial intelligence (AI) is a rapidly developing computer technology that has begun to be widely used in the medical field to improve the professional level and efficiency of clinical work, in addition to avoiding medical errors. In developing countries, the inequality between urban and rural health services is a serious problem, of which the shortage of qualified healthcare providers is the major cause of the unavailability and low quality of healthcare in rural areas. Some studies have shown that the application of computer-assisted or AI medical techniques could improve healthcare outcomes in rural areas of developing countries. Therefore, the development of suitable medical AI technology for rural areas is worth discussing and probing. Methods: This article reviews and discusses the literature concerning the prospects of medical AI technology, the inequity of healthcare, and the application of computer-assisted or AI medical techniques in rural areas of developing countries. Results: Medical AI technology not only could improve physicians' efficiency and quality of medical services, but other health workers could also be trained to use this technique to compensate for the lack of physicians, thereby improving the availability of healthcare access and medical service quality. This article proposes a multilevel medical AI service network, including a frontline medical AI system (basic level), regional medical AI support centers (middle levels), and a national medical AI development center (top level). Conclusion: The promotion of medical AI technology in rural areas of developing countries might be one means of alleviating the inequality between urban and rural health services. The establishment of a multilevel medical AI service network system may be a solution. 0\n",
      "Background: Reporting accurate surgical complication rates to patients and their families is important in the management of adolescent idiopathic scoliosis (AIS). In this study, we report the rate of major complications following the surgical treatment of AIS both in the perioperative period and among patients with a minimum of 2 years of follow-up. Methods: We reviewed the prospectively collected data of a multicenter registry of patients who underwent surgical treatment of AIS during the period of 1995 to 2014 in order to identify all complications. A complication was defined as \"major\" if it resulted in reoperation or in spinal cord or nerve root injury, or was life-Threatening. A total of 3,582 patients with preoperative and early postoperative data (4 to 6 weeks of follow-up) were included. A subset of 2,220 patients with a minimum of 2 years of follow-up comprised the cohort for delayed complications. Overall complication rates were calculated, as was the percentage of complications according to the year of the index surgery and type of surgical approach. Results: The mean age of the 3,582 patients at the time of surgery was 14.8 ± 2.2 years. The average major curve magnitude was 56° ± 13° for thoracic curves and 51° ± 11° for lumbar. In 365 patients, anterior spinal fusion (ASF) with instrumentation was performed, and in 3,217 patients, posterior spinal fusion (PSF) with instrumentation was performed; 142 patients in the PSF group underwent concomitant anterior release. There were 192major complications, with 93 (2.6%) occurring perioperatively. Perioperative complications included wound-related (1.0% of the patients), neurologic (0.5%), pulmonary (0.4%), instrumentation-related (0.4%), and gastrointestinal (0.2%) complications. One patient died. The mean annual perioperativemajor complication rate based on the year of surgery ranged from0%to 10.5%. The complication rate by surgical approach was 3.0% for ASF and 2.6% for PSF (2.4% for PSF only and 5.6% for PSF with anterior release). The major complication rate for the 2,220 patients with at least 2 years of follow-up was 4.1%; all but 1 had a reoperation (4.1%). The majority of these major complications were wound and instrumentation-related (1.9% and 0.8%, respectively). Conclusions: After surgery for AIS, a 2.6% rate of perioperative major complications and a 4.1% rate of major complications at 2 or more years after surgery can be anticipated. The complication rate decreased over the period of study. Level of Evidence: Therapeutic Level IV. See Instructions for Authors for a complete description of levels of evidence. 0\n",
      "Study Design. Retrospective review of CT scan. Objective. To investigate the accuracy and safety of pedicle screws placed in adolescent idiopathic scoliosis (AIS) patients. Summary of Background Data. The reported pedicle screws perforation rates for corrective AIS surgery vary widely from 1.2% to 65.0%. Knowledge regarding the safety of pedicle screws in scoliosis surgery is very important in preventing complications. Methods. This study investigates the accuracy and safety of pedicle screws placed in 140 AIS patients. CT scans were used to assess the perforations that were classified according to Rao et al (2002): grade 0, grade 1 (<2mm), grade 2 (2-4mm), and grade 3 (>4mm). Anterior perforations were classified into grade 0, grade 1 (<4mm), grade 2 (4-6mm), and grade 3 (>6mm). Grade 2 and 3 (excluding lateral grade 2 and 3 perforation over thoracic vertebrae) were considered as critical perforations. Results. A total of 2020 pedicle screws from 140 patients were analyzed. The overall total perforation rate was 20.3% (410 screws) with 8.2% (166 screws) grade 1, 2.9% (58 screws) grade 2 and 9.2% (186 screws) grade 3 perforations. Majority of the perforations was because of lateral perforation occurring over the thoracic region, as a result of application of extrapedicular screws at this region. When the lateral perforations of the thoracic region were excluded, the perforation rate was 6.4% (129 screws), grade 2, 1.4% (28 screws) and grade 3, 0.8% (16 screws). There were only two symptomatic left medial grade 2 perforations: one screw at T12 presented with postoperative iliac crest numbness and another screw at L2 presented with radicular pain that subsided with conservative treatment. There were six anterior perforations abutting the right lung, four anterior perforations abutting the aorta, two anterior perforations abutting the esophagus, and one abutting the trachea was noted. Conclusion. Pedicle screws insertion in AIS has a total perforation rate of 20.3%. After exclusion of lateral thoracic perforations, the overall perforation rate was 8.6% with a critical perforation rate of 2.2% (44/2020). The rate of symptomatic screw perforation leading to radicular symptoms was 0.1%. There was no spinal cord, aortic, esophageal, or lung injuries caused by malpositioned screws in this study. Level of Evidence: 4 0\n",
      "Recurrence of hypercortisolemia after initial treatment of Cushing disease (CD) is more common than previously thought, with a third of patients suffering a recurrence over their lifetime. Awareness of this high rate and delayed timeline (sometimes decades) of potential recurrence is critical and patients with CD should be monitored at regular intervals throughout their lives. In this manuscript, we review the complex evaluation needed for defining CD remission versus persistent disease after surgery, and focus on challenges in diagnosing early recurrent hypercortisolemia. Late night salivary cortisol appears to be an earlier predictor of recurrence when compared with urinary free cortisol (UFC) excretion. We also review the criteria suggested to define recurrence of hypercortisolemia in patients treated with medical therapy. Further research is needed to determine the optimal way to evaluate a patient with CD recurrence as well as the riskbenefit ratio of treatment in early, mild recurrent disease. 0\n",
      "Feature selection (FS) and classification are consecutive artificial intelligence (AI) methods used in data analysis, pattern classification, data mining and medical informatics. Beside promising studies in the application of AI methods to health informatics, working with more informative features is crucial in order to contribute to early diagnosis. Being one of the prevalent psychiatric disorders, depressive episodes of bipolar disorder (BD) is often misdiagnosed as major depressive disorder (MDD), leading to suboptimal therapy and poor outcomes. Therefore discriminating MDD and BD at earlier stages of illness could help to facilitate efficient and specific treatment. In this study, a nature inspired and novel FS algorithm based on standard Ant Colony Optimization (ACO), called improved ACO (IACO), was used to reduce the number of features by removing irrelevant and redundant data. The selected features were then fed into support vector machine (SVM), a powerful mathematical tool for data classification, regression, function estimation and modeling processes, in order to classify MDD and BD subjects. Proposed method used coherence, a promising quantitative electroencephalography (EEG) biomarker, values calculated from alpha, theta and delta frequency bands. The noteworthy performance of novel IACO-SVM approach stated that it is possible to discriminate 46 BD and 55 MDD subjects using 22 of 48 features with 80.19% overall classification accuracy. The performance of IACO algorithm was also compared to the performance of standard ACO, genetic algorithm (GA) and particle swarm optimization (PSO) algorithms in terms of their classification accuracy and number of selected features. In order to provide an almost unbiased estimate of classification error, the validation process was performed using nested cross-validation (CV) procedure. 0\n",
      "Artificial intelligence (AI) is expected to support clinical judgement in medicine. We constructed a new predictive model for diabetic kidney diseases (DKD) using AI, processing natural language and longitudinal data with big data machine learning, based on the electronic medical records (EMR) of 64,059 diabetes patients. AI extracted raw features from the previous 6 months as the reference period and selected 24 factors to find time series patterns relating to 6-month DKD aggravation, using a convolutional autoencoder. AI constructed the predictive model with 3,073 features, including time series data using logistic regression analysis. AI could predict DKD aggravation with 71% accuracy. Furthermore, the group with DKD aggravation had a significantly higher incidence of hemodialysis than the non-aggravation group, over 10 years (N = 2,900). The new predictive model by AI could detect progression of DKD and may contribute to more effective and accurate intervention to reduce hemodialysis. 0\n",
      "Objective: Accurate diagnosis and prognosis are essential in lung cancer treatment selection and planning. With the rapid advance of medical imaging technology, whole slide imaging (WSI) in pathology is becoming a routine clinical procedure. An interplay of needs and challenges exists for computer-aided diagnosis based on accurate and efficient analysis of pathology images. Recently, artificial intelligence, especially deep learning, has shown great potential in pathology image analysis tasks such as tumor region identification, prognosis prediction, tumor microenvironment characterization, and metastasis detection. Materials and Methods: In this review, we aim to provide an overview of current and potential applications for AI methods in pathology image analysis, with an emphasis on lung cancer. Results: We outlined the current challenges and opportunities in lung cancer pathology image analysis, discussed the recent deep learning developments that could potentially impact digital pathology in lung cancer, and summarized the existing applications of deep learning algorithms in lung cancer diagnosis and prognosis. Discussion and Conclusion: With the advance of technology, digital pathology could have great potential impacts in lung cancer patient care. We point out some promising future directions for lung cancer pathology image analysis, including multi-task learning, transfer learning, and model interpretation. 0\n",
      "Advances in machine learning in medical imaging are occurring at a rapid pace in research laboratories both at academic institutions and in industry. Important artificial intelligence (AI) tools for diagnostic imaging include algorithms for disease detection and classification, image optimization, radiation reduction, and workflow enhancement. Although advances in foundational research are occurring rapidly, translation to routine clinical practice has been slower. In August 2018, the National Institutes of Health assembled multiple relevant stakeholders at a public meeting to discuss the current state of knowledge, infrastructure gaps, and challenges to wider implementation. The conclusions of that meeting are summarized in two publications that identify and prioritize initiatives to accelerate foundational and translational research in AI for medical imaging. This publication summarizes key priorities for translational research developed at the workshop including: (1) creating structured AI use cases, defining and highlighting clinical challenges potentially solvable by AI; (2) establishing methods to encourage data sharing for training and testing AI algorithms to promote generalizability to widespread clinical practice and mitigate unintended bias; (3) establishing tools for validation and performance monitoring of AI algorithms to facilitate regulatory approval; and (4) developing standards and common data elements for seamless integration of AI tools into existing clinical workflows. An important goal of the resulting road map is to grow an ecosystem, facilitated by professional societies, industry, and government agencies, that will allow robust collaborations between practicing clinicians and AI researchers to advance foundational and translational research relevant to medical imaging. 0\n",
      "Importance: Radiation therapy (RT) is a critical cancer treatment, but the existing radiation oncologist work force does not meet growing global demand. One key physician task in RT planning involves tumor segmentation for targeting, which requires substantial training and is subject to significant interobserver variation. Objective: To determine whether crowd innovation could be used to rapidly produce artificial intelligence (AI) solutions that replicate the accuracy of an expert radiation oncologist in segmenting lung tumors for RT targeting. Design, Setting, and Participants: We conducted a 10-week, prize-based, online, 3-phase challenge (prizes totaled 55000). A well-curated data set, including computed tomographic (CT) scans and lung tumor segmentations generated by an expert for clinical care, was used for the contest (CT scans from 461 patients; median 157 images per scan; 77942 images in total; 8144 images with tumor present). Contestants were provided a training set of 229 CT scans with accompanying expert contours to develop their algorithms and given feedback on their performance throughout the contest, including from the expert clinician. Main Outcomes and Measures: The AI algorithms generated by contestants were automatically scored on an independent data set that was withheld from contestants, and performance ranked using quantitative metrics that evaluated overlap of each algorithm's automated segmentations with the expert's segmentations. Performance was further benchmarked against human expert interobserver and intraobserver variation. Results: A total of 564 contestants from 62 countries registered for this challenge, and 34 (6%) submitted algorithms. The automated segmentations produced by the top 5 AI algorithms, when combined using an ensemble model, had an accuracy (Dice coefficient = 0.79) that was within the benchmark of mean interobserver variation measured between 6 human experts. For phase 1, the top 7 algorithms had average custom segmentation scores (S scores) on the holdout data set ranging from 0.15 to 0.38, and suboptimal performance using relative measures of error. The average S scores for phase 2 increased to 0.53 to 0.57, with a similar improvement in other performance metrics. In phase 3, performance of the top algorithm increased by an additional 9%. Combining the top 5 algorithms from phase 2 and phase 3 using an ensemble model, yielded an additional 9% to 12% improvement in performance with a final S score reaching 0.68. Conclusions and Relevance: A combined crowd innovation and AI approach rapidly produced automated algorithms that replicated the skills of a highly trained physician for a critical task in radiation therapy. These AI algorithms could improve cancer care globally by transferring the skills of expert clinicians to under-resourced health care settings.. 0\n",
      "Many clinical applications based on deep learning and pertaining to radiology have been proposed and studied in radiology for classification, risk assessment, segmentation tasks, diagnosis, prognosis, and even prediction of therapy responses. There are many other innovative applications of AI in various technical aspects of medical imaging, particularly applied to the acquisition of images, ranging from removing image artifacts, normalizing/harmonizing images, improving image quality, lowering radiation and contrast dose, and shortening the duration of imaging studies. This article will address this topic and will seek to present an overview of deep learning applied to neuroimaging techniques. 0\n",
      "Artificial intelligence (AI), particularly deep learning algorithms, is gaining extensive attention for its excellent performance in image-recognition tasks. They can automatically make a quantitative assessment of complex medical image characteristics and achieve an increased accuracy for diagnosis with higher efficiency. AI is widely used and getting increasingly popular in the medical imaging of the liver, including radiology, ultrasound, and nuclear medicine. AI can assist physicians to make more accurate and reproductive imaging diagnosis and also reduce the physicians' workload. This article illustrates basic technical knowledge about AI, including traditional machine learning and deep learning algorithms, especially convolutional neural networks, and their clinical application in the medical imaging of liver diseases, such as detecting and evaluating focal liver lesions, facilitating treatment, and predicting liver treatment response. We conclude that machine-assisted medical services will be a promising solution for future liver medical care. Lastly, we discuss the challenges and future directions of clinical application of deep learning techniques. 0\n",
      "Dietary fibre is important for regular laxation and reduces chronic disease risk. The National Health and Medical Research Council outlines daily fibre intake targets, yet the proportion of the population that meets these targets is unknown. Using the 2011–2012 National Nutrition and Physical Activity Survey, we profiled fibre intake among Australian children and adults. Data from one-day dietary recalls were analysed (n = 12,153, ≥2 years) as well as demographic and anthropometric factors. The median fibre intake was 18.2 g (interquartile range [IQR] 13.2–25.0) in children and 20.7 g (IQR 14.3–28.7) in adults. We found that 42.3% (95% CI 40.5–44.1%) of children and 28.2% (95% CI 27.3–29.1%) of adults met the Adequate Intake (AI), and less than 20% of adults met the Suggested Dietary Target (SDT) to reduce the risk of chronic disease. Older children (aged 14–18 years), girls, young adults (19–30 years), males, and those of lower socio-economic status were less likely to meet the AI (p < 0.001). Those with a higher energy intake were more likely to meet the AI. Anthropometric measures were not associated with fibre intake or the likelihood of meeting the AI. Fibre is a nutrient of concern in Australian diets, with most children and adults falling short of recommendations. Adolescents, girls, young adults, men, and those of lower socio-economic status were less likely to meet the recommendations and may benefit most from public health interventions. 0\n",
      "Artificial intelligence (AI) has been heralded as the next big wave in the computing revolution and touted as a transformative technology for many industries including health care. In radiology, considerable excitement and anxiety are associated with the promise of AI and its potential to disrupt the practice of the radiologist. Radiology has often served as the gateway for medical technological advancements, and AI will likely be no different. We present a brief overview of AI advancements that have driven recent interest, offer a review of the current literature, and examine the most likely ways that AI will change radiology in the coming years. 0\n",
      "Oncologists are aware of the vulvovaginal atrophy (VVA) problem in breast cancer survivors (BCSs) but only half of them illustrate VVA as a possible consequence of treatment. Forty-one percent of the oncologists refer BCSs to gynaecologist to define VVA treatment, whereas 35.1% manages it alone. Nonhormonal treatments are preferred by most oncologists (71%). The main reason not to prescribe vaginal estrogen therapy in BCSs is the fear of increased cancer recurrence, the possible interference with tamoxifen, or aromatase inhibitors and the fear of medical litigation. Background Vulvovaginal atrophy (VVA) is a relevant problem for breast cancer survivors (BCSs), in particular for those who receive aromatase inhibitors (AIs). We conducted a survey, to assess the attitude of oncologists toward the diagnosis and treatment of VVA in BCSs. Materials and Methods In 2015, 120 computer-assisted Web interviews were performed among breast oncologists. Results According to oncologists' perceptions, 60% of postmenopausal BCSs and 39.4% of premenopausal BCSs will suffer from VVA. Despite that none of the physicians considered VVA as a transient event or a secondary problem in BCSs, only half of the oncologists (48%) directly illustrated VVA to the patients as a possible consequence. Forty-one percent of the oncologists refer BCSs to gynaecologist to define VVA treatment, whereas 35.1% manages it alone. Nonhormonal treatments are preferred by most oncologists (71%). The main reason not to prescribe vaginal estrogen therapy in BCSs is the fear of increased cancer recurrence, the possible interference with tamoxifen, or AIs and the fear of medical litigation. Conclusion VVA is a relevant problem for BCSs. Great effort should be done to correctly inform health care providers about VVA problems and on the different possible available treatments. 0\n",
      "Background and Purpose-Patients with acute ischemic stroke (AIS) and large vessel occlusion may benefit from direct transportation to an endovascular capable comprehensive stroke center (mothership approach) as opposed to direct transportation to the nearest stroke unit without endovascular therapy (drip and ship approach). The optimal transport strategy for patients with AIS and unknown vessel status is uncertain. The rapid arterial occlusion evaluation scale (RACE, scores ranging from 0 to 9, with higher scores indicating higher stroke severity) correlates with the National Institutes of Health Stroke Scale and was developed to identify patients with large vessel occlusion in a prehospital setting. We evaluate how the RACE scale can help to inform prehospital triage decisions for AIS patients. Methods-In a model-based approach, we estimate probabilities of good outcome (modified Rankin Scale score of ≤2 at 3 months) as a function of severity of stroke symptoms and transport times for the mothership approach and the drip and ship approach. We use these probabilities to obtain optimal RACE cutoff scores for different transfer time settings and combinations of treatment options (time-based eligibility for secondary transfer under the drip and ship approach, time-based eligibility for thrombolysis at the comprehensive stroke center under the mothership approach). Results-In our model, patients with AIS are more likely to benefit from direct transportation to the comprehensive stroke center if they have more severe strokes. Values of the optimal RACE cutoff scores range from 0 (mothership for all patients) to >9 (drip and ship for all patients). Shorter transfer times and longer door-to-needle and needle-to-transfer (door out) times are associated with lower optimal RACE cutoff scores. Conclusions-Use of RACE cutoff scores that take into account transport times to triage AIS patients to the nearest appropriate hospital may lead to improved outcomes. Further studies should examine the feasibility of translation into clinical practice. 0\n",
      "Background: The independent role of mild autonomous cortisol secretion (ACS) in influencing the cardiovascular event (CVE) occurrence is a topic of interest. We investigated the role of mild ACS in the CVE occurrence in patients with adrenal incidentaloma (AI) by standard statistics and artificial neural networks (ANNs). Methods: We analyzed a retrospective record of 518 AI patients. Data regarding cortisol levels after 1 mg dexamethasone suppression (1 mg DST) and the presence of obesity (OB), hypertension (AH), type-2 diabetes (T2DM), dyslipidemia (DL), familial CVE history, smoking habit and CVE were collected. Results: The receiver-operating characteristic curve analysis suggested that 1 mg DST, at a cut-off of 1.8 μg/dL, had the best accuracy for detecting patients with increased CVE risk. In patients with 1 mg-DST ≥1.8 μg/dL (DST+, n = 223), age and prevalence of AH, T2DM, DL and CVE (66 years, 74.5, 25.9, 41.4 and 26.8% respectively) were higher than that of patients with 1 mg-DST ≤1.8 μg/dL (61.9 years, 60.7, 18.5, 32.9 and 10%, respectively, P < 0.05 for all). The CVE were associated with DST+ (OR: 2.46, 95% CI: 1.5-4.1, P = 0.01), regardless of T2DM, AH, DL, smoking habit, gender, observation period and age. The presence of at least two among AH, T2DM, DL and OB plus DST+ had 61.1% sensitivity in detecting patients with CVE. By using the variables selected by ANNs (familial CVE history, age, T2DM, AH, DL and DST+) 78.7% sensitivity was reached. Conclusions: Cortisol after 1 mg-DST is independently associated with the CVE occurrence. The ANNs might help for assessing the CVE risk in AI patients. 0\n",
      "The global pandemic of coronavirus disease 2019 (COVID-19), caused by novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), has resulted in over 7,273,958 cases with almost over 413,372 deaths worldwide as per the WHO situational report 143 on COVID-19. There are no known treatment regimens with proven efficacy and vaccines thus far, posing an unprecedented challenge to identify effective drugs and vaccines for prevention and treatment. The urgency for its prevention and cure has resulted in an increased number of proposed treatment options. The high rate and volume of emerging clinical trials on therapies for COVID-19 need to be compared and evaluated to provide scientific evidence for effective medical options. Other emerging non-conventional drug discovery techniques such as bioinformatics and cheminformatics, structure-based drug design, network-based methods for prediction of drug-target interactions, artificial intelligence (AI) and machine learning (ML) and phage technique could provide alternative routes to discovering potent Anti-SARS-CoV2 drugs. While drugs are being repurposed and discovered for COVID-19, novel drug delivery systems will be paramount for efficient delivery and avoidance of possible drug resistance. This review describes the proposed drug targets for therapy, and outcomes of clinical trials that have been reported. It also identifies the adopted treatment modalities that are showing promise, and those that have failed as drug candidates. It further highlights various emerging therapies and future strategies for the treatment of COVID-19 and delivery of Anti-SARS-CoV2 drugs. 0\n",
      "The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce. 0\n",
      "Deep learning methods have been very effective for a variety of medical diagnostic tasks and have even outperformed human experts on some of those. However, the black-box nature of the algorithms has restricted their clinical use. Recent explainability studies aim to show the features that influence the decision of a model the most. The majority of literature reviews of this area have focused on taxonomy, ethics, and the need for explanations. A review of the current applications of explainable deep learning for different medical imaging tasks is presented here. The various approaches, challenges for clinical deployment, and the areas requiring further research are discussed here from a practical standpoint of a deep learning researcher designing a system for the clinical end-users. 0\n",
      "Introduction: Machine learning capability holds promise to inform disease models, the discovery and development of novel disease modifying therapeutics and prevention strategies in psychiatry. Herein, we provide an introduction on how machine learning/Artificial Intelligence (AI) may instantiate such capabilities, as well as provide rationale for its application to psychiatry in both research and clinical ecosystems. Methods: Databases PubMed and PsycINFO were searched from 1966 to June 2016 for keywords:Big Data, Machine Learning, Precision Medicine, Artificial Intelligence, Mental Health, Mental Disease, Psychiatry, Data Mining, RDoC, and Research Domain Criteria. Articles selected for review were those that were determined to be aligned with the objective of this particular paper. Results: Results indicate that AI is a viable option to build useful predictors of outcome while offering objective and comparable accuracy metrics, a unique opportunity, particularly in mental health research. The approach has also consistently brought notable insight into disease models through processing the vast amount of already available multi-domain, semi-structured medical data. The opportunity for AI in psychiatry, in addition to disease-model refinement, is in characterizing those at risk, and it is likely also relevant to personalizing and discovering therapeutics. Conclusions: Machine learning currently provides an opportunity to parse disease models in complex, multi-factorial disease states (e.g. mental disorders) and could possibly inform treatment selection with existing therapies and provide bases for domain-based therapeutic discovery. 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText2\"]/a/span[1]').click()\n",
    "contents = driver.find_elements_by_xpath('//*[@id=\"previewAbstract2\"]/span')\n",
    "for i in contents:\n",
    "    a=i.text\n",
    "print(type(a))\n",
    "\n",
    "# content"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "//*[@id=\"previewAbstractLinkText3\"]/a/span[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText3\"]/a/span[1]').click()\n",
    "contents = driver.find_elements_by_xpath('//*[@id=\"previewAbstract3\"]/span')\n",
    "for i in contents:\n",
    "    content.append(i.text)\n",
    "\n",
    "content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText4\"]/a/span[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText4\"]/a/span[1]').click()\n",
    "contents = driver.find_elements_by_xpath('//*[@id=\"previewAbstract4\"]/span')\n",
    "for i in contents:\n",
    "    content.append(i.text)\n",
    "\n",
    "print(len(content))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText5\"]/a/span[1]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"previewAbstractLinkText5\"]/a/span[1]').click()\n",
    "contents = driver.find_elements_by_xpath('//*[@id=\"previewAbstract5\"]/span')\n",
    "for i in contents:\n",
    "    content.append(i.text)\n",
    "\n",
    "print(len(content))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "contents_list = []\n",
    "\n",
    "for i in abstract_xlist:\n",
    "    content = driver.find_elements_by_xpath(i)\n",
    "    contents_list.append(content)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "abstract = []\n",
    "\n",
    "for i in contents_list:\n",
    "    abstracts_ = i.text\n",
    "    abstract.append(abstracts_)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1j/_j1_4nyn2dsdvt2c9kb6lr4r0000gn/T/ipykernel_1310/1474417618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mabstracts_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mabstract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstracts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'text'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "content = driver.find_elements_by_xpath('//*[@id=\"previewAbstract1\"]/span')\n",
    "print(content)\n",
    "for i in content:\n",
    "    print(i.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4ab621ef-6ade-4087-85fe-6c03266b1387\")>]\n",
      "The COVID-19 outbreak has created havoc around the world and has brought life to a disturbing halt claiming thousands of lives worldwide with the infected cases rising every day. With technological advancements in artificial intelligence (AI), AI-based platforms can be used to deal with the COVID-19 pandemic and accelerate the processes ranging from crowd surveillance to medical diagnosis. This paper renders a response to battle the virus through various AI techniques by making use of its subsets such as machine learning (ML), deep learning (DL), and natural language processing (NLP). A survey of promising AI methods that could be used in various applications to facilitate the processes in this pandemic along with the potential of AI and challenges imposed are discussed thoroughly. This paper relies on the findings of the most recent research publications and journals on COVID-19 and suggests numerous relevant strategies. A case study on the impact of COVID-19 in various economic sectors is also discussed. The potential research challenges and future directions are also presented in the paper.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "content = driver.find_elements_by_xpath('//*[@id=\"previewAbstract2\"]/span')\n",
    "print(content)\n",
    "for i in content:\n",
    "    print(i.text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "content = driver.find_elements_by_xpath('//*[@id=\"previewAbstract3\"]/span')\n",
    "print(content)\n",
    "for i in content:\n",
    "    print(i.text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "contents=[]\n",
    "\n",
    "for num,i in enumerate (abstract_xlist):\n",
    "    # print(abstract_xlist[num])\n",
    "    content = driver.find_elements_by_xpath(abstract_xlist[num])\n",
    "    contents.append(content)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "contents[0][0].text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "contents[1][0].text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'During the current global public health emergency caused by novel coronavirus disease 19 (COVID-19), researchers and medical experts started working day and night to search for new technologies to mitigate the COVID-19 pandemic. Recent studies have shown that artificial intelligence (AI) has been successfully employed in the health sector for various healthcare procedures. This study comprehensively reviewed the research and development on state-of-the-art applications of artificial intelligence for combating the COVID-19 pandemic. In the process of literature retrieval, the relevant literature from citation databases including ScienceDirect, Google Scholar, and Preprints from arXiv, medRxiv, and bioRxiv was selected. Recent advances in the field of AI-based technologies are critically reviewed and summarized. Various challenges associated with the use of these technologies are highlighted and based on updated studies and critical analysis, research gaps and future recommendations are identified and discussed. The comparison between various machine learning (ML) and deep learning (DL) methods, the dominant AI-based technique, mostly used ML and DL methods for COVID-19 detection, diagnosis, screening, classification, drug repurposing, prediction, and forecasting, and insights about where the current research is heading are highlighted. Recent research and development in the field of artificial intelligence has greatly improved the COVID-19 screening, diagnostics, and prediction and results in better scale-up, timely response, most reliable, and efficient outcomes, and sometimes outperforms humans in certain healthcare tasks. This review article will help researchers, healthcare institutes and organizations, government officials, and policymakers with new insights into how AI can control the COVID-19 pandemic and drive more research and studies for mitigating the COVID-19 outbreak.'"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "contents[2][0].text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Background: Histopathological classification of Wilms tumors determines treatment regimen. Machine learning has been shown to contribute to histopathological classification in various malignancies but requires large numbers of manually annotated images and thus specific pathological knowledge. This study aimed to assess whether trained, inexperienced observers could contribute to reliable annotation of Wilms tumor components for classification performed by machine learning. Methods: Four inexperienced observers (medical students) were trained in histopathology of normal kidneys and Wilms tumors by an experienced observer (pediatric pathologist). Twenty randomly selected scanned Wilms tumor-slides (from n = 1472 slides) were annotated, and annotations were independently classified by both the inexperienced observers and two experienced pediatric pathologists. Agreement between the six observers and for each tissue element was measured using kappa statistics (κ). Results: Pairwise interobserver agreement between all inexperienced and experienced observers was high (range: 0.845–0.950). The interobserver variability for the different histological elements, including all vital tumor components and therapy-related effects, showed high values for all κ-coefficients (> 0.827). Conclusions: Inexperienced observers can be trained to recognize specific histopathological tumor and tissue elements with high interobserver agreement with experienced observers. Nevertheless, supervision by experienced pathologists remains necessary. Results of this study can be used to facilitate more rapid progress for supervised machine learning-based algorithm development in pediatric pathology and beyond.'"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "//*[@id=\"previewAbstractLinkText4\"]/a/span[1]\n",
    "//*[@id=\"previewAbstractLinkText5\"]/a/span[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "text_list = []\n",
    "for i in abstract_xlist:\n",
    "    content = driver.find_elements_by_xpath(i)\n",
    "    print(content)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4ab621ef-6ade-4087-85fe-6c03266b1387\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"47ca4d4a-0cd0-47d6-b31e-cc2e3f6e801b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"404dae65-c539-4439-a16c-134bdbed605f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"09e7dd7d-45d4-4e9f-b1ff-12f879689500\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a5dc84e1-3fe2-4b2d-b0df-8eda9b5dd078\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5ad3cd48-09d1-417f-a1cd-3a569bd9b25f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"157775c2-c87c-4a15-995d-470e68074382\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e6209a04-a8a6-4203-95ef-382d851e428b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"28e242aa-be55-49ef-93f9-7caabf59d4b5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a047210b-fca6-4083-85c8-d216858d12ea\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"77885561-ea17-4ee1-8ac9-bda61755574f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"408b6755-6c5c-424a-ae64-86626f887db7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c31c0ac2-c477-4117-8f1e-c97b04722ffd\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"448f5e21-43d3-46c6-a634-d1d6e99f66d1\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"049b10f1-64a2-4299-a1c9-07e8298719f1\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"90ac0df0-f62f-4502-bdd1-5c3d7883d9fa\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"68859959-4270-4bd5-9567-84e778f6138f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d534519a-457d-4154-93eb-9a717cf8d313\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c22f0236-c144-4419-9979-0884c50ad647\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"0dbdc1ec-7f10-44eb-b19a-0b6a1af2fb68\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"21cb9a6f-be72-4908-bf29-31d64eaf451e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"51c7a487-67bb-4b60-9e9f-8fa8701d3e55\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"1781b51c-a0ee-48f3-a2db-38519f3ff854\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"72057647-9b43-4b1f-a1ba-5b189b0f6097\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"558007c8-ed77-4295-ace8-17b6459363ee\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f7a84972-a0ce-48f8-9175-aa591aed3d0f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"8e91b5ed-c196-4e81-bc3a-880b55b8b9fc\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6a9abb83-7c09-4060-aec9-22a21e354916\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e8973fa6-77cd-46e5-8e78-cde9e5c354b1\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"29b49a8a-fc9a-4f24-b9a8-5892017afcdf\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"cf48e542-6ee6-4550-b6dd-9a6c3d56d2ff\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"9ad0cad1-baa5-4872-9b9d-20bb04fa36d2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a412aa8c-0e6e-45ec-b13f-5ea8fe8b779b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3ec3a443-4f20-4079-883d-596cebae82cf\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"110f3536-db90-4e5f-b803-ee003fe79f11\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a7be9012-16c3-4c4b-8e21-af6e78930fc4\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4776c2e3-755e-4776-9f7d-177947b6fc47\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b32bc142-bc0d-449e-a0e2-e47723a9324c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"591efc5d-486c-4173-be53-21fae74decf4\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5aa6a328-61bd-4106-b97b-abae393dd84a\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"968c79b3-3586-4174-b82f-0266fce79d31\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"de3d743c-2760-4bd1-9e66-c0ee09490ee9\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a17918d2-b75e-4437-b29f-37d4f1e6faa6\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c3543d77-3cba-4c6c-a717-ee4c5335c057\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"2bd4e48c-9864-42cd-9682-f33c01fc9bb9\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3961650d-0dc4-4a6b-ab9e-4cec78b2fabe\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"28ae9207-e770-4b35-9a87-c91f932179cb\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a1263ec8-12b2-478c-b471-5c3dba0adad5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"fa1b48ac-9080-45f3-a61c-45852ba09f08\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7154b7b8-4148-4151-85cf-099a8d0e317e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c98ab303-70d7-4524-a059-956f258e64db\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"695d20e5-d3d2-476c-9437-3c02a5b65124\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"05eaf0ff-9c30-442a-9aeb-1a3e1bc61c59\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"cbe4bbc9-d613-437c-a101-25c96c75660a\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"8210c9e3-4523-494e-8e67-c150b248bbc8\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"9c65e519-1b0c-4e84-9337-ac34f265ad36\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7de2d14c-a891-4441-93b2-ee8366614034\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"11b7bab0-e048-45a5-bd83-83a6ba4c8fe6\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"49f89f19-aedc-4b00-9f33-f3e41af1ea19\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"21a0d05c-43e2-4659-be58-1f84bb29d907\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7278510e-3702-4cff-898a-fd14bdb4b993\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"1a164fc9-8fa7-459b-bb8c-981376e48d48\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"bcf14ff8-f4a1-4e74-9080-c1d97089ac86\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"cd18f83e-e679-47fa-bb87-fee1b9b635e0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"8e27285e-67cf-4a20-bf5d-76c9fe142a79\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4a202f50-aeb5-4819-90a3-564010097f0b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"bb40047f-e615-453f-b155-2b74f6d7eff1\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d7d876ca-59a6-4ec0-a2b5-fee4410bbd79\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4d665408-59c3-4cf1-af32-c8262a8617f8\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"83a1cf0b-2e87-4984-92f2-cf6abfcf3dcb\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"bf50ce01-0590-41c6-b910-c190b58aef67\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"bad4faac-a237-43b9-9d32-c1848b8d9406\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b0031b1f-dd2a-42db-a7c6-86317f3d4888\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3bed9d6d-2408-472d-892f-360b211e04dd\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f99eca55-bc64-44fe-a4b0-ec5d6b0aeb29\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3ba3edad-ed6a-4730-afda-6b0dc9601f4e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"163dcd58-3fd9-4e91-9cc2-4c96ca8e9c8f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5b64b6f1-b6cd-4204-a7e7-c24758435bec\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b4a0bc71-7d5d-498e-ac81-ddc413221cd0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a174d5a9-f494-4f94-abf7-845df19a14e9\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c22df07f-0251-4e38-84c2-3c66b89f09fb\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"20cc6622-72c2-4309-90da-4c372a339b8c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6fdc521c-417b-47af-b8fd-6ebaea924a4a\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7c897b40-2c1f-4f12-ad83-24be1429010b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4b1580ea-7b99-4a90-a4a8-5563f52bb5dc\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d4fee762-f323-4bf5-8318-c4a263739f1f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f449032a-0de9-4680-9bc4-63c1b16187d5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"72894f00-9a78-44dc-bcf8-0fb42d1999d3\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"fd09a82f-d10c-4988-9bba-7b171d2b2292\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e9368bf9-6efc-4f0d-ae55-cb9578189204\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"10eaf938-134d-4821-94aa-aecd742c2376\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3efa9200-2ff8-473c-8cec-cb6bc035c4a3\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"576401e7-7653-49f2-b0fe-73f143d0f735\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"ccc1b9e5-8547-4d1b-acf6-de238a7e7873\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"89119ab8-8103-4c9c-bc96-d00c7feb3e29\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d9a502c4-3f07-4b8d-8142-f7a8de920cc5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a0eadf40-ef33-4704-a406-4327ba45de49\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"71d401b6-84d0-4ca6-b113-5130f2d47ee0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5baf734b-e9db-4307-a6f3-993c62e19062\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c7c54ccc-0964-4c97-8a2c-eba8ab8330a0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"53348dec-5bc9-4e69-993f-fcc85cf0964c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c4026941-cc69-4b2c-9eb1-f92cd2281815\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"894f1bed-2523-4be2-a908-1c1815d2e2a0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"128bdd86-01b1-44d5-86ea-4cf019d31535\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e76bdef4-d742-4cb3-b275-2c6e8f876ed7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"110715b7-d79e-43a2-82dc-ff5f4f1a1302\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"73468c5b-fa66-4528-a25f-8b15a4066dcd\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"0c0c2c55-a03f-4516-8f57-bcb57ce40117\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3587716c-387a-43fc-b7ac-e52edc613b05\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"617c2ea1-62a6-49a3-9dab-0047a50fdc59\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6ad51fa2-9ce6-4f54-a755-ba86a82068fe\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"de0efd29-7926-43ae-adad-3bc46ac1b20c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b179d64d-f2a8-43a7-8bc8-d4d88cb76e8d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"1358ffef-af93-4538-a6be-70dc9934ad59\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a8f256a8-d170-4e2f-9c2a-76e8ce218157\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4a841f08-a569-4cc0-8dd0-c2505d8ba80f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7589cfe1-2b9e-4c2c-83e7-b2e6b71da2a7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e288a5e8-0975-4051-92ae-1f5ebc1c1e2c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f780c9ec-272d-4b81-8ae6-9cdea397a481\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"32ed21aa-93cd-4dd8-8c5a-5d3d89e255fa\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4ac9209d-e368-4756-b43d-f6bec37ae94f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"84e162f0-3f9e-4bf5-b0e2-7944f3a43a65\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"ce0430d6-6f02-4e44-b009-10eecff44994\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"86c8d61e-7ff6-4080-adc8-8b1e57ba6fa8\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"cd12aff9-cbc8-4bc0-9be0-e8ce18af2bf5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"982fe041-9c56-421d-bc47-3ce4669d1e89\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c5757079-2660-482f-a13e-b7a6f52603aa\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"703f06a0-914c-4770-834c-062e6e65dfb2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6d98dff3-630b-4012-9a6f-7db37b564038\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"51d4b761-196f-4f5a-93b5-85aa7d4b2317\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"35967c2f-c1b7-4105-8196-df41c6cf8a1e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d45c4f84-ec74-473e-9632-cdc41537644f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5de4065d-26b6-4ffd-aea2-9745d2e5daa9\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f8e89988-4e8c-4b55-9159-5880eaf9b0d2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"afc8014a-a054-4caf-9fd2-388c4c8327e5\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"47ea3657-0104-4587-9666-4d6c62c2e0c6\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"2fa1e295-4b9e-4f20-8d93-dacabfb3bb9d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a48b7a5f-de34-4549-bb92-8f4e81c490d2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7a8d6206-22e4-410a-abcc-73f1d3a870f7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"025e57eb-5a38-4bcf-b2b2-c3c2737b4a57\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f5a4b513-f472-400e-8c6f-5621e03ba358\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f57c1770-e7c0-433a-a787-7940fada1c94\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"753d710e-75cd-419c-ad3f-6225bae3ec93\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e21af47b-8d78-44ea-9e5a-af1e9878057b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"1c1c2141-8dd5-42c2-b0d4-98adee448f18\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f0074127-9f6c-4c46-b2c7-6946d49008f2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"0cb364e8-0305-4ed4-aba0-61422aed1a37\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"67e837c9-e973-4cad-a324-9ca67bfc924b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"dd7b3bb7-c6c8-42c4-aa9a-bc8ebc7f02c2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7bb33846-0e26-4348-8fae-09bedc39759f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d924d6b0-099f-40e2-8aef-a737d2c47097\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"1c030844-75ff-471e-a333-9fbc44fe2509\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"03625b91-971c-4051-a939-2d3c662f7cc9\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"aa2216e0-8a5f-43c9-9e91-eb9ce279e503\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c67b8e71-801f-4d85-9ac9-a3dfa1706586\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"7f3c45df-065f-4075-bc6a-f93b60f846f2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"139db87a-631d-432c-b034-61311ae2f1c4\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f609cf7d-194a-46ab-8bd4-e0e945fe3646\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6a24fe1a-01f9-44b2-83aa-cfb9fe983c5d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3baff49c-e3f1-4140-b700-71155992c7ab\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"ed32b329-20f4-48ce-9776-88f4e96a6371\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c0f83a78-b7c6-49f2-be27-96428aeb9f9b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6164abf0-4181-472c-a0f3-8275be97ba8f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"769cfbdb-0163-48f0-b144-24a3a9c1ec8d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"769fbb06-bc55-4b87-a850-e13abc93245d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6ab9f809-ee28-454d-8e30-53431b817e9e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"9bbfb995-158f-4584-b78a-2ea32785dc43\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c639fe5b-1eec-41e6-aba4-3b6fcf579e23\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"4135dd9a-9203-4ab9-b773-7d338d52bfbb\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"c8474462-b05b-4ae3-a017-60965aba5bb3\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"02685ecd-1574-4545-8811-db8cf5ceff20\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"974441d3-9cd7-4ead-a60a-880da1a010d8\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"fe98f438-9a89-41f6-9d4a-614b65707305\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6600f9a8-1f9a-4e58-a666-7bc78aa35858\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"63ce6f48-3636-4006-9d91-2f9a8a0938a1\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d35709e0-5067-4385-a9ab-63184003db6e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"fad40822-68b9-4833-9bd7-21530997ab7f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"8af3da79-2549-4ccc-9eb6-7b7325a133c2\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"3bfceb11-ae96-41ec-94ea-d0f38b828429\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b63de213-9127-4888-931e-0e875a611eae\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"870c2a7f-fc47-4cfb-9f3c-36a441c8fa77\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"fa9357ce-c411-4280-a76c-a265dc9f6ab6\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"16a90c9f-7cb4-4ccf-a963-e364f37338cc\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"0e48bf20-21a9-4237-9532-14d8c039352e\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"a35a9397-f986-4cd2-ad0d-4e0ec04f5ba8\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"f862ea16-e0ae-4dae-9e12-f06e97622ba7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"65e320c3-741a-4a42-b0b5-794995b2ef6c\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"9f1d0501-b0f4-495c-8955-6b9b8c71b101\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e76d3aec-1996-4569-a62c-6f9044db27e7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"77219cda-8d39-46bb-881e-ba6946444efb\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"d23a1ddd-79af-4383-91f0-e2776a026650\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"75c01b3c-748c-481f-9ff3-afe74d42e67d\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"eb83cbfd-a919-4e5c-bd87-8cfd2fa0845f\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"b9e269ae-079b-4cc2-82a8-2357233ec7d7\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"5e3c37c6-1fad-4206-83b4-8e4f60ba2a65\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"8216ed10-180f-4160-95ba-af46d0fe563b\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"12cf6e2c-b11c-4d4e-979c-23daded03d99\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"e35bd473-537b-4163-a933-db16a2c687a0\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"f1830ff10308da315f43cc15fdc081cf\", element=\"6e2baeed-80cf-487b-bbf1-b0dcdf3e1f4d\")>]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('scrapper': conda)"
  },
  "interpreter": {
   "hash": "13ddd8e4bbab9f189b23159d9bff0382f6ebbdf19bbccdd26279f60d699cf2a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}